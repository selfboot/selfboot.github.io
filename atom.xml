<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Just For Fun</title>
  <icon>https://www.gravatar.com/avatar/0de0c23d97c75300e32f8494b1485fb8</icon>
  <subtitle>知其然，知其所以然。知识广度是深度的副产品！</subtitle>
  <link href="https://selfboot.cn/atom.xml" rel="self"/>
  
  <link href="https://selfboot.cn/"/>
  <updated>2025-06-10T13:51:57.714Z</updated>
  <id>https://selfboot.cn/</id>
  
  <author>
    <name>selfboot</name>
    <email>xuezaigds@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  
  
  
  <entry>
    <title>LevelDB 源码阅读：结合代码理解多版本并发控制(MVCC)</title>
    <link href="https://selfboot.cn/2025/06/10/leveldb_mvcc_intro/"/>
    <id>https://selfboot.cn/2025/06/10/leveldb_mvcc_intro/</id>
    <published>2025-06-10T17:47:42.000Z</published>
    <updated>2025-06-10T13:51:57.714Z</updated>
    
    <content type="html"><![CDATA[<p>在数据库系统中，并发访问是一个常见的场景。多个用户同时读写数据库，如何保证每个人的读写结果都是正确的，这就是并发控制要解决的问题。</p><p>考虑一个简单的转账场景，开始的时候 A 账户有 1000 元，要转 800 元给 B 账户。转账过程包括两步：从 A 扣钱，给 B 加钱。恰好在这两步中间，有人查询了 A 和 B 的余额。</p><p>如果没有任何并发控制，查询者会看到一个异常现象：A 账户已经被扣除了 800 元，只剩 200 元，B 账户还没收到转账，还是原来的金额！这就是典型的数据不一致问题。为了解决这个问题，数据库系统<strong>需要某种并发控制机制</strong>。</p><p>最直观的解决方案是加锁，当有人在进行写操作（如转账）时，其他人的读操作必须等待。回到前面的问题，只有在转账的两步都完成之后，才能查到正确的账户余额。但是锁机制存在明显的问题，每次只要写相关 key，所有读该 key 的操作都要排队等待，导致并发上不去，性能会比较差。</p><p>现代数据库系统普遍采用 MVCC 来控制并发，LevelDB 也不例外，接下来我们结合源码来理解 LevelDB 的 MVCC 实现。</p><span id="more"></span><h2 id="通过-MVCC-控制并发"><a href="#通过-MVCC-控制并发" class="headerlink" title="通过 MVCC 控制并发"></a>通过 MVCC 控制并发</h2><p>MVCC(<a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">Multi-Version Concurrency Control</a>) 是一种并发控制机制，它通过维护数据的多个版本来实现并发访问。简单来说，LevelDB 的 MVCC 实现关键点有下面几个：</p><ul><li>每个 key 可以有多个版本，每个版本都有自己的序列号(sequence number)；</li><li>写操作创建新版本而不是直接修改现有数据。不同的写入需要加锁互斥，保证每个写入获得递增的版本号。</li><li>不同的读操作之间可以并发，不用加锁。多个读操作也可以和写操作并发，不需要加锁。</li><li>通过 snapshot 来实现读和写、读和读之间的隔离，读取操作看到的总是某个时间点之前的数据版本。</li></ul><p>这就是 MVCC 的核心思想了。我们通过一个具体的时间操作序列，来理解下 MVCC 是怎么工作的。假设有以下操作序列：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">时间点 T1: <span class="attribute">sequence</span>=100, 写入 <span class="attribute">key</span>=A, <span class="attribute">value</span>=1</span><br><span class="line">时间点 T2: <span class="attribute">sequence</span>=101, 写入 <span class="attribute">key</span>=A, <span class="attribute">value</span>=2</span><br><span class="line">时间点 T3: Reader1 获取 <span class="attribute">snapshot</span>=101</span><br><span class="line">时间点 T4: <span class="attribute">sequence</span>=102, 写入 <span class="attribute">key</span>=A, <span class="attribute">value</span>=3</span><br><span class="line">时间点 T5: Reader2 获取 <span class="attribute">snapshot</span>=102</span><br></pre></td></tr></table></figure><p>那么不管 Reader1 和 Reader2 谁先读取，Reader1 读取 key&#x3D;A 总会得到 value&#x3D;2（sequence&#x3D;101），Reader2 读取 key&#x3D;A 会得到 value&#x3D;3（sequence&#x3D;102）。后续如果有新的读取，不带 snapshot 的读取会得到最新的数据。通过下面的时序图更容易理解，mermaid 源码在<a href="/downloads/mermaid_leveldb_mvcc.txt">这里</a>：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250610_leveldb_mvcc_intro_r_w.webp" alt="LevelDB 读写 MVCC 操作时序图"></p><p>MVCC 的整体效果就如上了，还是比较容易理解的。下面看看 LevelDB 中是怎么实现 MVCC 的。</p><h2 id="LevelDB-键带版本格式"><a href="#LevelDB-键带版本格式" class="headerlink" title="LevelDB 键带版本格式"></a>LevelDB 键带版本格式</h2><p>实现 MVCC 的前提是，<strong>每个键都保存多个版本</strong>。所以要设计一个数据结构，把键和版本号关联起来。LevelDB 设计的 key 格式如下：</p><blockquote><p>[key][sequence&lt;&lt;8|type]</p></blockquote><p>LevelDB 的做法也比较容易理解，在原来的 key 后面拼上版本信息。这里版本信息是一个 64 位的 uint，其中高 56 位存储的是 sequence，低 8 位存储的是操作类型。这里操作类型目前只有两种，对应的分别是写入和删除操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Value types encoded as the last component of internal keys.</span></span><br><span class="line"><span class="comment">// DO NOT CHANGE THESE ENUM VALUES: they are embedded in the on-disk</span></span><br><span class="line"><span class="comment">// data structures.</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">ValueType</span> &#123; kTypeDeletion = <span class="number">0x0</span>, kTypeValue = <span class="number">0x1</span> &#125;;</span><br></pre></td></tr></table></figure><p>这里序列号只有 56 位，所以最多可以支持 $ 2^{56} $ 次写入。这样实现会不会有问题？如果我想<span style="color:red">写入更多的 key 那岂不是不支持了</span>？理论上是的，但是咱们从实际使用场景来分析下。假设每秒写入 100W 次，这个已经是很高的写入 QPS 了，那么可以持续写入的时间是：</p><p>$$ 2^{56} &#x2F; 1000000 &#x2F; 3600 &#x2F; 24 &#x2F; 365 &#x3D; 2284 $$ </p><p>嗯。。。能写 2000 多年，所以这个序列号是够用的，不用担心耗尽问题了。这里的数据格式设计虽然很简单，但还是有不少好处的：</p><ol><li><strong>同一个 key 支持不同版本</strong>，同一个 key 多次写入，最新写入的会有更高的序列号。在写入的同时，支持并发读这个 key 的更老版本。</li><li>类型字段(type)区分普通写入还是删除，这样删除并不是真正删除数据，而是写入一个删除标记，只有等待 compaction 时被真正删除。</li></ol><p>我们知道 LevelDB 中键是顺序存储的，当要查询单个键时，可以用二分查找快速定位。当需要获取一系列连续键时，可以使用二分查找快速定位范围起点，然后顺序扫描即可。但现在我们给键增加了版本号，那么问题来了，<strong>带版本号的键要怎么排序呢</strong>？</p><h3 id="内部键排序方法"><a href="#内部键排序方法" class="headerlink" title="内部键排序方法"></a>内部键排序方法</h3><p>LevelDB 的做法也是比较简单有效，排序规则如下：</p><ol><li>首先按键升序排列，这里是按照字符串的字典序排序；</li><li>然后按序列号降序排列，序列号越大越靠前；</li><li>最后按类型降序排列，写入类型靠前，删除类型靠后；</li></ol><p>为了实现这里的排序规则，LevelDB 实现了自己的比较器，在 <a href="https://github.com/google/leveldb/blob/main/db/dbformat.cc#L47">db&#x2F;dbformat.cc</a> 中，代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">InternalKeyComparator::Compare</span><span class="params">(<span class="type">const</span> Slice&amp; akey, <span class="type">const</span> Slice&amp; bkey)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Order by:</span></span><br><span class="line">  <span class="comment">//    increasing user key (according to user-supplied comparator)</span></span><br><span class="line">  <span class="comment">//    decreasing sequence number</span></span><br><span class="line">  <span class="comment">//    decreasing type (though sequence# should be enough to disambiguate)</span></span><br><span class="line">  <span class="type">int</span> r = user_comparator_-&gt;<span class="built_in">Compare</span>(<span class="built_in">ExtractUserKey</span>(akey), <span class="built_in">ExtractUserKey</span>(bkey));</span><br><span class="line">  <span class="keyword">if</span> (r == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint64_t</span> anum = <span class="built_in">DecodeFixed64</span>(akey.<span class="built_in">data</span>() + akey.<span class="built_in">size</span>() - <span class="number">8</span>);</span><br><span class="line">    <span class="type">const</span> <span class="type">uint64_t</span> bnum = <span class="built_in">DecodeFixed64</span>(bkey.<span class="built_in">data</span>() + bkey.<span class="built_in">size</span>() - <span class="number">8</span>);</span><br><span class="line">    <span class="keyword">if</span> (anum &gt; bnum) &#123;</span><br><span class="line">      r = <span class="number">-1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (anum &lt; bnum) &#123;</span><br><span class="line">      r = <span class="number">+1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到首先从带版本号的 key 中去掉后 8 位，拿到真实的用户键，之后按照用户键的排序规则进行比较。这里再多说一句，LevelDB 提供了一个默认的用户键比较器 <code>leveldb.BytewiseComparator</code>，这里是完全按照键值的字节序进行比较。比较器的实现代码在 <a href="https://github.com/google/leveldb/blob/main/util/comparator.cc#L21">util&#x2F;comparator.cc</a> 中，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BytewiseComparatorImpl</span> : <span class="keyword">public</span> Comparator &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">BytewiseComparatorImpl</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">const</span> <span class="type">char</span>* <span class="title">Name</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;leveldb.BytewiseComparator&quot;</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">Compare</span><span class="params">(<span class="type">const</span> Slice&amp; a, <span class="type">const</span> Slice&amp; b)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a.<span class="built_in">compare</span>(b);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ... </span></span><br></pre></td></tr></table></figure><p>这里 Slice 是 LevelDB 中定义的一个字符串类，用于表示一个字符串，它的 compare 就是字节码比较。其实 LevelDB 也支持用户自定义比较器，只需要实现 Comparator 接口即可。这里多说一点，在使用比较器的时候，用 BytewiseComparator 封装了一个单例，代码有点难理解，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">const</span> Comparator* <span class="title">BytewiseComparator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">static</span> NoDestructor&lt;BytewiseComparatorImpl&gt; singleton;</span><br><span class="line">  <span class="keyword">return</span> singleton.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我之前专门写了一篇文章来解释 NoDestructor 模板类，感兴趣的可以看下：<a href="https://selfboot.cn/2024/07/22/leveldb_source_nodestructor/">LevelDB 源码阅读：禁止对象被析构</a>。</p><p>这种排序规则的好处也是显而易见的，首先按照用户键升序排列，这样范围查询非常高效。当用户需要获取一系列连续键时，可以使用二分查找快速定位范围起点，然后顺序扫描即可。另外，同一个用户键的多个版本按序列号降序排列，这意味着最新版本在前，便于快速找到当前值。查询时，只需找到第一个序列号小于等于当前快照的版本，<strong>不需要完整扫描所有版本</strong>。</p><p>好了，关于排序就说到这。下面咱们结合代码来看看写入和读取的时候，是怎么拼接 key 的。</p><h2 id="写入带版本键"><a href="#写入带版本键" class="headerlink" title="写入带版本键"></a>写入带版本键</h2><p>LevelDB 写入键值对的步骤比较复杂，可以看我之前的文章：<a href="https://selfboot.cn/2025/01/24/leveldb_source_writedb/">LevelDB 源码阅读：写入键值的工程实现和优化细节</a>。简单说就是先写入 memtable，然后是 immutable memtable，最后不断沉淀(compaction)到不同层次的 SST 文件。整个过程的第一步就是写入 memtable，所以在最开始写入 memtable 的时候，就会给 key 带上版本和类型，组装成前面我们说的带版本的内部 key 格式。</p><p>这里组装 Key 的代码在 <a href="https://github.com/google/leveldb/blob/main/db/memtable.cc#L76">db&#x2F;memtable.c</a> 的 <code>MemTable::Add</code> 函数中。这里除了组装 key，还拼接了 value 部分。实现如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">MemTable::Add</span><span class="params">(SequenceNumber s, ValueType type, <span class="type">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Format of an entry is concatenation of:</span></span><br><span class="line">  <span class="comment">//  key_size     : varint32 of internal_key.size()</span></span><br><span class="line">  <span class="comment">//  key bytes    : char[internal_key.size()]</span></span><br><span class="line">  <span class="comment">//  tag          : uint64((sequence &lt;&lt; 8) | type)</span></span><br><span class="line">  <span class="comment">//  value_size   : varint32 of value.size()</span></span><br><span class="line">  <span class="comment">//  value bytes  : char[value.size()]</span></span><br><span class="line">  <span class="type">size_t</span> key_size = key.<span class="built_in">size</span>();</span><br><span class="line">  <span class="type">size_t</span> val_size = value.<span class="built_in">size</span>();</span><br><span class="line">  <span class="type">size_t</span> internal_key_size = key_size + <span class="number">8</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">size_t</span> encoded_len = <span class="built_in">VarintLength</span>(internal_key_size) +</span><br><span class="line">                             internal_key_size + <span class="built_in">VarintLength</span>(val_size) +</span><br><span class="line">                             val_size;</span><br><span class="line">  <span class="type">char</span>* buf = arena_.<span class="built_in">Allocate</span>(encoded_len);</span><br><span class="line">  <span class="type">char</span>* p = <span class="built_in">EncodeVarint32</span>(buf, internal_key_size);</span><br><span class="line">  std::<span class="built_in">memcpy</span>(p, key.<span class="built_in">data</span>(), key_size);</span><br><span class="line">  p += key_size;</span><br><span class="line">  <span class="built_in">EncodeFixed64</span>(p, (s &lt;&lt; <span class="number">8</span>) | type);</span><br><span class="line">  p += <span class="number">8</span>;</span><br><span class="line">  p = <span class="built_in">EncodeVarint32</span>(p, val_size);</span><br><span class="line">  std::<span class="built_in">memcpy</span>(p, value.<span class="built_in">data</span>(), val_size);</span><br><span class="line">  <span class="built_in">assert</span>(p + val_size == buf + encoded_len);</span><br><span class="line">  table_.<span class="built_in">Insert</span>(buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这里同一个用户键的多次写入会产生多个版本，每个版本都有唯一的 sequence number。用户键一旦被转换为内部键，后续所有处理过程都基于这个内部键进行。包括 MemTable 转为 Immutable MemTable，SST 文件写入，SST 文件合并等。</p><p>这里 Add 函数中，在 internal_key 内部键的前面其实也保存了整个内部键的长度，然后把长度和内部键拼接起来，一起插入到了 MemTable 中。这样的 key 其实是 memtable_key，后续在读取的时候，也是用 memtable_key 来在 memtable 中查找的。</p><p><strong>这里为什么要保存长度呢</strong>？我们知道 Memtable 中的 SkipList 使用 const char* 指针作为键类型，但这些指针只是指向内存中某个位置的裸指针。当跳表的比较器需要比较两个键时，它需要知道每个键的确切范围，也就是起始位置和结束位置。如果直接使用 internal key，就没有明确的方法知道一个 internal key 在内存中的确切边界。加上长度信息后，就可以快速定位到每个键的边界，从而进行正确的比较。</p><h2 id="读取键值过程"><a href="#读取键值过程" class="headerlink" title="读取键值过程"></a>读取键值过程</h2><p>接下来看看读取键值的过程。在读取键值的时候，会先把用户键转为内部键，然后进行查找。不过这里首先面临一个问题是，序列号要用哪个呢。回答这个问题前，我们先来看读取键常用的的方法，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::string newValue;</span><br><span class="line">status = db-&gt;<span class="built_in">Get</span>(leveldb::<span class="built_in">ReadOptions</span>(), <span class="string">&quot;key500&quot;</span>, &amp;newValue);</span><br></pre></td></tr></table></figure><p>这里有个 ReadOptions 参数，里面会封装一个 Snapshot 快照对象。这里的快照你可以理解为数据库在某个时间点的状态，里面有这个时间点之前所有的数据，但不会包含这个时间点之后的写入。</p><p>其实这里快照的核心实现就是保存某个时间点的最大序列号，读取的时候，会用这个序列号来组装内部键。读的时候，分两种情况，如果没有指定 snapshot，使用当前最新的 sequence number。如果使用了之前保存下来的 snapshot，则会使用 snapshot 的序列号。</p><p>之后会根据快照序列号和用户键组装，这里先定义了一个 LookupKey 对象，用来封装查找时候使用内部键的一些常用操作。代码在 <a href="https://github.com/google/leveldb/blob/main/db/dbformat.h#L184">db&#x2F;dbformat.h</a> 中，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A helper class useful for DBImpl::Get()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LookupKey</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Initialize *this for looking up user_key at a snapshot with</span></span><br><span class="line">  <span class="comment">// the specified sequence number.</span></span><br><span class="line">  <span class="built_in">LookupKey</span>(<span class="type">const</span> Slice&amp; user_key, SequenceNumber sequence);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">LookupKey</span>(<span class="type">const</span> LookupKey&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  LookupKey&amp; <span class="keyword">operator</span>=(<span class="type">const</span> LookupKey&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  ~<span class="built_in">LookupKey</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return a key suitable for lookup in a MemTable.</span></span><br><span class="line">  <span class="function">Slice <span class="title">memtable_key</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">Slice</span>(start_, end_ - start_); &#125;</span><br><span class="line">  <span class="comment">// Return an internal key (suitable for passing to an internal iterator)</span></span><br><span class="line">  <span class="function">Slice <span class="title">internal_key</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">Slice</span>(kstart_, end_ - kstart_); &#125;</span><br><span class="line">  <span class="comment">// Return the user key</span></span><br><span class="line">  <span class="function">Slice <span class="title">user_key</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">Slice</span>(kstart_, end_ - kstart_ - <span class="number">8</span>); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 LookupKey 的构造函数中，会根据传入的 user_key 和 sequence 来组装内部键，具体代码在 <a href="https://github.com/google/leveldb/blob/main/db/dbformat.cc#L117">db&#x2F;dbformat.cc</a> 中。后续在 memtable 中搜索的时候，用的 memtable_key，然后在 SST 中查找的时候，用的 internal_key。这里 memtable_key 就是我们前面说的，在 internal_key 的前面加上了长度信息，方便在 SkipList 中快速定位到每个键的边界。</p><p>这里在 memtable 和 immutable memtable 中找不到的话，会去 SST 中查找。SST 的查找就相当复杂一些，涉及多版本数据的管理，后续我会专门写文章来介绍这里的读取过程。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇对 MVCC 的讲解还比较浅显，介绍了大概的概念，以及重点讲了下读取和写入过程中如何对序列号进行处理的过程。并没有深入数据多版本管理，以及旧版本数据回收清理的过程。后面文章再深入这些话题。</p><p>总的来说，LevelDB 通过在键值中引入版本号，实现了多版本并发控制。通过 snapshot 来实现读取隔离，写入永远创建新版本。对于读操作来说，不需要加锁，可以并发读取。对于写操作来说，需要加锁，保证写入的顺序。</p><p>这种设计提供了很好的并发性能，保证了读取的一致性，同时减少了锁冲突。不过代价是存储空间的额外开销，以及需要保存多个版本带来的代码复杂度。</p>]]></content>
    
    
    <summary type="html">本文深入剖析LevelDB如何通过MVCC实现并发控制，详细解读了带版本键的数据结构设计、排序规则以及读写过程的实现细节。文章介绍了LevelDB如何通过在键中嵌入序列号和类型信息，实现多版本数据管理，使读操作无需加锁即可获取一致性视图，同时写操作创建新版本而非覆盖现有数据。通过实际代码分析，展示了内部键的排序方法、Snapshot机制的工作原理，以及键值读写过程中的版本控制逻辑，帮助读者理解现代数据库系统并发控制的实际工程实现。</summary>
    
    
    
    <category term="源码剖析" scheme="https://selfboot.cn/categories/%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="LevelDB" scheme="https://selfboot.cn/tags/LevelDB/"/>
    
  </entry>
  
  
  
  <entry>
    <title>使用 Cursor 深度体验 3 个 MCP Server，惊艳但并不实用?</title>
    <link href="https://selfboot.cn/2025/05/23/mcp_user_report/"/>
    <id>https://selfboot.cn/2025/05/23/mcp_user_report/</id>
    <published>2025-05-23T11:39:14.000Z</published>
    <updated>2025-06-10T13:51:57.714Z</updated>
    
    <content type="html"><![CDATA[<p>大语言模型刚出来的时候，只是通过预训练的模型来生成回答内容。这个时候的模型有两个主要的缺点：</p><ol><li>有些数据它不知道，比如 2024 年 3 月训练的模型，就不知道 2024 年 5 月的事情；</li><li>没法使用外部工具。这里的工具我们可以等效理解为函数调用，比如我有个发表文章的工具函数，我没法用自然语言让大模型来帮我调用这个函数。</li></ol><p>为了解决这两个问题，OpenAI 最先在模型中支持了 <code>function calling</code> 功能，他们在这篇博客: <a href="https://openai.com/index/function-calling-and-other-api-updates/">Function calling and other API updates</a> 有介绍。</p><h2 id="背景：理解-Function-Calling"><a href="#背景：理解-Function-Calling" class="headerlink" title="背景：理解 Function Calling"></a>背景：理解 Function Calling</h2><p>这时候，我们就可以告诉模型，我有这么几个工具，每个工具需要什么参数，然后能做什么事情，输出什么内容。当模型收到具体任务的时候，会帮我们选择合适的工具，并解析出参数。之后我们可以执行相应的工具，拿到结果。并可以接着循环这个过程，让 AI 根据工具结果继续决定往下做什么事情。</p><p>我在网上找了个动图，可以来理解下有了 function calling 后，做事情的流程：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_functioncalling.webp" alt="理解 function calling过程"></p><span id="more"></span><p>当然这里大模型只是根据我们给的工具列表，选择合适的工具，并解析出参数。它不能直接去调用工具，我们需要<strong>编程实现工具调用部分</strong>，可以参考 OpenAI 的 <a href="https://platform.openai.com/docs/guides/function-calling?api-mode=responses">Function calling 文档</a>。</p><h2 id="为什么又引入了-MCP"><a href="#为什么又引入了-MCP" class="headerlink" title="为什么又引入了 MCP"></a>为什么又引入了 MCP</h2><p>只有 function calling 已经能做很多事了，派生了不少有意思的项目，比如 <a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a>，可以说是最早的 Agent 智能体了。</p><p>但是有个问题，就是不同厂商 function calling 实现各不相同，开发者需要为每个平台单独适配。另外开发者还需要编写代码来解析 function calling 的输出，并调用相应的工具。这里面有不少工程的工作，比如失败重试、超时处理、结果解析等。</p><p>计算机领域，<strong>没有什么是不能通过加个中间层来解决的</strong>。过了一年多，随着模型能力提升，各种外部工具的丰富，<a href="https://www.anthropic.com/news/model-context-protocol">Anthropic 在2024年11月25日推出了 MCP 协议</a>，引入了 MCP Client 和 MCP Server 这个中间层，来解决解决 LLM 应用与外部数据源和工具之间通信的问题。</p><p>当然其实这中间也有一些其他方案，来赋予模型调用外部工具的能力，比如 OpenAI 推出的 <a href="https://openai.com/index/introducing-the-gpt-store/">ChatGPT Store</a>，曾经也火了一阵子的 <a href="https://chatgpt.com/gpts">GTPs</a>，不过目前似乎很少看到人用了。</p><p>目前比较流行的就是 MCP 了，这里有个图，可以帮助你理解：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_whatismcp.webp" alt="理解什么是 MCP"></p><p>咱们这篇文章主要是介绍实用体验，所以关于背景的交代就到这里。如果对 MCP 的开发感兴趣，可以看<a href="https://modelcontextprotocol.io/introduction">官方文档</a>，介绍的还是十分详细的。</p><h2 id="Cursor-MCP-使用方法"><a href="#Cursor-MCP-使用方法" class="headerlink" title="Cursor MCP 使用方法"></a>Cursor MCP 使用方法</h2><p>在使用之前，我先简单介绍下 Cursor 使用 MCP 的方法。Cursor 接入 MCP 还是挺方便的，对于大部分不需要密钥的 MCP Server，基本一个配置就能接入。现在 MCP 发展还挺快，所以建议大家直接去看 <a href="https://docs.cursor.com/context/model-context-protocol">Cursor 的官方文档</a>，获取最新信息。网上不少教你如何配置的文章，其实都过时了。</p><p>这里我给大家介绍下配置的整体思想，方便你理解文档。Cursor 在这里相当于 AI 应用，它内置了 MCP Client，所以你不用管 Client 部分了。你只需要告诉他你有哪些 MCP Server，然后在会话聊天中 Cursor 会自动调用工具并使用它的结果。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_understand.webp" alt="MCP 整体理解图"></p><p>先祭出上面这张图，方便你理解。目前大部分 AI 应用都是用 json 文件来配置 MCP Server 的，比如 Claude Desktop。Cursor 也是如此，它支持全局配置(<code>~/cursor/mcp.json</code>)，也可以在项目中(<code>.cursor/mcp.json</code>) 配置。</p><p>目前 Cursor 支持本地 MCP CLI Stdio Server 和远程 MCP SSE Server 两种方式，关于 SSE 可以参考我之前的文章<a href="https://selfboot.cn/2024/05/19/stream_sse_chunk/">结合实例理解流式输出的几种实现方法</a>。本地的 CLI 方式，其实就是在本地机器启动一个 Server 进程，然后 Cursor 通过标准输入输出来和这个本地进程交互。</p><p>这里本地的 Server 支持 Python，Node 服务，也支持 Docker 容器。不过前提是<strong>本地机器已经安装了对应的语言环境，能跑起来相应的启动命令</strong>。这 3 种方式，我都给了一个例子：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npx @browsermcp/mcp@latest</span><br><span class="line">uvx mcp-server-browser-use@latest</span><br><span class="line">docker run -i --<span class="built_in">rm</span> -e GITHUB_PERSONAL_ACCESS_TOKEN ghcr.io/github/github-mcp-server</span><br></pre></td></tr></table></figure><p>有时候 MCP Server 里面还需要一些配置，比如 Github 的 API 密钥，这时候就需要你手动配置了。提醒下你要把密钥配置到环境变量中，<strong>千万不要把密钥上传到代码仓库</strong>哦。</p><p>具体到某个 MCP Server，你可以参考它的文档，看如何配置，应该没什么难度。配置好 json 后，Cursor 会自动识别，你可以打开这个 MCP Server，过一会看到绿色标记和列出来的工具，就说明配置成功了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_configsucc.webp" alt="Cursor 配置 MCP Server 成功"></p><p>接下来终于到重头戏了，咱们来体验下 MCP 的实际效果。</p><h2 id="MCP-体验一：网页自动操作"><a href="#MCP-体验一：网页自动操作" class="headerlink" title="MCP 体验一：网页自动操作"></a>MCP 体验一：网页自动操作</h2><p>之前就经常想着让 AI 来自动化执行一些网页任务。比如自动去某个站点搜索、浏览指定主题的内容，进行回复，或者导出一些有意义的内容。于是试了下微软的无头 playwright MCP Server，给了它一个比较复杂的任务:</p><blockquote><p>帮我打开淘宝，搜索苹果手机，找到最新款的苹果手机，给出店铺销量最高的几家，并导出每家店铺的销量和价格。</p></blockquote><p>确实如期打开了淘宝，并真的找到了搜索框，输入了苹果手机，如图:</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_taobaocase.webp" alt="MCP 体验一：网页自动操作"></p><p>但是后面弹了一个登录框，Claude 3.7 在这里卡了很久，也没解决。跑了一阵子，最后的输出是这样的：</p><blockquote><p>我注意到我们看到了一个登录弹窗，这可能是因为淘宝网站要求用户登录才能查看详细搜索结果。这是淘宝网站的常见安全措施，特别是对于非登录用户通过自动化工具访问时。<br>让我尝试取消登录弹窗，点击关闭按钮：<br>我们看到点击关闭按钮后，淘宝网站依然要求登录才能查看搜索结果。淘宝网站对非登录用户有严格的安全限制，特别是使用自动化工具访问时。<br>由于需要登录才能查看详细的苹果手机信息，我可以尝试使用其他方式获取有关苹果手机的信息。例如，我可以使用网络搜索查找有关最新款苹果手机及其销量和价格信息的公开数据：</p></blockquote><p>最后开始联网搜索，和我本意差的有点远。这里登录态确实不好处理，我找了另一个 <a href="https://browsermcp.io/">MCP Server</a>，它支持在本地浏览器中运行，这样可以登录后再让 AI 来操作。这个工具的原理是，在本地浏览器安装一个插件，然后 MCP Server 来控制本地浏览器。</p><p>使用下来，目前登录态是没问题了，但有些网站有部分防爬的功能，页面元素做了些保护，这个 MCP Server 还没法完美的操控，比如没法成功点击按钮，另外滚动起来也是很卡顿。</p><p>其实目前 LLM 操控浏览器还是有不少难度的，最近一个比较火的 <a href="https://browser-use.com/">Browser Use</a> 项目，它除了用 HTML 元素，还尝试用视觉元素来操控浏览器。整体前景会好一些，等我有 Token 了再来深度体验下这个。</p><h2 id="MCP-体验二：Github-仓库信息分析"><a href="#MCP-体验二：Github-仓库信息分析" class="headerlink" title="MCP 体验二：Github 仓库信息分析"></a>MCP 体验二：Github 仓库信息分析</h2><p>再来试试 Cursor 官方例子中的 <a href="https://github.com/github/github-mcp-server">Github MCP Server</a>，它支持搜索仓库、代码、issue，创建 PR 等。我想到一个场景就是，遇到一个火的项目，可以先让 AI 总结下目前比较火的 PR 或者 Issue，然后看看有没有可以贡献的地方。当然了，如果 AI 找到有价值的 Issue，然后再分析代码，给出解决方案，并自动提交代码，那这个价值就更大了。</p><p>当然，咱先拆分问题，来个低难度的信息收集：</p><blockquote><p>LevelDB 这个项目中，有哪些讨论比较多，还没合并的 pull request 啊</p></blockquote><p>这里用的 Claude3.7，竟然有点死循环了，一直在 Call list_pull_requests 这个工具，参数也基本一样：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;owner&quot;</span><span class="punctuation">:</span> <span class="string">&quot;google&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;repo&quot;</span><span class="punctuation">:</span> <span class="string">&quot;leveldb&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;state&quot;</span><span class="punctuation">:</span> <span class="string">&quot;open&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span> <span class="string">&quot;updated&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;direction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;desc&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;perPage&quot;</span><span class="punctuation">:</span> <span class="number">30</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>查了 10 多遍，也没自动终止。PR 查不成功，我换了下查 Issue，这次还可以，用 list_issues 工具，查了 3 页，参数类似下面:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;owner&quot;</span><span class="punctuation">:</span> <span class="string">&quot;google&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;repo&quot;</span><span class="punctuation">:</span> <span class="string">&quot;leveldb&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;state&quot;</span><span class="punctuation">:</span> <span class="string">&quot;open&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span> <span class="string">&quot;comments&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;direction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;desc&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;perPage&quot;</span><span class="punctuation">:</span> <span class="number">10</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;page&quot;</span><span class="punctuation">:</span> <span class="number">3</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>最后也给出了一些结论，如图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_leveldbcase.webp" alt="Github MCP Issue 信息分析"></p><p>检查了几个，没什么大问题，这个我还是挺满意的。遇到一个大的项目，能够快速找到大家讨论多的 Issue，然后分析下，确实能帮上忙。不过我怀疑这里没找完，只有 3 页，其实一共 200 多个 Issue 呢。</p><p>然后继续聚焦其中一个 <a href="https://github.com/google/leveldb/pull/917">PR #917</a>，让他给我分析下。刚好今天 Claude 推出了 Sonnet 4 模型，用这个新的模型让他分析下。不得不说，针对这种拆解开的小的问题，AI 分析还是很强的。</p><p>先是收集了这个 PR 的评论，PR 的代码改动，然后还拉了这个 PR 提到的另外 2 个 Issue，<strong>综合了这么多信息后，给出了一个详细的分析</strong>。分析也十分给力，先是问题描述，问题背景和表现，接着是提议的解决方案，社区针对这个方案的讨论焦点，比如性能影响，作者回应等。最后还给出这个 PR 的当前状态，从 2021 年 6 月提交至今，还没合并进去。这里的分析太惊艳了，看来后面遇到一些开源项目的问题，还是可以来用下的。</p><p>这里是截图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250523_mcp_user_report_githubissue.webp" alt="Github MCP PR 信息分析"></p><p>当然看了下 Github MCP Server 的文档，这里不止是提供了读仓库，读 Issue 的能力，还有修改仓库的能力。包括提交 PR，创建 Issue，创建评论，创建标签，新建分支等。我还没来得及深入使用下这些会改动仓库的功能，等后面有机会再接着体验。</p><h2 id="MCP-体验三：图表生成"><a href="#MCP-体验三：图表生成" class="headerlink" title="MCP 体验三：图表生成"></a>MCP 体验三：图表生成</h2><p>有时候会经常根据数据生成一些好看的报表，之前还有 AI 写了一个工具，来<a href="https://gallery.selfboot.cn/zh/tools/chartrace">生成动态柱状图</a>。现在有了 MCP 后，可以试试让 AI 来生成图表。其实有不少很酷的生成图表的库，比如 echarts 这些。看了下现在没有官方的图表库，不过找到了一个 <a href="https://github.com/antvis/mcp-server-chart?tab=readme-ov-file">mcp-server-chart</a>，它支持生成 echarts 的图表。</p><p>这里有<a href="https://gallery.selfboot.cn/zh/tools/chartrace/dynamic/china_population">最近 10 年中国各省份人口变化的动态竞速图</a>，导了一份数据出来，然后试试 MCP Server 生成图表效果如何。</p><p>直接给它一份文件，然后提示：</p><blockquote><p>@china_population.csv 结合这份中国人口变化数据，生成一个 2022 年和2023 年各省份人口的柱状图</p></blockquote><p>这里用的 Claude 4 Sonnet 模型，成功调用了 mcp-server-chart 的 generate_column_chart 工具，生成了图表。不过这个工具返回的是图片 URL，需要去输出里复制出来打开才能看。其实 Cursor 支持输出图片的 Base64 编码，这样聊天里也能加载出来。工具返回的图片地址<a href="https://mdn.alipayobjects.com/one_clip/afts/img/w099SKFp0AMAAAAAAAAAAAAAoEACAQFr/original">在这</a>，效果如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250523_mcp_user_report_echart.webp" alt="MCP 生成柱状图"></p><p>然后我发现这个工具支持其他类型的图表，比如折线图，散点图，饼图等。有个图我不知道啥图，但效果还挺好的，我就截了个图给 Claude，提示：</p><blockquote><p>参考这张图，生成一个 2023 年各省人口的图</p></blockquote><p>它先分析这是一个树状图，然后帮我生成了结果，还解释了下。解释超大矩形块是广东省，占据最大面积，提现了人口第一大省的地位。生成图<a href="https://mdn.alipayobjects.com/one_clip/afts/img/6CQ6TKSrI_sAAAAAAAAAAAAAoEACAQFr/original">地址在这</a>，我这里也放出来吧：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250523_mcp_user_report_echart_treemap.webp" alt="MCP 生成人口树状图"></p><p>效果还是可以的。目前这个工具每个图表一个 Tool，支持的图表类型还是有限的。</p><h2 id="MCP-使用限制"><a href="#MCP-使用限制" class="headerlink" title="MCP 使用限制"></a>MCP 使用限制</h2><p>目前的 MCP 还是存在一些限制的，首先咱们要明确一点，MCP 协议只是加了个 Server 和 Client 的中间层，它<strong>还是要依赖 LLM 的 function calling 能力</strong>。而 function calling 会受到 LLM 的上下文长度限制，工具的描述信息，参数等都会占用 Token。</p><p>当工具数量太多或者描述复杂的时候，可能会导致 Token 不够用。另外，就算 Token 够用，如果提供的工具描述过多，也会导致模型效果下降。<a href="https://platform.openai.com/docs/guides/function-calling?api-mode=responses#token-usage">OpenAI 的文档</a>也有提到：</p><blockquote><p>Under the hood, functions are injected into the system message in a syntax the model has been trained on. This means functions count against the model’s context limit and are billed as input tokens. If you run into token limits, we suggest limiting the number of functions or the length of the descriptions you provide for function parameters.</p></blockquote><p>MCP 基于 function calling 能力，所以也有同样的限制。MCP server 如果提供了过多的工具，或者工具描述太复杂，都会影响到实际效果。</p><p>比如拿 Cursor 来说，它推荐打开的 MCP Servers 最多提供 40 个工具，太多工具的话，模型效果不好。并且有的模型也不支持超过 40 个工具。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_cursor_limit.webp" alt="Cursor MCP 工具限制"></p><h2 id="MCP-的实用价值？"><a href="#MCP-的实用价值？" class="headerlink" title="MCP 的实用价值？"></a>MCP 的实用价值？</h2><p>好了，咱们介绍完 MCP 背景以及使用方法以及限制了，最后来聊下 MCP 的实用价值。目前市面上有太多 MCP Server 了，Cursor 有个 <a href="https://cursor.directory/mcp">MCP Server 列表页</a>，有需求的话可以在这找找看。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250522_mcp_user_report_cursor_allmcps.webp" alt="MCP Server 列表"></p><p>大致看了下，觉得有些 MCP Servers 后面可能会继续尝试用一用。</p><ul><li><a href="https://github.com/mendableai/firecrawl-mcp-server">firecrawl-mcp-server</a>: 这个工具可以搜索网页，并导出网页内容。还支持搜索，深度研究以及批量爬取。感觉后面写一些文章的时候，可以用来收集参考资料。爬网页这个需求还是会有的，也有不少类似的 MCP Server，后面都可以玩玩看了。</li><li><a href="https://github.com/MiniMax-AI/MiniMax-MCP">MiniMax-MCP</a>: 最近 MiniMax 的语言合成冲到了榜首，体验了下确实很不错。有几十款音色，每个都很有特色，听起来几乎就是真人的了。这款 MCP Server 支持调用 MiniMax 的合成接口，可以用来生成一些语音内容，来尝尝鲜也是可以的。</li><li><a href="https://github.com/ClickHouse/mcp-clickhouse">mcp-clickhouse</a>: 这类 DB 操作类的 MCP Server 如果足够强大的话也不错，可以聊着天就把数据查出来了，对普通人来说足够了。再配合图表类的 MCP Server，真的就能一句话把数据可视化出来。这里不止 Clickhouse 有，Mysql，Sqlite，Redis 这些都有 MCP Server，后面可以试试。</li></ul><p>就目前试过的几款，确实有些不错的亮点功能，但还不能让我觉得有特别大的价值。尝鲜之后，也就就束之高阁了。也就 Github MCP Server 让我觉得后面可能会用得到。</p><p>不过文章还没写好 Claude Sonnet 4 模型就发布了，号称世界上最强编程模型。推理能力也有很大提升，等后面多用一段时间，才能有一个真实的体感。或许随着模型能力提升，各个 MCP Server 的持续优化，有一天终会变成大家每天都离不开的工具吧。</p><p>不知道各位有什么好的 MCP Server 使用场景吗？欢迎留言讨论。</p>]]></content>
    
    
    <summary type="html">文章详细介绍了MCP的背景起源、与OpenAI Function Calling的关系，以及如何在Cursor中配置使用MCP Server。分别体验了网页自动化操作、Github仓库信息分析、图表生成等实用场景，发现MCP在Github代码分析方面表现惊艳，但网页操作仍有局限。文章同时指出MCP的核心限制：依然依赖大模型的function calling能力，受Token数量限制影响。虽然MCP为AI工具调用提供了标准化解决方案，但目前实用价值有限，更多是技术尝鲜阶段，期待未来随着模型能力提升带来更大突破。</summary>
    
    
    
    <category term="人工智能" scheme="https://selfboot.cn/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="LLM" scheme="https://selfboot.cn/tags/LLM/"/>
    
  </entry>
  
  
  
  
  
  
  
  <entry>
    <title>LevelDB 源码阅读：写入键值的工程实现和优化细节</title>
    <link href="https://selfboot.cn/2025/01/24/leveldb_source_writedb/"/>
    <id>https://selfboot.cn/2025/01/24/leveldb_source_writedb/</id>
    <published>2025-01-24T18:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.714Z</updated>
    
    <content type="html"><![CDATA[<p>读、写键值是 KV 数据库中最重要的两个操作，LevelDB 中提供了一个 Put 接口，用于写入键值对。使用方法很简单：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Status status = leveldb::DB::<span class="built_in">Open</span>(options, <span class="string">&quot;./db&quot;</span>, &amp;db);</span><br><span class="line">status = db-&gt;<span class="built_in">Put</span>(leveldb::<span class="built_in">WriteOptions</span>(), key, value);</span><br></pre></td></tr></table></figure><p>LevelDB 最大的优点就是<strong>写入速度也非常快，可以支持很高的并发随机写</strong>。官方给过一个<a href="https://github.com/google/leveldb/tree/main?tab=readme-ov-file#write-performance">写入压力测试结果</a>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fillseq      :       1.765 micros/op;   62.7 MB/s</span><br><span class="line">fillsync     :     268.409 micros/op;    0.4 MB/s (10000 ops)</span><br><span class="line">fillrandom   :       2.460 micros/op;   45.0 MB/s</span><br><span class="line">overwrite    :       2.380 micros/op;   46.5 MB/s</span><br></pre></td></tr></table></figure><p>可以看到这里不强制要求刷磁盘的话，随机写入的速度达到 45.0 MB&#x2F;s，每秒支持写入 40 万次。如果强制要求刷磁盘，写入速度会下降不少，也能够到 0.4 MB&#x2F;s, 每秒支持写入 3700 次左右。</p><p>这里 Put 接口具体做了什么？数据的写入又是如何进行的？LevelDB 又有哪些优化？本文一起来看看。开始之前，先看一个大致的流程图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250124_leveldb_source_writedb_flow_zh.png" alt="LevelDB 写入整体流程图"></p><span id="more"></span><h2 id="LevelDB-写入-key-的-2-种方式"><a href="#LevelDB-写入-key-的-2-种方式" class="headerlink" title="LevelDB 写入 key 的 2 种方式"></a>LevelDB 写入 key 的 2 种方式</h2><p>LevelDB 支持一次写入一个键值对，也支持一次写入多个键值对。不论是单个写入，还是批量写内部都是通过 <a href="https://selfboot.cn/2025/01/13/leveldb_source_write_batch/">WriteBatch</a> 来处理。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DB::Put</span><span class="params">(<span class="type">const</span> WriteOptions&amp; opt, <span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  WriteBatch batch;</span><br><span class="line">  batch.<span class="built_in">Put</span>(key, value);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Write</span>(opt, &amp;batch);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以选择在调用 LevelDB 接口的应用层聚合写入操作，从而实现批量写入，提高写入吞吐。例如，在应用层可以设计一个缓冲机制，收集一定时间内的写入请求，然后将它们打包在一个 WriteBatch 中提交。这种方式可以减少磁盘的写入次数和上下文切换，从而提高性能。</p><p>当然也可以每次都写入单个键值，这时候 LevelDB 内部会通过 WriteBatch 来处理。如果在高并发情况下，可能会在内部合并多个写操作，然后将这批键值对写入 WAL 并更新到 memtable。</p><p>这里整体写入还是比较复杂的，本篇文章只先关注写入到 WAL 和 memtable 的过程。</p><h2 id="LevelDB-写入详细步骤"><a href="#LevelDB-写入详细步骤" class="headerlink" title="LevelDB 写入详细步骤"></a>LevelDB 写入详细步骤</h2><p>完整的写入部分代码在 <a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1205">leveldb&#x2F;db&#x2F;db_impl.cc 的 DBImpl::Write</a> 方法中，咱们一点点拆开看吧。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>&#123;</span><br><span class="line">  <span class="function">Writer <span class="title">w</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">  w.batch = updates;</span><br><span class="line">  w.sync = options.sync;</span><br><span class="line">  w.done = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">MutexLock <span class="title">l</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">  writers_.<span class="built_in">push_back</span>(&amp;w);</span><br><span class="line">  <span class="keyword">while</span> (!w.done &amp;&amp; &amp;w != writers_.<span class="built_in">front</span>()) &#123;</span><br><span class="line">    w.cv.<span class="built_in">Wait</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (w.done) &#123;</span><br><span class="line">    <span class="keyword">return</span> w.status;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>开始部分把 WriteBatch 和 sync 参数赋值给 Writer 结构体，然后通过一个 writers_ 队列来管理多个 Writer 结构体。这两个结构体和队列在整个写入过程中还是挺重要的，先来看看。</p><h3 id="Writer-结构和处理队列"><a href="#Writer-结构和处理队列" class="headerlink" title="Writer 结构和处理队列"></a>Writer 结构和处理队列</h3><p>这里 <a href="https://github.com/google/leveldb/blob/main/db/db_impl.h#L186">writers_</a> 是一个 <code>std::deque&lt;Writer*&gt;</code> 类型的队列，用于管理多个 Writer 结构体。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::deque&lt;Writer*&gt; writers_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br></pre></td></tr></table></figure><p>这里队列用 <code>GUARDED_BY(mutex_)</code> 装饰，表示队列的访问需要通过 <code>mutex_</code> 互斥锁来保护。这个用到了 Clang 的静态线程安全分析功能，可以参考我之前的文章 <a href="https://selfboot.cn/2025/01/02/leveldb_source_thread_anno/">LevelDB 源码阅读：利用 Clang 的静态线程安全分析</a></p><p>这里 Writer 结构体定义如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">DBImpl</span>::Writer &#123;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">Writer</span><span class="params">(port::Mutex* mu)</span></span></span><br><span class="line"><span class="function">      : batch(nullptr), sync(false), done(false), cv(mu) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  Status status;</span><br><span class="line">  WriteBatch* batch;</span><br><span class="line">  <span class="type">bool</span> sync;</span><br><span class="line">  <span class="type">bool</span> done;</span><br><span class="line">  port::CondVar cv;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里 Writer 结构体封装了不少参数，其中最重要是一个 WriteBatch 指针，记录了每个 WriteBatch 写请求的数据。然后用一个 status 用来记录每个 WriteBatch 写请求的错误状态。</p><p>此外，用一个 sync <strong>来标记每个 WriteBatch 写请求是否需要立马刷到磁盘中</strong>。默认是 false，不强制刷磁盘，如果系统崩溃，可能会丢掉部分还没来得及写进磁盘的数据。如果打开了 sync 选项，每次写入都会立马刷到磁盘，整体写入耗时会上涨，但是可以保证只要写入成功，数据就不会丢失。关于刷磁盘文件的更多细节，可以参考我之前的文章<a href="https://selfboot.cn/2024/08/02/leveldb_source_env_posixfile/">LevelDB 源码阅读：Posix 文件操作接口实现细节</a>。</p><p>还有一个 **done 则用来标记每个 WriteBatch 的写请求是否完成。**这里因为内部可能会合并写入多个 WriteBatch，当本次写入请求被合并到其他批次写入后，本次请求标记完成，就不需要再处理了。从而避免重复执行，提高并发的写入效率。</p><p>为了<strong>实现等待和通知，这里还有一个条件变量 cv，用于支持多个写请求的批量处理，并实现多个写请求的同步</strong>。写入的时候，多个线程可以同时提交写入请求，每个写请求都会先被放入写入队列。<strong>实际写入过程，则是串行化写入，同一时刻只有一批写入过程在执行</strong>。每次会从队列中取出队首的写请求，如果此时队列中还有其他等待的写任务，则会被合并为一个批次一起处理。在当前批次的写入请求处理过程中，后续来的请求进入队列后都需要等待。当前批次的请求处理完成后，会通知后面进入队列在等待中的写请求。</p><p>结合这里的介绍，应该能看懂前面 Write 方法开始部分代码的含义了。对于每个写入请求，都会先创建一个 Writer 结构体，然后将其放入 writers_ 队列中。接下来在 while 循环中，判断当前写入请求是否完成，如果完成就会直接返回当前写入的状态结果。如果当前写入请求没在队首，则需要等待在 cv 条件变量上。</p><p>如果当前写入请求在队首，那么就需要执行实际的写入操作了，这里具体写入流程是什么样呢？</p><h3 id="预先分配空间"><a href="#预先分配空间" class="headerlink" title="预先分配空间"></a>预先分配空间</h3><p>接下来在正式写入前，要先确保有足够的空间来写入数据。这里会调用 <a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1330">MakeRoomForWrite</a> 方法，确保在进行写入操作之前，有足够的资源和空间来处理新的写入请求。它负责管理内存表（memtable）的使用情况、控制 Level 0 文件的数量，并在需要时触发后台压缩。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// REQUIRES: this thread is currently at the front of the writer queue</span></span><br><span class="line"><span class="function">Status <span class="title">DBImpl::MakeRoomForWrite</span><span class="params">(<span class="type">bool</span> force)</span> </span>&#123;</span><br><span class="line">  mutex_.<span class="built_in">AssertHeld</span>();</span><br><span class="line">  <span class="built_in">assert</span>(!writers_.<span class="built_in">empty</span>());</span><br><span class="line">  <span class="type">bool</span> allow_delay = !force;</span><br><span class="line">  Status s;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!bg_error_.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">      <span class="comment">// Yield previous error</span></span><br><span class="line">      s = bg_error_;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里开始部分是一些验证部分，用 AssertHeld 验证当前线程必须持有 mutex_ 互斥锁，并且 writers_ 队列不能为空。接着会判断 bg_error_ 是否为空，如果不为空，则直接返回 bg_error_ 状态。在下文中会看到，如果写入 WAL 刷磁盘失败，就会设置 bg_error_ ，这样会让后续的写入都直接返回失败。</p><p>在 while 循环中，接着是一系列 if 分支检查，处理不同情况。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (allow_delay &amp;&amp; versions_-&gt;<span class="built_in">NumLevelFiles</span>(<span class="number">0</span>) &gt;=</span><br><span class="line">                                  config::kL0_SlowdownWritesTrigger) &#123;</span><br><span class="line">      <span class="comment">// We are getting close to hitting a hard limit on the number of</span></span><br><span class="line">      <span class="comment">// L0 files.  Rather than delaying a single write by several</span></span><br><span class="line">      <span class="comment">// seconds when we hit the hard limit, start delaying each</span></span><br><span class="line">      <span class="comment">// individual write by 1ms to reduce latency variance.  Also,</span></span><br><span class="line">      <span class="comment">// this delay hands over some CPU to the compaction thread in</span></span><br><span class="line">      <span class="comment">// case it is sharing the same core as the writer.</span></span><br><span class="line">      mutex_.<span class="built_in">Unlock</span>();</span><br><span class="line">      env_-&gt;<span class="built_in">SleepForMicroseconds</span>(<span class="number">1000</span>);</span><br><span class="line">      allow_delay = <span class="literal">false</span>;  <span class="comment">// Do not delay a single write more than once</span></span><br><span class="line">      mutex_.<span class="built_in">Lock</span>();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>首先当 Level 0 文件数量接近 kL0_SlowdownWritesTrigger&#x3D;8 阈值时，<strong>暂时释放锁，延迟 1 毫秒，以减缓写入速度</strong>。当然这里只允许延迟一次，避免长时间阻塞单个写入。这里之所以设置一个小的 Level 0 文件数量阈值，是为了防止 Level 0 文件太多后，到达系统瓶颈后，后续写入卡太长时间。在没到瓶颈前，就开始把延迟平摊到每个请求上，从而减缓压力。这里的注释也写的很清楚，上面也都贴出来了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (!force &amp;&amp;</span><br><span class="line">           (mem_-&gt;<span class="built_in">ApproximateMemoryUsage</span>() &lt;= options_.write_buffer_size)) &#123;</span><br><span class="line">  <span class="comment">// There is room in current memtable</span></span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>接着这里判断如果当前 memtable 的使用量没超过最大容量，就直接返回了。这里 write_buffer_size 是 memtable 的最大容量，默认是 4MB。这里可以调整配置，如果大一点的话，会在内存缓存更多数据，提高写入的性能，但是会占用更多内存，并且下次打开 db 的时候，恢复时间也会更长些。</p><p>接下来有两种情况，是当前没有地方可以写入，因此需要等待了。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (imm_ != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">  <span class="comment">// We have filled up the current memtable, but the previous</span></span><br><span class="line">  <span class="comment">// one is still being compacted, so we wait.</span></span><br><span class="line">  <span class="built_in">Log</span>(options_.info_log, <span class="string">&quot;Current memtable full; waiting...\n&quot;</span>);</span><br><span class="line">  background_work_finished_signal_.<span class="built_in">Wait</span>();</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (versions_-&gt;<span class="built_in">NumLevelFiles</span>(<span class="number">0</span>) &gt;= config::kL0_StopWritesTrigger) &#123;</span><br><span class="line">  <span class="comment">// There are too many level-0 files.</span></span><br><span class="line">  <span class="built_in">Log</span>(options_.info_log, <span class="string">&quot;Too many L0 files; waiting...\n&quot;</span>);</span><br><span class="line">  background_work_finished_signal_.<span class="built_in">Wait</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一种情况是不可变的 memtable 还在写入中，因此需要等待它写入完成。LevelDB 会维护两个 memtable，一个是当前可以写入的 memtable mem_，一个是不可变的 memtable imm_。每次写满一个 mem_ 后，就会把它转为 imm_ 然后刷数据到磁盘。如果 imm_ 还没完成刷磁盘，那么就必须等待刷完后才能把现有的 mem_ 转为新的 imm_。</p><p>第二种情况是 Level 0 文件数量太多，需要等待压缩完成。LevelDB 配置了 Level 0 文件数量的阈值 kL0_StopWritesTrigger，默认是 12，当 Level 0 文件数量超过这个阈值时，那么当前写入请求就需要等待。因为 Level 0 层的文件之间没有全局排序的保证，多个 Level 0 文件可能包含重叠的键范围。对于读来说，查询操作需要在所有 L0 文件中查找，文件数量过多会增加读取延迟。对于写来说，文件数量多，后台压缩的工作量也会增加，影响整体系统性能。所以这里强制控制 Level 0 的文件数量，达到阈值后就直接不给写入。</p><p>接下来的情况就是不可变的 imm_ 为空，同时 mem_ 也没足够空间，这时候要做的事情比较多：</p><ol><li><strong>创建新日志文件</strong>：生成新的日志文件号，并尝试创建新的 writable file 作为 WAL（Write-Ahead Log）。如果失败，重用文件号并退出循环，返回错误状态。</li><li><strong>关闭旧日志文件</strong>：关闭当前日志文件。如果关闭失败，记录后台错误，阻止后续写入操作。</li><li><strong>更新日志文件指针</strong>：设置新的日志文件指针，更新日志编号，创建新的 log::Writer 进行写入。</li><li><strong>转换 memtable</strong>：将当前 memtable 转换为不可变 memtable（imm_），并创建新的 memtable 进行写入。通过 has_imm_.store(true, std::memory_order_release) 标记有不可变 memtable 存在。</li><li>触发后台压缩：调用 MaybeScheduleCompaction()，触发后台压缩任务，处理不可变 memtable。</li></ol><p>这里可以看到 <strong>memtable 和 WAL 文件一一对应的，每个 memtable 对应一个 WAL 文件，WAL 文件记录写入 memtable 的所有操作，当 memtable 满时，同时切换 WAL 文件</strong>。同一时刻，前台 memtable 和新的 WAL 日志文件处理新的请求，同时后台的 imm_ 和旧的 WAL 文件处理压缩任务。等压缩完成，就可以删除旧的 WAL 文件了。</p><h3 id="合并写入任务"><a href="#合并写入任务" class="headerlink" title="合并写入任务"></a>合并写入任务</h3><p>接着是合并写入的逻辑，<a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1224">核心代码</a>如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">uint64_t</span> last_sequence = versions_-&gt;<span class="built_in">LastSequence</span>();</span><br><span class="line">Writer* last_writer = &amp;w;</span><br><span class="line"><span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; updates != <span class="literal">nullptr</span>) &#123;  <span class="comment">// nullptr batch is for compactions</span></span><br><span class="line">  WriteBatch* write_batch = <span class="built_in">BuildBatchGroup</span>(&amp;last_writer);</span><br><span class="line">  WriteBatchInternal::<span class="built_in">SetSequence</span>(write_batch, last_sequence + <span class="number">1</span>);</span><br><span class="line">  last_sequence += WriteBatchInternal::<span class="built_in">Count</span>(write_batch);</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">   <span class="comment">// ... 具体写入到 WAL 和 memtable </span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (write_batch == tmp_batch_) tmp_batch_-&gt;<span class="built_in">Clear</span>();</span><br><span class="line"></span><br><span class="line">  versions_-&gt;<span class="built_in">SetLastSequence</span>(last_sequence);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先是获取当前全局的 sequence 值，这里 <strong>sequence 用来记录写入键值对的版本号，全局单调递增</strong>。每个写入请求都会被分配一个唯一的 sequence 值，通过版本号机制来实现 MVCC 等特性。在写入当前批次键值对的时候，会先设置 sequence 值，写入成功后，还会更新 last_sequence 值。</p><p>为了<strong>提高写入并发性能，每次写入的时候，不止需要写队首的任务，还会尝试合并队列中后续的写入任务</strong>。这里合并的逻辑放在 <a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1280">BuildBatchGroup</a> 中，主要是遍历整个写入队列，<strong>在控制整体批次的大小，以及保证刷磁盘的级别情况下，不断把队列后面的写入任务合并到队首的写入任务</strong>中。整体构建好的写入批次，会放到一个临时的对象 tmp_batch_ 中，在完整的写入操作完成后，会清空 tmp_batch_ 对象。</p><p>我们提到的每个写入任务其实封装为了一个 WriteBatch 对象，该类的实现支持了不同写入任务合并，以及获取任务的大小等。相关细节实现可以参考我前面的文章 <a href="https://selfboot.cn/2025/01/13/leveldb_source_write_batch/">LevelDB 源码阅读：如何优雅地合并写入和删除操作</a>。</p><p>上面代码其实忽略了核心的写入到 WAL 和 memtable 的逻辑，下面来看看这部分的实现。</p><h3 id="写入到-WAL-和-memtable"><a href="#写入到-WAL-和-memtable" class="headerlink" title="写入到 WAL 和 memtable"></a>写入到 WAL 和 memtable</h3><p>LevelDB 中写入键值对，会先写 WAL 日志，然后写入到 memtable 中。WAL 日志是 LevelDB 中实现数据恢复的关键，memtable 则是 LevelDB 中实现内存缓存和快速查询的关键。写入关键代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Add to log and apply to memtable.  We can release the lock</span></span><br><span class="line"><span class="comment">// during this phase since &amp;w is currently responsible for logging</span></span><br><span class="line"><span class="comment">// and protects against concurrent loggers and concurrent writes</span></span><br><span class="line"><span class="comment">// into mem_.</span></span><br><span class="line">&#123;</span><br><span class="line">  mutex_.<span class="built_in">Unlock</span>();</span><br><span class="line">  status = log_-&gt;<span class="built_in">AddRecord</span>(WriteBatchInternal::<span class="built_in">Contents</span>(write_batch));</span><br><span class="line">  <span class="type">bool</span> sync_error = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; options.sync) &#123;</span><br><span class="line">    status = logfile_-&gt;<span class="built_in">Sync</span>();</span><br><span class="line">    <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">      sync_error = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">    status = WriteBatchInternal::<span class="built_in">InsertInto</span>(write_batch, mem_);</span><br><span class="line">  &#125;</span><br><span class="line">  mutex_.<span class="built_in">Lock</span>();</span><br><span class="line">  <span class="keyword">if</span> (sync_error) &#123;</span><br><span class="line">    <span class="comment">// The state of the log file is indeterminate: the log record we</span></span><br><span class="line">    <span class="comment">// just added may or may not show up when the DB is re-opened.</span></span><br><span class="line">    <span class="comment">// So we force the DB into a mode where all future writes fail.</span></span><br><span class="line">    <span class="built_in">RecordBackgroundError</span>(status);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里<strong>在写入到 WAL 和 memtable 的时候，会先释放 mutex_ 互斥锁，写入完成后，再重新加锁</strong>。注释也专门解释了下，因为当前队首 <code>&amp;w</code> 正在负责写入 WAL 和 memtable，后续的写入调用，可以拿到 mutex_ 互斥锁，因此可以完成入队操作。但是因为不是队首，需要等在条件变量上，只有当前任务处理完成，才有机会执行。所以<strong>写入 WAL 和 memtable 的过程，虽然释放了锁，但整体还是串行化写入的</strong>。WAL 和 memtable 本身也不需要保证线程安全。</p><p>不过因为写 WAL 和 memtable 相对耗时，释放锁之后，其他需要用到 mutex_ 的地方，都可以拿到锁继续执行了，整体提高了系统的并发。</p><p>WAL（Write-Ahead Logging）是一种日志记录机制，它允许在数据写入磁盘之前，先记录日志。<strong>WAL 日志是追加写入，磁盘的顺序 IO 性能优于随机 IO 性能，因此追加写入一般效率比较高</strong>。写入 WAL 成功后，再把数据放到 memtable 中，memtable 是内存结构，写入效率也很高，等在内存积累到一定量级，再写入磁盘。如果系统崩溃重启，内存中 memtable 的数据可能会丢失，但是通过 WAL 日志，可以重放写入操作，从而恢复数据状态，确保数据的完整性。</p><p>这里具体写入，只是简单的调用 log::Writer 对象 log_ 的 AddRecord 方法来写入 WriteBatch 数据。log::Writer 会把这里的数据进行组织，然后在适当的时机写入磁盘，详细实现可以参考我前面的文章<a href="https://selfboot.cn/2024/08/14/leveldb_source_wal_log/">LevelDB 源码阅读：读写 WAL 日志保证持久性</a>。</p><p>当然，如果写入的时候带了 sync&#x3D;true，那么这里写入 WAL 成功后，会调用 logfile_-&gt;Sync() 方法，强制刷磁盘。这里稍微补充说明下，这里<strong>往文件里写内容是会通过系统调用 <code>write</code> 来完成，这个系统调用返回成功，并不保证数据一定被写入磁盘。文件系统一般会把数据先放到缓冲区，然后根据情况，选择合适的时机刷到磁盘中</strong>。要保证一定刷到磁盘中去，则需要另外的系统调用，不同平台有不同的接口，具体可以参考我之前的文章<a href="https://selfboot.cn/2024/08/02/leveldb_source_env_posixfile/">LevelDB 源码阅读：Posix 文件操作接口实现细节</a>。</p><p>如果强制刷磁盘过程发生错误，那么这里会调用 RecordBackgroundError 方法，记录错误状态到 bg_error_ 中，这样后续所有的写入操作都会返回失败。</p><p>在写入 WAL 成功后，就可以写入 memtable 了。这里调用 WriteBatchInternal::InsertInto 方法，把 WriteBatch 数据插入到 memtable 中。关于 memtable 的实现，我后面文章会详细介绍。</p><h3 id="更新批次写任务的状态"><a href="#更新批次写任务的状态" class="headerlink" title="更新批次写任务的状态"></a>更新批次写任务的状态</h3><p>写入批次完成后，就需要更新批次写任务的状态，从 writers_ 队列的前端取出最先入队的 Writer 对象，然后开始遍历，直到批次中的最后一个写入任务。这里更新所有已经完成任务的状态，然后唤醒所有等待的写入任务。<a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1259">核心实现</a>如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">  Writer* ready = writers_.<span class="built_in">front</span>();</span><br><span class="line">  writers_.<span class="built_in">pop_front</span>();</span><br><span class="line">  <span class="keyword">if</span> (ready != &amp;w) &#123;</span><br><span class="line">    ready-&gt;status = status;</span><br><span class="line">    ready-&gt;done = <span class="literal">true</span>;</span><br><span class="line">    ready-&gt;cv.<span class="built_in">Signal</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (ready == last_writer) <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Notify new head of write queue</span></span><br><span class="line"><span class="keyword">if</span> (!writers_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">  writers_.<span class="built_in">front</span>()-&gt;cv.<span class="built_in">Signal</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后如果队列中还有写入任务，则需要唤醒队首的写入任务，继续处理。至此整个写入处理完毕，可以返回给调用方写入的结果了。</p><h2 id="其他工程实现细节"><a href="#其他工程实现细节" class="headerlink" title="其他工程实现细节"></a>其他工程实现细节</h2><p>整个写入过程到此分析完了，不过还有些工程实现细节，值得一起看看。</p><h3 id="混合-sync-和非-sync-写入"><a href="#混合-sync-和非-sync-写入" class="headerlink" title="混合 sync 和非 sync 写入"></a>混合 sync 和非 sync 写入</h3><p>如果有一批写入请求，其中既有 sync 又有非 sync 的写入，那么 LevelDB 内部会怎么处理呢？</p><p>前面分析可以看到每次取出队首的写入任务后，会尝试合并队列中后续的写入任务。因为每个写入任务可以强制 sync 刷磁盘，也可以不刷，合并的时候，怎么处理这种混合不同 sync 配置的写入任务呢？</p><p>这里配置 <strong>sync&#x3D;true 的时候写入会强制刷磁盘，对于合并后的批次写入，取得是队首的 sync</strong>。<a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1237">核心代码</a>如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; updates != <span class="literal">nullptr</span>) &#123;  <span class="comment">// nullptr batch is for compactions</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    &#123;</span><br><span class="line">      mutex_.<span class="built_in">Unlock</span>();</span><br><span class="line">      status = log_-&gt;<span class="built_in">AddRecord</span>(WriteBatchInternal::<span class="built_in">Contents</span>(write_batch));</span><br><span class="line">      <span class="type">bool</span> sync_error = <span class="literal">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; options.sync) &#123;</span><br><span class="line">        status = logfile_-&gt;<span class="built_in">Sync</span>();</span><br><span class="line">        <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">          sync_error = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以，如果队首是的任务是不需要刷磁盘，那么合并的时候，就不能合并 sync&#x3D;true 的写入任务。<a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1302">核心实现代码</a>如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (; iter != writers_.<span class="built_in">end</span>(); ++iter) &#123;</span><br><span class="line">  Writer* w = *iter;</span><br><span class="line">  <span class="keyword">if</span> (w-&gt;sync &amp;&amp; !first-&gt;sync) &#123;</span><br><span class="line">    <span class="comment">// Do not include a sync write into a batch handled by a non-sync write.</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不过如果队首是 sync&#x3D;true 的写入任务，那么合并的时候，就不需要考虑被合并的写入任务的 sync 设置。因为整个合并后的批次，都会被强制刷磁盘。这样就<strong>可以保证不会降低写入的持久化保证级别，但是可以适当提升写入的持久化保证级别</strong>。当然这里提升写入的持久化级别保证，其实也并不会导致整体耗时上涨，因为这里队首一定要刷磁盘，顺带着多一点不需要刷磁盘的写入任务，也不会导致耗时上涨。</p><h3 id="优化大批量小-key-写入延迟"><a href="#优化大批量小-key-写入延迟" class="headerlink" title="优化大批量小 key 写入延迟"></a>优化大批量小 key 写入延迟</h3><p>上面实现可以看到，如果大批量并发写入的时候，写入请求会先被放入队列中，然后串行化写入。如果写入的 key 都比较小，那么从队首取出一个写入任务，然后和当前队列中的其他写入合并为一个批次。合并的时候，需要设置一个 max_size 来限制合并的 key 数量，那么这里 max_size 要设置多少合理呢？</p><p>这里 LevelDB 给了一个经验值，默认是 1 &lt;&lt; 20 个字节。但是考虑一个场景，如果写入的 key 都比较小，合并的时候，可能会合并很多 key，从而导致写入耗时变长。<strong>由于是小 key 的写入，写入耗时长的话，体验上来并不好</strong>。</p><p>所以这里加了个小优化，如果当前队首写入任务的整体 size 小于 128 &lt;&lt; 10 个字节，那么这里 max_size 就会小很多。当然，这个值应该也只是经验值，我也没找到官方具体的说明。相关代码在<br> <a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1289">BuildBatchGroup</a> 中：</p> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Allow the group to grow up to a maximum size, but if the</span></span><br><span class="line"><span class="comment">// original write is small, limit the growth so we do not slow</span></span><br><span class="line"><span class="comment">// down the small write too much.</span></span><br><span class="line"><span class="type">size_t</span> max_size = <span class="number">1</span> &lt;&lt; <span class="number">20</span>;</span><br><span class="line"><span class="keyword">if</span> (size &lt;= (<span class="number">128</span> &lt;&lt; <span class="number">10</span>)) &#123;</span><br><span class="line">  max_size = size + (<span class="number">128</span> &lt;&lt; <span class="number">10</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="写入-WAL-成功，但是-memtable-失败"><a href="#写入-WAL-成功，但是-memtable-失败" class="headerlink" title="写入 WAL 成功，但是 memtable 失败"></a>写入 WAL 成功，但是 memtable 失败</h3><p>写入过程，会先写入 WAL 日志，写成功后，才写 memtable。但这两个写入并不是原子的，如果写 WAL 失败，不回写 memtable，并且会阻塞后续所有的写入，这样是合理的，也不会有问题。</p><p>但是如果写入 WAL 日志成功，但是写入 memtable 失败的话，返回给调用方的状态是写入失败，调用可能认为写失败。但是 WAL 成功写入，并且其他流程都是正常执行，也更新了全局的 sequence。<strong>万一这时候故障，从 WAL 恢复数据的时候，会把写 memtable 失败的也恢复，这样就导致调用方认为写失败的数据，其实成功写入了</strong>。</p><p>这里自己暂时还没彻底搞明白，可能是 LevelDB 的潜在 bug，也可能是自己对整体代码还没理解透。这里尝试用 GPT O1 和 Deepseek 的 R1 深度思考分析了下，都倾向这里是 bug。Deepseek 给的思考过程也比较有意思：</p><blockquote><p>我需要确认在LevelDB的实际运行中，这种情况发生的概率有多大。MemTable的写入失败通常可能由什么原因引起？比如内存不足，或者其他不可恢复的错误？如果是暂时性的错误，LevelDB是否有重试机制？</p><p>另外，查看LevelDB的官方文档或相关讨论，是否有提到这种情况的处理方式。比如，是否在写入MemTable失败时，LevelDB会主动删除或无效化对应的WAL记录？</p><p>可能还需要考虑数据库恢复流程。当LevelDB重启时，会读取WAL并重新构建MemTable。如果某个WAL记录对应的写入在MemTable失败，但WAL存在，恢复时会再次尝试写入MemTable。如果此时条件允许（比如内存足够），写入可能成功，导致不一致。但如果原来的失败是持久性的（如数据结构错误），恢复时可能再次失败，导致数据库无法打开，从而避免不一致。</p><p>此外，用户的问题是否假设了某些特定场景？例如，MemTable写入失败但数据库没有崩溃，之后正常关闭，这时候WAL未被清除，恢复时重新应用。这种情况是否可能？</p></blockquote><p>AI 现在的深度思考能力，逻辑推理的能力还是非常强的，考虑问题比较全面。这里也欢迎读者留言讨论这个问题哈。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>文章有点长，这里简单总结下吧。LevelDB 的写入操作设计充分考虑了高并发和性能优化，通过一系列精巧的机制实现了高效的键值对写入。下面是一些值得借鉴的设计：</p><ol><li><p><strong>批量合并写入</strong>: LevelDB 通过 Writer 队列将多个写入请求合并处理，避免了频繁的磁盘 IO。每个写入请求会被放入队列，队列头部的写入请求负责合并后续请求，形成一个大的 WriteBatch。这种设计显著提高了吞吐量，尤其适合高并发的小键值对写入场景。</p></li><li><p><strong>WAL 日志处理崩溃恢复</strong>: WAL（Write-Ahead Log）：所有写入操作首先顺序写入 WAL 日志，确保数据持久性。写入 WAL 后才更新内存中的 MemTable，这种 “先日志后内存” 的设计是 LevelDB 崩溃恢复的基石。</p></li><li><p><strong>内存双缓冲机制</strong>: 当 MemTable 写满后，会转换为 Immutable MemTable 并触发后台压缩，同时创建新的 MemTable 和 WAL 文件。这<strong>种双缓冲机制避免了写入阻塞，实现了平滑的内存-磁盘数据流转</strong>。</p></li><li><p><strong>写入限流与自适应延迟</strong>: 通过 kL0_SlowdownWritesTrigger 和 kL0_StopWritesTrigger 阈值，在 Level 0 文件过多时主动引入写入延迟或暂停写入。这种 “软限流” 策略避免了系统过载后的雪崩效应。</p></li><li><p><strong>动态批次合并</strong>: 根据当前队列头部请求的大小，动态调整合并批次的最大尺寸（如小请求合并 128KB，大请求合并 1MB），在吞吐量和延迟之间取得平衡。</p></li><li><p><strong>条件变量唤醒机制</strong>: 通过 CondVar 实现高效的线程等待-通知，确保合并写入时不会长时间阻塞后续请求。</p></li><li><p><strong>混合 Sync 处理</strong>: 支持同时处理需要强制刷盘（sync&#x3D;true）和非强制刷盘的请求，优先保证队首请求的持久化级别，避免降低数据安全性。</p></li><li><p><strong>错误隔离</strong>: WAL 写入失败会标记全局错误状态 bg_error_，直接拒绝掉所有后续写请求，防止数据不一致。</p></li></ol><p>最后，欢迎大家留言讨论，一起学习 LevelDB 的实现细节。</p>]]></content>
    
    
    <summary type="html">本文深入剖析LevelDB的写入机制，详解从Put接口到WAL日志、MemTable落盘的全流程。通过源码解析揭示LevelDB实现40万次/秒高吞吐写入的奥秘：WriteBatch批量合并策略、双MemTable内存管理、WAL顺序写优化、Level0文件数动态限流等核心技术。探讨混合sync写入处理、小键值合并优化、异常场景数据一致性等工程细节，带你掌握LevelDB高性能写入的设计精髓与实现策略。</summary>
    
    
    
    <category term="源码剖析" scheme="https://selfboot.cn/categories/%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="LevelDB" scheme="https://selfboot.cn/tags/LevelDB/"/>
    
  </entry>
  
  
  
  <entry>
    <title>LevelDB 源码阅读：如何优雅地合并写入和删除操作</title>
    <link href="https://selfboot.cn/2025/01/13/leveldb_source_write_batch/"/>
    <id>https://selfboot.cn/2025/01/13/leveldb_source_write_batch/</id>
    <published>2025-01-13T22:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.713Z</updated>
    
    <content type="html"><![CDATA[<p>LevelDB 支持写入单个键值对和批量写入多个键值对，这两种操作的处理流程本质上是相同的，都会被封装进一个 WriteBatch 对象中，这样就可以提高写操作的效率。</p><p>在 LevelDB 中，WriteBatch 是通过一个简单的数据结构实现的，其中包含了一系列的写入操作。这些操作被序列化（转换为字节流）并存储在内部的一个字符串中。每个操作都包括操作类型（如插入或删除），键和值（对于插入操作）。</p><p>当 WriteBatch 被提交给数据库时，其内容被解析并应用到 WAL 日志和 memtable 中。不管 WriteBatch 中包含多少操作，它们都将作为一个整体进行处理和日志记录。</p><span id="more"></span><p>WriteBatch 的实现主要涉及到 4 个文件，接下来一起看看。</p><ol><li><a href="https://github.com/google/leveldb/blob/main/include/leveldb/write_batch.h">include&#x2F;leveldb&#x2F;write_batch.h</a>：对外暴露的接口文件，定义了 WriteBatch 类的接口。</li><li><a href="https://github.com/google/leveldb/blob/main/db/write_batch_internal.h">db&#x2F;write_batch_internal.h</a>：内部实现文件，定义了 WriteBatchInternal 类，提供了一些操作 WriteBatch 的方法。</li><li><a href="https://github.com/google/leveldb/blob/main/db/write_batch.cc">db&#x2F;write_batch.cc</a>：WriteBatch 类的实现文件，实现了 WriteBatch 类。</li><li><a href="https://github.com/google/leveldb/blob/main/db/write_batch_test.cc">db&#x2F;write_batch_test.cc</a>：WriteBatch 类的测试文件，用于测试 WriteBatch 的功能。</li></ol><h2 id="WriteBatch-接口设计"><a href="#WriteBatch-接口设计" class="headerlink" title="WriteBatch 接口设计"></a>WriteBatch 接口设计</h2><p>我们先来看 write_batch.h 文件，这里定义了 WriteBatch 类对外暴露的一些接口。 LevelDB 代码中的注释十分清晰，不过这里先省略注释：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LEVELDB_EXPORT</span> WriteBatch &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">LEVELDB_EXPORT</span> Handler &#123;</span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">Handler</span>();</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Put</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Delete</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">WriteBatch</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Intentionally copyable.</span></span><br><span class="line">  <span class="built_in">WriteBatch</span>(<span class="type">const</span> WriteBatch&amp;) = <span class="keyword">default</span>;</span><br><span class="line">  WriteBatch&amp; <span class="keyword">operator</span>=(<span class="type">const</span> WriteBatch&amp;) = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  ~<span class="built_in">WriteBatch</span>();</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Put</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Delete</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Clear</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">size_t</span> <span class="title">ApproximateSize</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Append</span><span class="params">(<span class="type">const</span> WriteBatch&amp; source)</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">Iterate</span><span class="params">(Handler* handler)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">WriteBatchInternal</span>;</span><br><span class="line"></span><br><span class="line">  std::string rep_;  <span class="comment">// See comment in write_batch.cc for the format of rep_</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中 <a href="https://github.com/google/leveldb/blob/main/include/leveldb/write_batch.h#L35">WriteBatch::Handler</a> 是一个抽象基类，定义了处理键值对操作的接口，只包括 Put 和 Delete 方法。这样的设计允许 WriteBatch 类实现与<strong>具体存储操作</strong>解耦，使得 WriteBatch 不必直接知道如何将操作应用到底层存储（如 MemTable）。</p><p><strong>通过继承 Handler 类，可以创建多种处理器，它们可以以不同的方式实现这些方法</strong>。比如：</p><ol><li>MemTableInserter： 定义在 db&#x2F;write_batch.cc 中，将键值操作存储到 MemTable 中。</li><li>WriteBatchItemPrinter：定义在 db&#x2F;dumpfile.cc 中，将键值操作打印到文件中，可以用来测试。</li></ol><p>另外还有一个 <code>friend class WriteBatchInternal</code> 作为 WriteBatch 的友元类，能够访问其私有和受保护成员。<strong>WriteBatchInternal 主要用来封装一些内部操作，这些方法不需要对外暴露，只在内部用到。通过将内部操作方法隐藏在 WriteBatchInternal 中，保持了对象的接口清晰，可以自由地修改内部实现而不影响到使用这些对象的代码</strong>。</p><h3 id="WriteBatch-使用方法"><a href="#WriteBatch-使用方法" class="headerlink" title="WriteBatch 使用方法"></a>WriteBatch 使用方法</h3><p>在应用层，我们可以通过 WriteBatch 来批量写入多个键值对，然后通过 <code>DB::Write</code> 方法将 WriteBatch 写入到数据库中。</p><p>这里 WriteBatch 支持 Put 和 Delete 操作，可以合并多个 WriteBatch。如下使用示例：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">WriteBatch batch;</span><br><span class="line">batch.<span class="built_in">Put</span>(<span class="string">&quot;key1&quot;</span>, <span class="string">&quot;value1&quot;</span>);</span><br><span class="line">batch.<span class="built_in">Put</span>(<span class="string">&quot;key2&quot;</span>, <span class="string">&quot;value2&quot;</span>);</span><br><span class="line">batch.<span class="built_in">Delete</span>(<span class="string">&quot;key3&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 合并另一个批次</span></span><br><span class="line">WriteBatch another_batch;</span><br><span class="line">another_batch.<span class="built_in">Put</span>(<span class="string">&quot;key4&quot;</span>, <span class="string">&quot;value4&quot;</span>);</span><br><span class="line">batch.<span class="built_in">Append</span>(another_batch);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入数据库</span></span><br><span class="line">db-&gt;<span class="built_in">Write</span>(writeOptions, &amp;batch);</span><br></pre></td></tr></table></figure><h2 id="WriteBatch-实现细节"><a href="#WriteBatch-实现细节" class="headerlink" title="WriteBatch 实现细节"></a>WriteBatch 实现细节</h2><p>那么 WriteBatch 是怎么实现的呢？关键在 <a href="https://github.com/google/leveldb/blob/main/db/write_batch.cc">db&#x2F;write_batch.cc</a>，该类中有一个 private 成员 <code>std::string rep_</code> 来存储序列化后的键值操作。我们先来看看这里的存储数据协议：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+---------------+---------------+----------------------------------------+</span><br><span class="line">|<span class="string">   Sequence    </span>|<span class="string">     Count     </span>|<span class="string">                Data                    </span>|</span><br><span class="line">|<span class="string">  (8 bytes)    </span>|<span class="string">   (4 bytes)   </span>|<span class="string">                                        </span>|</span><br><span class="line">+---------------+---------------+----------------------------------------+</span><br><span class="line">                                   |<span class="string">                 </span>|<span class="string">                   </span>|</span><br><span class="line">                                   v                 v                   v</span><br><span class="line">                               +-------+         +-------+          +-------+</span><br><span class="line">                               |<span class="string">Record1</span>|<span class="string">         </span>|<span class="string">Record2</span>|<span class="string">   ...    </span>|<span class="string">RecordN</span>|</span><br><span class="line">                               +-------+         +-------+          +-------+</span><br><span class="line">                                  |<span class="string">                 </span>|</span><br><span class="line">                                  v                 v</span><br><span class="line">                        +-----------------+ +-----------------+</span><br><span class="line">                        |<span class="string"> kTypeValue      </span>|<span class="string"> </span>|<span class="string"> kTypeDeletion   </span>|</span><br><span class="line">                        |<span class="string"> Varstring Key   </span>|<span class="string"> </span>|<span class="string"> Varstring Key   </span>|</span><br><span class="line">                        |<span class="string"> Varstring Value </span>|<span class="string"> </span>|<span class="string">                 </span>|</span><br><span class="line">                        +-----------------+ +-----------------+</span><br><span class="line">                        </span><br><span class="line">Varstring (可变长度字符串):</span><br><span class="line">+-------------+-----------------------+</span><br><span class="line">|<span class="string"> Length (varint32) </span>|<span class="string"> Data (uint8[])  </span>|</span><br><span class="line">+-------------+-----------------------+</span><br></pre></td></tr></table></figure><p>该字符串前 12 个字节是头部元数据部分，包括 8 个字节的序列号和 4 个字节的 count 数。接下来是一个或多个操作记录，每个记录包含一个操作类型和键值对。操作类型是一个字节，可以是 Put 或者 Delete 操作。键和值都是可变长度的字符串，格式为 varstring。</p><h3 id="LevelDB-的序列号机制"><a href="#LevelDB-的序列号机制" class="headerlink" title="LevelDB 的序列号机制"></a>LevelDB 的序列号机制</h3><p>rep_ 头部 8 个字节代表64位的数字 sequence（序列号），WriteBatchInternal 友元类提供了两个方法来获取和设置 sequence number，内部是用 <a href="https://selfboot.cn/2024/08/29/leveldb_source_utils/#%E6%95%B4%E6%95%B0%E7%BC%96%E3%80%81%E8%A7%A3%E7%A0%81">EncodeFixed64 和 DecodeFixed64</a> 方法来编解码 64 位的序列号。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">SequenceNumber <span class="title">WriteBatchInternal::Sequence</span><span class="params">(<span class="type">const</span> WriteBatch* b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">SequenceNumber</span>(<span class="built_in">DecodeFixed64</span>(b-&gt;rep_.<span class="built_in">data</span>()));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">WriteBatchInternal::SetSequence</span><span class="params">(WriteBatch* b, SequenceNumber seq)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">EncodeFixed64</span>(&amp;b-&gt;rep_[<span class="number">0</span>], seq);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>序列号是 LevelDB 中的全局递增标识符，用于实现版本控制和操作排序</strong>。每个 WriteBatch 在执行时会获得一段连续的序列号，批次内的每个操作（Put&#x2F;Delete）都会分配到其中的一个序列号。序列号在 LevelDB 中有三个核心作用：</p><ol><li><strong>版本控制</strong>：LevelDB 中的每个 key 可以有多个版本，每个版本都对应一个序列号。在读取时，通过比较序列号来确定应该返回哪个版本的值。较大的序列号表示更新的版本。</li><li><strong>多版本并发控制（MVCC）</strong>：写操作获取新的序列号，创建 key 的新版本。读操作可以指定序列号，访问该序列号时间点的数据快照。这种机制使得读写操作可以并发执行，无需互相阻塞。</li><li><strong>故障恢复</strong>：WAL（预写日志）中记录了操作的序列号。系统重启时，通过序列号可以准确重建崩溃时的数据状态，避免重复应用已持久化的操作。</li></ol><p>这种设计让 LevelDB 既保证了数据一致性，又实现了高效的并发控制。</p><p>设置序列号的逻辑在 <a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L1222">DBImpl::Write</a> 方法中，首先获取当前最大序列号，然后为 WriteBatch 分配一个新的序列号。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="type">uint64_t</span> last_sequence = versions_-&gt;<span class="built_in">LastSequence</span>();</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; updates != <span class="literal">nullptr</span>) &#123;  <span class="comment">// nullptr batch is for compactions</span></span><br><span class="line">    WriteBatch* write_batch = <span class="built_in">BuildBatchGroup</span>(&amp;last_writer);</span><br><span class="line">    WriteBatchInternal::<span class="built_in">SetSequence</span>(write_batch, last_sequence + <span class="number">1</span>);</span><br><span class="line">    last_sequence += WriteBatchInternal::<span class="built_in">Count</span>(write_batch);</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 WriteBatch 包含多个操作，那么这些操作会<strong>连续地分配序列号</strong>。在写入 WAL 日志时，会将 WriteBatch 的序列号写入到日志中，这样在恢复时可以根据序列号来恢复操作的顺序。写入 memtable 之后，会更新当前最大序列号，以便下次分配。</p><h3 id="count-记录操作数"><a href="#count-记录操作数" class="headerlink" title="count 记录操作数"></a>count 记录操作数</h3><p>头部还有 4 个字节的 count，用于记录 WriteBatch 中包含的操作数。这里每次 put 或者 delete 操作都会增加 count 的值。如下示例：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WriteBatch batch;</span><br><span class="line">batch.<span class="built_in">Put</span>(<span class="string">&quot;key1&quot;</span>, <span class="string">&quot;value1&quot;</span>);  <span class="comment">// count = 1</span></span><br><span class="line">batch.<span class="built_in">Put</span>(<span class="string">&quot;key2&quot;</span>, <span class="string">&quot;value2&quot;</span>);  <span class="comment">// count = 2</span></span><br><span class="line">batch.<span class="built_in">Delete</span>(<span class="string">&quot;key3&quot;</span>);         <span class="comment">// count = 3</span></span><br><span class="line"><span class="type">int</span> num_ops = WriteBatchInternal::<span class="built_in">Count</span>(&amp;batch);  <span class="comment">// = 3</span></span><br></pre></td></tr></table></figure><p>在合并两个 WriteBatch 的时候，也会累计两部分的 count 的值，如下 <a href="https://github.com/google/leveldb/blob/main/db/write_batch.cc#L144">WriteBatchInternal::Append</a> 方法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">WriteBatchInternal::Append</span><span class="params">(WriteBatch* dst, <span class="type">const</span> WriteBatch* src)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">SetCount</span>(dst, <span class="built_in">Count</span>(dst) + <span class="built_in">Count</span>(src));</span><br><span class="line">  <span class="built_in">assert</span>(src-&gt;rep_.<span class="built_in">size</span>() &gt;= kHeader);</span><br><span class="line">  dst-&gt;rep_.<span class="built_in">append</span>(src-&gt;rep_.<span class="built_in">data</span>() + kHeader, src-&gt;rep_.<span class="built_in">size</span>() - kHeader);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 count 的地方主要有两个，一个是在迭代这里每个记录的时候，会用 <a href="https://github.com/google/leveldb/blob/main/db/write_batch.cc#L75">count 来做完整性检查</a>，确保没有遗漏操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">WriteBatch::Iterate</span><span class="params">(Handler* handler)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="function">Slice <span class="title">input</span><span class="params">(rep_)</span></span>;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (found != WriteBatchInternal::<span class="built_in">Count</span>(<span class="keyword">this</span>)) &#123;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">Corruption</span>(<span class="string">&quot;WriteBatch has wrong count&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另一个是在 db 写入的时候，根据 count 可以预先知道需要分配多少序列号，保证序列号连续性。如下 <a href="https://github.com/google/leveldb/blob/main/db/db_impl.cc#L449">DBImpl::Write</a>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WriteBatchInternal::<span class="built_in">SetSequence</span>(write_batch, last_sequence + <span class="number">1</span>);</span><br><span class="line">last_sequence += WriteBatchInternal::<span class="built_in">Count</span>(write_batch);</span><br></pre></td></tr></table></figure><h3 id="支持的各种操作"><a href="#支持的各种操作" class="headerlink" title="支持的各种操作"></a>支持的各种操作</h3><p>在头部的 sequence 和 count 之后，rep_ 紧跟着的是一系列的记录，每个记录包含一个操作类型和键值。这里记录可以通过 Put 和 Delete 方法来添加，其中 Put 方法的实现如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">WriteBatch::Put</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  WriteBatchInternal::<span class="built_in">SetCount</span>(<span class="keyword">this</span>, WriteBatchInternal::<span class="built_in">Count</span>(<span class="keyword">this</span>) + <span class="number">1</span>);</span><br><span class="line">  rep_.<span class="built_in">push_back</span>(<span class="built_in">static_cast</span>&lt;<span class="type">char</span>&gt;(kTypeValue));</span><br><span class="line">  <span class="built_in">PutLengthPrefixedSlice</span>(&amp;rep_, key);</span><br><span class="line">  <span class="built_in">PutLengthPrefixedSlice</span>(&amp;rep_, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里更新了 count，然后添加了 kTypeValue 操作类型，接着是添加 key 和 value。Delete 操作类似，count 计数也是要加 1，然后操作类型是 kTypeDeletion，最后只用添加 key 即可。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">WriteBatch::Delete</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span> </span>&#123;</span><br><span class="line">  WriteBatchInternal::<span class="built_in">SetCount</span>(<span class="keyword">this</span>, WriteBatchInternal::<span class="built_in">Count</span>(<span class="keyword">this</span>) + <span class="number">1</span>);</span><br><span class="line">  rep_.<span class="built_in">push_back</span>(<span class="built_in">static_cast</span>&lt;<span class="type">char</span>&gt;(kTypeDeletion));</span><br><span class="line">  <span class="built_in">PutLengthPrefixedSlice</span>(&amp;rep_, key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面是往 rep_ 中添加记录，那么如何从 rep_ 中解析出这些记录呢？这里 WriteBatch 类中提供了一个 <a href="https://github.com/google/leveldb/blob/main/db/write_batch.cc#L42">Iterate</a> 方法，该方法遍历 rep_ 中的每条记录，然后通过传入的 Handler 接口来灵活处理这些记录。 </p><p>此外该方法的实现中还有<strong>数据格式验证，会检查头部大小、操作类型、操作数量是否匹配</strong>。可以返回 Corruption 错误，表示数据格式不正确等。Iterate 核心代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">WriteBatch::Iterate</span><span class="params">(Handler* handler)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="function">Slice <span class="title">input</span><span class="params">(rep_)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (input.<span class="built_in">size</span>() &lt; kHeader) &#123;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">Corruption</span>(<span class="string">&quot;malformed WriteBatch (too small)&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  input.<span class="built_in">remove_prefix</span>(kHeader);</span><br><span class="line">  Slice key, value;</span><br><span class="line">  <span class="type">int</span> found = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (!input.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    found++;</span><br><span class="line">    <span class="type">char</span> tag = input[<span class="number">0</span>];</span><br><span class="line">    input.<span class="built_in">remove_prefix</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">switch</span> (tag) &#123;</span><br><span class="line">      <span class="keyword">case</span> kTypeValue:</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">GetLengthPrefixedSlice</span>(&amp;input, &amp;key) &amp;&amp;</span><br><span class="line">            <span class="built_in">GetLengthPrefixedSlice</span>(&amp;input, &amp;value)) &#123;</span><br><span class="line">          handler-&gt;<span class="built_in">Put</span>(key, value);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> Status::<span class="built_in">Corruption</span>(<span class="string">&quot;bad WriteBatch Put&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> kTypeDeletion:</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">GetLengthPrefixedSlice</span>(&amp;input, &amp;key)) &#123;</span><br><span class="line">          handler-&gt;<span class="built_in">Delete</span>(key);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> Status::<span class="built_in">Corruption</span>(<span class="string">&quot;bad WriteBatch Delete&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">Corruption</span>(<span class="string">&quot;unknown WriteBatch tag&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>前面提过 Handler 是 WriteBatch 的抽象基类，可以传入不同的实现。在 LevelDB 写数据的时候，这里传入的是 MemTableInserter 类，该类将操作数据存储到 MemTable 中。具体可以调用这里的实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">WriteBatchInternal::InsertInto</span><span class="params">(<span class="type">const</span> WriteBatch* b, MemTable* memtable)</span> </span>&#123;</span><br><span class="line">  MemTableInserter inserter;</span><br><span class="line">  inserter.sequence_ = WriteBatchInternal::<span class="built_in">Sequence</span>(b);</span><br><span class="line">  inserter.mem_ = memtable;</span><br><span class="line">  <span class="keyword">return</span> b-&gt;<span class="built_in">Iterate</span>(&amp;inserter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整体上看 WriteBatch 负责存储键值操作的数据，进行编码解码等，而 Handler 负责具体处理里面的每条数据。这样 WriteBatch 的操作就可以被灵活地应用到不同场景中，方便扩展。</p><h2 id="测试用例分析"><a href="#测试用例分析" class="headerlink" title="测试用例分析"></a>测试用例分析</h2><p>最后再来看看 <a href="https://github.com/google/leveldb/blob/main/db/write_batch_test.cc">write_batch_test.cc</a>，这里提供了一些测试用例，用于测试 WriteBatch 的功能。</p><p>首先定义了一个 PrintContents 函数，用来输出 WriteBatch 中的所有操作记录。这里用 MemTableInserter 将 WriteBatch 中的操作记录存储到 MemTable 中，然后通过 MemTable 的迭代器遍历所有记录，并保存到字符串中。</p><p>这里测试用例覆盖了下面这些情况：</p><ol><li>Empty：测试空的 WriteBatch 是否正常；</li><li>Multiple：测试多个 Put 和 Delete 操作，验证总的 count 数目和每个操作的序列号是否正确；</li><li>Corruption：先写进去数据，然后故意截断部分记录，测试能读取尽量多的正常数据；</li><li>Append：测试合并两个 WriteBatch，验证合并后序列号的正确性，以及合并空 WriteBatch；</li><li>ApproximateSize：测试 ApproximateSize 方法，计算 WriteBatch 的近似大小；</li></ol><p>这里通过测试用例，基本就能知道怎么使用 WriteBatch 了。比较有意思的是，前面在看 Append 代码的时候，没太留意到合并后这里序列号是用谁的。这里结合测试用例，才发现取的目标 WriteBatch 的序列号。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">TEST</span>(WriteBatchTest, Append) &#123;</span><br><span class="line">  WriteBatch b1, b2;</span><br><span class="line">  WriteBatchInternal::<span class="built_in">SetSequence</span>(&amp;b1, <span class="number">200</span>);</span><br><span class="line">  WriteBatchInternal::<span class="built_in">SetSequence</span>(&amp;b2, <span class="number">300</span>);</span><br><span class="line">  b<span class="number">1.</span><span class="built_in">Append</span>(b2);</span><br><span class="line">  <span class="built_in">ASSERT_EQ</span>(<span class="string">&quot;&quot;</span>, <span class="built_in">PrintContents</span>(&amp;b1));</span><br><span class="line">  b<span class="number">2.</span><span class="built_in">Put</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;va&quot;</span>);</span><br><span class="line">  b<span class="number">1.</span><span class="built_in">Append</span>(b2);</span><br><span class="line">  <span class="built_in">ASSERT_EQ</span>(<span class="string">&quot;Put(a, va)@200&quot;</span>, <span class="built_in">PrintContents</span>(&amp;b1));</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过深入分析 LevelDB 的 WriteBatch 实现，我们可以清晰地看到其设计精妙之处。WriteBatch 通过将多个写入和删除操作封装在一起，不仅提高了写操作的效率，还简化了并发控制和故障恢复的实现。有几个亮点值得借鉴：</p><ol><li><strong>批量操作</strong>：WriteBatch 允许将多个 Put 和 Delete 操作合并为一个批次，减少了频繁的 I&#x2F;O 操作，提升了写入性能。</li><li><strong>序列号机制</strong>：通过全局递增的序列号，LevelDB 实现了多版本并发控制（MVCC），确保了读写操作的一致性。</li><li><strong>Handler 抽象</strong>：通过 Handler 接口，WriteBatch 将操作的具体实现与存储逻辑解耦，使得代码更加灵活和可扩展。</li><li><strong>数据格式验证</strong>：在解析 WriteBatch 时，LevelDB 会进行严格的数据格式验证，确保数据的完整性和正确性。</li></ol><p>当然本篇只是分析 WriteBatch 的实现，并没有串起 LevelDB 的整个写入流程，后续文章我们会继续分析，写入一个 key 的完整流程。</p>]]></content>
    
    
    <summary type="html">本文深入剖析了 LevelDB 中 WriteBatch 的设计与实现，详细介绍了其如何通过批量写入和删除操作提升性能。文章从 WriteBatch 的接口设计、序列号机制、操作记录存储格式等方面展开，结合源码分析了其核心功能，如序列号的全局递增、操作计数、数据格式验证等。此外，文章还通过测试用例展示了 WriteBatch 的实际使用场景，适合对 LevelDB 或存储系统设计感兴趣的开发者阅读。</summary>
    
    
    
    <category term="源码剖析" scheme="https://selfboot.cn/categories/%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="LevelDB" scheme="https://selfboot.cn/tags/LevelDB/"/>
    
  </entry>
  
  
  
  
  
  
  
  <entry>
    <title>5 个导致 C++ 进程 Crash 的真实业务案例</title>
    <link href="https://selfboot.cn/2025/01/10/c++_crash_cases/"/>
    <id>https://selfboot.cn/2025/01/10/c++_crash_cases/</id>
    <published>2025-01-10T21:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.713Z</updated>
    
    <content type="html"><![CDATA[<p>只要你写过比较复杂的 C++ 项目，应该都或多或少遇见过进程 Coredump 的问题。Coredump 是程序运行过程中发生严重错误时，操作系统将程序当前的内存状态记录下来的一种机制。</p><p>C++ 中导致进程 Coredump 的原因有很多，比如：</p><ol><li><strong>访问非法内存地址</strong>：包括空指针解引用、访问已释放的内存、数组越界访问等；</li><li><strong>栈溢出</strong>：无限递归、大数组分配在栈上；</li><li><strong>段错误</strong>（Segmentation Fault）：试图写入只读内存、访问未映射的内存区域；</li><li><strong>异常未捕获</strong>：未处理的异常导致程序终止；</li></ol><p>遇到 Coredump 问题时，一般需要打开 core 文件，然后根据 core 文件来进行问题分析和调试。分析 core 文件有时候还是比较难的，需要对 C++ 的内存模型、异常处理机制、系统调用等有深入的理解。</p><p>本文不会过多介绍分析 core 文件的方法，而是通过几个真实项目中的案例，来让大家在写代码时候，能够有意识地避免这些错误。</p><span id="more"></span><h2 id="抛异常没有捕获"><a href="#抛异常没有捕获" class="headerlink" title="抛异常没有捕获"></a>抛异常没有捕获</h2><p>业务代码中最常见的导致进程 crash 的原因，就是不小心抛出异常却没有捕获。比如一个字符串转整数的函数中，用了 <a href="https://cplusplus.com/reference/string/stoi/">std::stoi</a> 来转换。但是这里万一字符串没法转成数字，就会抛出 <code>std::invalid_argument</code> 异常。如果框架层或者调用方没有捕获异常，就会导致进程 crash 掉。</p><p>就拿标准库来说，可能抛出异常的函数还是挺多的，常见的有：</p><ul><li>std::vector::at()：如果访问越界，会抛出 <code>std::out_of_range</code> 异常。</li><li>std::vector::push_back()：如果内存分配失败，会抛出 <code>std::bad_alloc</code> 异常。</li><li>std::map::at()：如果访问不存在的 key，会抛出 <code>std::out_of_range</code> 异常。</li></ul><p>在使用这些可能抛出异常的标准库函数的时候，一定要妥善处理好异常。<strong>另外如果是自定义类，不建议抛出异常，可以用错误码来处理。当然对使用异常还是错误码这里一直有争论，可以按照自己比较熟悉或者项目中的惯例来处理就好</strong>。如果是明确不抛出异常的函数，可以加上 noexcept 来告诉编译器和使用方。</p><p>这里再补充说下，有时候有些函数调用不会抛异常，但是会导致<a href="https://selfboot.cn/2016/09/18/c++_undefined_behaviours/">未定义行为</a>，也是可能导致进程 crash 的。比如 <a href="https://cplusplus.com/reference/cstdlib/atoi/?kw=atoi">atoi 函数</a>，如果字符串没法转成数字，这里会导致未定义行为。未定义行为在某些场景下，会导致进程 crash。</p><p>平常在使用一些基础函数的时候，如果对该函数不清楚的话，可以查看 <a href="https://cplusplus.com/">cplusplus</a> 的文档，来确定该函数是否会在某些场景抛异常，是否会导致未定义行为。比如对于 vector ：</p><blockquote><p>std::vector::front()<br> Calling this function on an empty container causes undefined behavior.</p><p>std::vector::push_back()<br> If a reallocation happens, the storage is allocated using the container’s allocator, which may throw exceptions on failure (for the default allocator, bad_alloc is thrown if the allocation request does not succeed).</p></blockquote><h2 id="数组下标访问越界"><a href="#数组下标访问越界" class="headerlink" title="数组下标访问越界"></a>数组下标访问越界</h2><p>除了抛出异常，还有一类问题也比较常见，那就是数组下标访问越界。我们都知道在 C++ 中<strong>访问数组的时候如果下标越界，会导致访问非法内存地址，可能导致进程 crash</strong>。你可能会觉得，怎么会数组访问越界？我遍历的时候限制长度就行了呀。</p><p>别急，看下面来自业务中的真实例子。当然为了演示，这里简化了很多实际业务逻辑，只保留核心部分。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; src = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>&#125;;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; dest;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; src.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        <span class="comment">// 可能是后面加的业务过滤逻辑</span></span><br><span class="line">        <span class="keyword">if</span>(src[i] == <span class="number">8</span>) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dest.<span class="built_in">push_back</span>(src[i] * <span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ... 继续根据 src 的内容进行处理</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; src.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        <span class="comment">// 其他对 src 的处理</span></span><br><span class="line">        <span class="comment">// 这种用法虽然有问题，但这里内存在堆上，可能还没被回收，也不会 core</span></span><br><span class="line">        <span class="comment">// dest[i] -= 5; </span></span><br><span class="line">        dest.<span class="built_in">at</span>(i) -= <span class="number">5</span>; <span class="comment">// 这种用法会 core</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里刚开始实现的时候，第一次遍历 src 用来初始化 dest。然后中间有一些其他代码，接着后面又遍历 src，根据 src 的内容对初始化后的 dest 再进行某些处理。</p><p>刚开始实现的时候，这样没什么问题，然后某天可能加了个需求，需要过滤掉 src 中某些数据，于是就加了 if 判断来跳过某些内容。改动的人，可能没注意到后面对 src 和 dest 的遍历，没意识到过滤会导致 dest 的长度已经变了。</p><p>这个场景有时候比较难触发 coredump，可能只有极少场景才会有过滤导致长度不一样。并且这里就算第二轮访问了越界下标，用 [] 访问的话，也可能不会 core。上面示例代码为了必现 core，故意改成用 at 访问，这样下标越界就会抛异常。</p><h2 id="访问失效的迭代器"><a href="#访问失效的迭代器" class="headerlink" title="访问失效的迭代器"></a>访问失效的迭代器</h2><p>除了下标访问越界，还有一类问题比较常见，那就是访问失效的迭代器。迭代器是一种设计模式，它提供了一种方法来访问容器对象中的元素，而无需暴露该对象的内部表示。在 C++ 中，迭代器是一个非常重要的概念，它是容器和算法之间的桥梁。</p><p>C++ 标准库中，很多容器都提供了迭代器，比如 vector、list、map 等。<strong>访问这些容器的迭代器时候，如果迭代器已经失效，就会导致未定义行为，可能导致进程 coredump</strong>。</p><p>导致迭代器失效的原因有很多，比如 vector 扩容，导致之前的迭代器失效。最常见的一个例子就是删除 vector 中偶数位置的元素，很多新手可能像下面这样写：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> it = numbers.<span class="built_in">begin</span>(); it != numbers.<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">    <span class="keyword">if</span> (*it % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        numbers.<span class="built_in">erase</span>(it);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里当调用 <code>erase</code> 删除元素时，会<strong>导致删除位置和它之后的所有迭代器都失效</strong>。所以循环中接着访问 <code>it</code> 就会导致未定义行为。正确做法是使用 erase 的返回值，来更新迭代器，或者使用 remove_if 和 erase 来删除元素。</p><p>当然这个示例比较简单，在实际业务中，我们遇见过一些比较隐蔽的迭代器失效问题。背景是这样，我们有个批处理任务，会用协程池来处理一批 IO 密集的任务，并且把结果写回到一个 vector 中。为了示例，这里代码简化如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 模拟异步任务处理函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">AsyncProcess</span><span class="params">(<span class="type">int</span>&amp; value)</span> </span>&#123;</span><br><span class="line">    std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">milliseconds</span>(<span class="number">100</span>));</span><br><span class="line">    value += <span class="number">1</span>;  <span class="comment">// 可能访问已经失效的引用</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; values;</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; results;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        values.<span class="built_in">push_back</span>(i);</span><br><span class="line">        results.<span class="built_in">push_back</span>(<span class="number">-1</span>);</span><br><span class="line">        <span class="type">int</span>&amp; result = results.<span class="built_in">back</span>();</span><br><span class="line"></span><br><span class="line">        <span class="function">std::thread <span class="title">t</span><span class="params">([&amp;result]() &#123;</span></span></span><br><span class="line"><span class="params"><span class="function">            AsyncProcess(result);  <span class="comment">// 在异步任务中使用引用</span></span></span></span><br><span class="line"><span class="params"><span class="function">        &#125;)</span></span>;</span><br><span class="line">        t.<span class="built_in">detach</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 等待一段时间让任务执行</span></span><br><span class="line">    std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">seconds</span>(<span class="number">1</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们保存了 <code>results.back()</code> 的引用，并在异步任务中使用它。在异步任务执行期间，<code>results</code> vector 继续添加新元素。当 vector 需要扩容时，原有的内存会被释放，新的内存会被分配。此时异步任务中持有的引用就变成了悬空引用，访问它会导致未定义行为。</p><p>正确的做法应该是使用 <code>reserve</code> 预分配空间，避免扩容。或者保存索引，使用索引值而不是引用。</p><h2 id="并发导致的数据竞争"><a href="#并发导致的数据竞争" class="headerlink" title="并发导致的数据竞争"></a>并发导致的数据竞争</h2><p>还有一类 crash 问题，是因为并发导致的数据竞争。经常有这么一个场景，就是服务中有一个后台线程，会从某个配置中心拉取配置更新到本地。然后有多个业务线程，会并发读取这里的配置。</p><p>因为是经典的读多写少场景，所以一般会用读写锁来实现。多个读线程可以同时持有读锁，写线程必须独占，写的过程需要保证无其他读或写操作。写操作期间，新的读操作需要等待。一个可能的执行序列如下：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Time ──────────────────────────────────────────────────────▶</span></span><br><span class="line"><span class="attribute">Reader 1</span><span class="punctuation">:</span> <span class="string">     RRRR      RRRR      </span></span><br><span class="line"><span class="attribute">Reader 2</span><span class="punctuation">:</span> <span class="string">        RRRR        RRRR</span></span><br><span class="line"><span class="attribute">Reader 3</span><span class="punctuation">:</span> <span class="string">           RRRR         RRRR</span></span><br><span class="line"><span class="attribute">Writer A</span><span class="punctuation">:</span> <span class="string"> W                 W</span></span><br></pre></td></tr></table></figure><p>这里 W 代表一次写入，R 代表一次读取。可以看到，写操作期间，新的读操作需要等待。我们在实际场景中，有遇见过一个 crash 就是错误的使用读写锁。整体比较复杂，下面简化下逻辑，给出核心代码。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DataManager</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::shared_mutex mutex_;</span><br><span class="line">    std::unordered_map&lt;std::string, std::string&gt; m_data;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> num_keys = <span class="number">100</span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">loadData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::unordered_map&lt;std::string, std::string&gt; localdata;</span><br><span class="line">        std::vector&lt;std::string&gt; keys;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_keys; i++) &#123;</span><br><span class="line">            keys.<span class="built_in">push_back</span>(<span class="string">&quot;test&quot;</span> + std::<span class="built_in">to_string</span>(i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_keys; i++) &#123;</span><br><span class="line">            localdata[keys[i]] = <span class="string">&quot;test&quot;</span> + std::<span class="built_in">to_string</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function">std::unique_lock&lt;std::shared_mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">            m_data.<span class="built_in">swap</span>(localdata);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">std::string <span class="title">readData</span><span class="params">(<span class="type">const</span> std::string&amp; key)</span> </span>&#123;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function">std::shared_lock&lt;std::shared_mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">            <span class="keyword">return</span> m_data[key];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>完整的演示代码在 <a href="https://gist.github.com/selfboot/dc0d9450ded391bc28a43aecd1045694">core_share.cpp</a> 中，感兴趣的可以看下。这里 loadData 中，先准备好配置数据，然后用写锁来更新配置。在 readData 中，则用读锁来读取配置。</p><p>看起来没啥问题呀？因为当时是很偶发的 crash，这里业务代码也很久没动过了，只能开了 core 文件来分析。结果 core 的堆栈很奇怪，在 loadData 方法里，localdata 的<strong>析构过程发生的 crash</strong>。这里 localdata 是局部变量，最后析构前交换了 m_data 和 localdata 的值。那就是 m_data 的数据内存布局有问题了，<strong>m_data 只有这里会写，其他地方全部是“读“</strong>。</p><p>又仔细翻了下业务代码，发现 m_data 读的时候，用了 [] 来拿 unordered_map 的值。<strong>对于 unordered_map 来说，如果 key 不存在，[] 会导致插入一个默认值</strong>。啊！！这里本来意图是用读锁保护只读操作，结果不小心还执行了写操作。我们知道，并发写 unordered_map 会有数据竞争，怪不得导致 crash。</p><p>当然这里 core 的堆栈其实不一定是析构时候，比如示例的代码，堆栈就是在读线程 readData 的时候，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250110_c++_crash_cases_mapread.png" alt="读线程 crash 堆栈"></p><h2 id="灾难性回溯导致的栈溢出"><a href="#灾难性回溯导致的栈溢出" class="headerlink" title="灾难性回溯导致的栈溢出"></a>灾难性回溯导致的栈溢出</h2><p>上面的示例其实平时多注意的话，还是能避免的。但下面这个，一般人还是很少知道，很容易踩坑。</p><p>我们有个地方需要判断字符串中是否有一对括号，于是用了 C++ 的正则表达式。相关代码简化如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;regex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::string problematic = <span class="string">&quot;((((&quot;</span>;</span><br><span class="line">    problematic += std::<span class="built_in">string</span>(<span class="number">100000</span>, <span class="string">&#x27;a&#x27;</span>);</span><br><span class="line">    problematic += <span class="string">&quot;))))&quot;</span>;</span><br><span class="line">    <span class="function">std::regex <span class="title">re</span><span class="params">(<span class="string">R&quot;(\([^\)]+\))&quot;</span>)</span></span>;</span><br><span class="line">    std::smatch matches;</span><br><span class="line">    <span class="type">bool</span> found = std::<span class="built_in">regex_search</span>(problematic, matches, re);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码中，我构造了一个很长的字符串，然后使用正则表达式来匹配。用 g++ 编译后，运行程序，程序就会 coredump 掉。如果用 gdb 看堆栈的话，如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250107_c++_crash_cases_regex.png" alt="灾难性回溯导致的栈溢出"></p><p>这是因为正则引擎进行了大量的回溯，每次回溯都会在调用栈上创建新的栈帧。导致这里栈的深度特别长，最终超出栈大小限制，进程 coredump 了。</p><p>这个就是所谓的<strong>灾难性回溯（Catastrophic Backtracking）</strong>，实际开发中，对于复杂的文本处理，最好对输入长度进行限制。如果能用循环或者其他非递归的方案解决，就尽量不用正则表达式。如果一定要用正则表达式，可以限制重复次数（使用 {n,m} 而不是 + 或 *），另外也要注意避免嵌套的重复（如 (.+)+）。</p><p>上面的正则表达式，可以改成：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::regex <span class="title">re</span><span class="params">(<span class="string">R&quot;(\([^\)]&#123;1,100&#125;\))&quot;</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>当然除了这里递归回溯导致的栈溢出，还有其他一些场景，比如无限递归、大数组分配在栈上，都可能导致栈溢出。好在栈溢出的话，有 core 文件还是能比较好定位到原因的。</p><h2 id="coredump-问题分析"><a href="#coredump-问题分析" class="headerlink" title="coredump 问题分析"></a>coredump 问题分析</h2><p>遇到 crash 问题，一般需要打开 core 文件。真实业务环境中，业务进程如果占内存比较大，crash 后保存 core 文件可能会持续比较久的时间。而真实业务中，一般会有守护进程定时拨测业务进程，如果发现业务进程没回应，有的会用 <code>kill -9</code> 来杀死进程并重启。<strong>这时候，业务进程的 core 文件可能只写了一半，我们拿到的是不完整的 core 文件</strong>。这时候就要修改守护进程，等 core 文件写完再重启进程。</p><p>拿到 core 文件后，用 gdb 来分析，如果堆栈比较明确，一般就能很快定位到问题。但很多时候，可能看到的堆栈不完整，是一堆 ??。比如上面访问失效的迭代器，用 gdb 来运行，crash 之后看到堆栈如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250109_c++_crash_cases_gdb_iter.png" alt="访问失效的迭代器堆栈"></p><p>这里堆栈没有什么有用的信息，比较难分析。对于示例这种能稳定复现的问题，使用 <a href="https://en.wikipedia.org/wiki/Valgrind">Valgrind</a> 来辅助分析，会更容易定位。上面代码分析结果如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20250109_c++_crash_cases_valgrind.png" alt="访问失效的迭代器用 Valgrind 分析"></p><p>从这里分析结果可以看到，主要有两个问题，无效读取（Invalid read）和无效写入（Invalid write）。发生问题的代码行数这里也有，所以可以很快定位到问题。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了 5 个自己遇到过的导致进程 Coredump 的经典案例：</p><ol><li><strong>抛异常没有捕获</strong>：使用标准库函数时，要注意其是否会抛出异常。对于可能抛出异常的函数，需要妥善处理异常。对于自定义类，建议使用错误码而不是异常来处理错误。</li><li><strong>数组下标访问越界</strong>：在使用数组或容器时，要特别注意下标访问的合法性。尤其是在多处遍历同一容器时，要确保容器的大小没有发生变化。可以使用 <code>at()</code> 方法来进行带边界检查的访问。</li><li><strong>访问失效的迭代器</strong>：在使用迭代器时，要注意容器的操作（如删除、插入等）可能会导致迭代器失效。对于 vector 来说，扩容会导致所有迭代器失效；对于其他容器，也要了解其迭代器失效的规则。</li><li><strong>并发导致的数据竞争</strong>：在多线程环境下，要特别注意数据的并发访问。即使是看似只读的操作（如 map 的 [] 操作符），也可能会修改容器的内容。使用合适的同步机制（如互斥锁、读写锁等）来保护共享数据。</li><li><strong>灾难性回溯导致的栈溢出</strong>：在使用正则表达式等可能导致大量递归的场景下，要注意输入的限制。对于复杂的文本处理，最好使用非递归的方案，或者限制递归深度。</li></ol><p>当然还有些不常见的 core，比如我之前遇到的：<a href="https://selfboot.cn/2024/03/15/object_memory_coredump/">Bazel 依赖缺失导致的 C++ 进程 coredump 问题分析</a>。大家有遇见过什么印象深刻的 crash 案例，欢迎留言分享。</p>]]></content>
    
    
    <summary type="html">本文深入分析了 C++ 开发中常见的 5 种导致进程 Crash 的典型案例：未捕获的异常处理、数组越界访问、迭代器失效、并发数据竞争以及栈溢出问题。通过真实的代码示例，详细讲解了每种问题的成因、排查方法和解决方案。文章还介绍了如何使用 GDB、Valgrind 等工具来分析 Coredump 问题，是一篇实用的 C++ 参考指南。</summary>
    
    
    
    <category term="计算机基础" scheme="https://selfboot.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
  </entry>
  
  
  
  
  
  <entry>
    <title>LevelDB 源码阅读：利用 Clang 的静态线程安全分析</title>
    <link href="https://selfboot.cn/2025/01/02/leveldb_source_thread_anno/"/>
    <id>https://selfboot.cn/2025/01/02/leveldb_source_thread_anno/</id>
    <published>2025-01-02T22:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.713Z</updated>
    
    <content type="html"><![CDATA[<p>LevelDB 中有一些宏比较有意思，平时自己写代码的时候，还基本没用过。这些宏在 <a href="https://github.com/google/leveldb/blob/main/port/thread_annotations.h">thread_annotations.h</a> 中定义，可以在编译时<strong>使用 Clang 编译器的线程安全分析工具，来检测潜在的线程安全问题</strong>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20241227_leveldb_source_thread_anno_code.png" alt="Clang 编译器的线程安全分析工具"></p><span id="more"></span><p>比如下面这些宏，到底有什么作用呢？本文就一起来看看吧。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">GUARDED_BY</span>(x)          <span class="comment">// 表示变量必须在持有锁x时才能访问</span></span><br><span class="line"><span class="built_in">PT_GUARDED_BY</span>(x)       <span class="comment">// 指针类型的 GUARDED_BY</span></span><br><span class="line"><span class="built_in">ACQUIRED_AFTER</span>(...)    <span class="comment">// 指定锁的获取顺序，防止死锁</span></span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><h2 id="GUARDED-BY-锁保护"><a href="#GUARDED-BY-锁保护" class="headerlink" title="GUARDED_BY 锁保护"></a>GUARDED_BY 锁保护</h2><p>在很多类的成员变量定义中，都有 <code>GUARDED_BY(mutex_)</code> 这样的注解，有什么作用呢？比如 LRU Cache 的定义：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LRUCache</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="keyword">mutable</span> port::Mutex mutex_;</span><br><span class="line">  <span class="function"><span class="type">size_t</span> usage_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="function">HandleTable table_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其实这就是 Clang 的线程安全注解，编译的时候，Clang 会检查所有对 <code>usage_</code> 和 <code>table_</code> 的访问是否都在持有 <code>mutex_</code> 锁的情况下进行。另外，在函数或代码块结束时，编译器还会检查所有应该释放的锁是否都已经释放，可以防止遗漏锁释放导致的资源泄露或死锁。</p><p>反观我们平时在写业务代码的时候，几乎没用过这些线程安全注解。顶多注释下这里不是线程安全的，要加锁访问，全靠开发的自觉。可想而知，业务中肯定会遇见各种奇怪的多线程数据竞争问题。</p><p>LevelDB 实现的时候，加了很多类似的线程安全注解，<strong>不仅可以明确告诉其他开发者这个变量需要锁保护，还可以在编译期就发现潜在的线程安全问题，从而减少多线程环境下可能出现的竞态条件、死锁等问题</strong>。</p><h3 id="锁保护线程注解示例"><a href="#锁保护线程注解示例" class="headerlink" title="锁保护线程注解示例"></a>锁保护线程注解示例</h3><p>下面通过一个完整的例子来看看 Clang 的线程安全注解作用。这里 SharedData 类中，<code>counter_</code> 变量需要锁保护，<code>mutex_</code> 是我们封装的一个锁实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// guard.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">__attribute__</span>((<span class="built_in">capability</span>(<span class="string">&quot;mutex&quot;</span>))) Mutex &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123; mutex_.<span class="built_in">lock</span>(); &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123; mutex_.<span class="built_in">unlock</span>(); &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::mutex mutex_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SharedData</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Increment</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        mutex_.<span class="built_in">lock</span>();</span><br><span class="line">        counter_++;</span><br><span class="line">        mutex_.<span class="built_in">unlock</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Wrong case: Accessing shared variable without holding the lock</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">UnsafeIncrement</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        counter_++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">UnsafeIncrement2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        mutex_.<span class="built_in">lock</span>();</span><br><span class="line">        counter_++;</span><br><span class="line">        <span class="comment">// Forgot to unlock, will trigger warning</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Mutex mutex_;</span><br><span class="line">    <span class="type">int</span> counter_ __attribute__((<span class="built_in">guarded_by</span>(mutex_)));</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    SharedData data;</span><br><span class="line">    data.<span class="built_in">Increment</span>();</span><br><span class="line">    data.<span class="built_in">UnsafeIncrement</span>();</span><br><span class="line">    data.<span class="built_in">UnsafeIncrement2</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然这里的测试代码为了直接能运行，就没有依赖 LevelDB 中的宏定义 GUARDED_BY。下面的 <code>__attribute__((guarded_by(mutex_)))</code> 和宏展开的结果是一样的。</p><p>用 Clang 编译上面的代码，就能看到告警信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">clang++ -pthread -Wthread-safety -std=c++17 guard.cpp -o guard</span></span><br><span class="line">guard.cpp:16:9: warning: writing variable &#x27;counter_&#x27; requires holding mutex &#x27;mutex_&#x27; exclusively [-Wthread-safety-analysis]</span><br><span class="line">        counter_++;</span><br><span class="line">        ^</span><br><span class="line">guard.cpp:22:9: warning: writing variable &#x27;counter_&#x27; requires holding mutex &#x27;mutex_&#x27; exclusively [-Wthread-safety-analysis]</span><br><span class="line">        counter_++;</span><br><span class="line">        ^</span><br><span class="line">guard.cpp:27:9: warning: writing variable &#x27;counter_&#x27; requires holding mutex &#x27;mutex_&#x27; exclusively [-Wthread-safety-analysis]</span><br><span class="line">        counter_++;</span><br><span class="line">        ^</span><br><span class="line">3 warnings generated</span><br></pre></td></tr></table></figure><p>可以看到，编译器在编译的时候，就发现了 <code>counter_</code> 变量在未持有 <code>mutex_</code> 锁的情况下被访问，从而告警。</p><h3 id="PT-GUARDED-BY-指针保护"><a href="#PT-GUARDED-BY-指针保护" class="headerlink" title="PT_GUARDED_BY 指针保护"></a>PT_GUARDED_BY 指针保护</h3><p>这里 GUARDED_BY 通常用在对象的非指针成员上，用来保护成员变量自身。而 <strong>PT_GUARDED_BY 则是用在指针和智能指针成员上，用来保护指针指向的数据</strong>。注意这里 PT_GUARDED_BY <strong>只保护指针指向的数据，指针本身并没有约束的</strong>。可以看下面的例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Mutex mu;</span><br><span class="line"><span class="function"><span class="type">int</span> *p1             <span class="title">GUARDED_BY</span><span class="params">(mu)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> *p2             <span class="title">PT_GUARDED_BY</span><span class="params">(mu)</span></span>;</span><br><span class="line"><span class="function">unique_ptr&lt;<span class="type">int</span>&gt; p3  <span class="title">PT_GUARDED_BY</span><span class="params">(mu)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  p1 = <span class="number">0</span>;             <span class="comment">// Warning!</span></span><br><span class="line"></span><br><span class="line">  *p2 = <span class="number">42</span>;           <span class="comment">// Warning!</span></span><br><span class="line">  p2 = <span class="keyword">new</span> <span class="type">int</span>;       <span class="comment">// OK.</span></span><br><span class="line"></span><br><span class="line">  *p3 = <span class="number">42</span>;           <span class="comment">// Warning!</span></span><br><span class="line">  p<span class="number">3.</span><span class="built_in">reset</span>(<span class="keyword">new</span> <span class="type">int</span>);  <span class="comment">// OK.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="capability-属性注解"><a href="#capability-属性注解" class="headerlink" title="capability 属性注解"></a>capability 属性注解</h2><p>上面的例子中，我们没有直接用标准库的 mutex 互斥锁，而是简单封装了一个 <code>Mutex</code> 类。在类定义那里，用了 <code>__attribute__((capability(&quot;mutex&quot;)))</code> 注解。</p><p>这是因为 Clang 的线程安全分析需要<strong>知道哪些类型是锁，需要去追踪锁的获取和释放状态</strong>。而标准库的类型没有这些注解，不能直接用于 Clang 的线程安全分析。这里用到了 clang 的 <code>capability(&quot;mutex&quot;)</code> 属性，用来指定该类具有锁的特性。</p><p>LevelDB 中定义锁的代码也用到了注解，不过稍微不同，用的是 <code>LOCKABLE</code>，代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LOCKABLE</span> Mutex &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">Mutex</span>() = <span class="keyword">default</span>;</span><br><span class="line">  ~<span class="built_in">Mutex</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Mutex</span>(<span class="type">const</span> Mutex&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  Mutex&amp; <span class="keyword">operator</span>=(<span class="type">const</span> Mutex&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>这是因为早期版本的 Clang 使用 lockable 属性，后来引入了更通用的 capability 属性。为了向后兼容，lockable 被保留为 capability(“mutex”) 的别名。所以，这两者是等效的。</p><h2 id="线程安全分析的能力"><a href="#线程安全分析的能力" class="headerlink" title="线程安全分析的能力"></a>线程安全分析的能力</h2><p>上面例子有点简单，其实从本质上来看，这里 clang 静态线程安全分析想做的事情，<strong>就是在编译器提供一种保护资源的能力</strong>。这里资源可以是数据成员，比如前面的 <code>counter_</code>，也可以是提供对某些底层资源访问的函数&#x2F;方法。clang 可以在编译期确保，除非某个线程有访问资源的能力，否则它无法访问资源。</p><p>这里线程安全分析<strong>使用属性来声明这里的资源约束</strong>，属性可以附加到类、方法和数据成员前面。Clang 官方也提供了一系列属性定义宏，可以直接拿来用。LevelDB 中定义了自己的宏，也可以参考。</p><p>前面给的例子中，注解主要用在数据成员上，其实也可以用在函数上。比如 LevelDB 中定义的锁对象 Mutex，在成员函数上用到了这些注解：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LOCKABLE</span> Mutex &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Lock</span><span class="params">()</span> <span class="title">EXCLUSIVE_LOCK_FUNCTION</span><span class="params">()</span> </span>&#123; mu_.<span class="built_in">lock</span>(); &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Unlock</span><span class="params">()</span> <span class="title">UNLOCK_FUNCTION</span><span class="params">()</span> </span>&#123; mu_.<span class="built_in">unlock</span>(); &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AssertHeld</span><span class="params">()</span> <span class="title">ASSERT_EXCLUSIVE_LOCK</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这些注解主要用于标记锁对象的成员函数，告诉编译器这些函数会如何改变锁的状态：</p><ul><li><strong>EXCLUSIVE_LOCK_FUNCTION</strong>: 表示函数会获取互斥锁的独占访问权，调用前锁必须是未持有状态，调用后锁会被当前线程独占；</li><li><strong>UNLOCK_FUNCTION</strong>: 表示函数会释放锁，调用前锁必须是被持有状态（可以是独占或共享），调用后锁会被释放；</li><li><strong>ASSERT_EXCLUSIVE_LOCK</strong>: 用于断言当前线程持有锁的独占权，通常用在调试代码中，确保代码运行在正确的加锁状态下。</li></ul><p>当然这些是 clang 早期的线程安全注解，主要为了锁来命名。上面这几个现在可以用 <a href="https://clang.llvm.org/docs/ThreadSafetyAnalysis.html#acquire-acquire-shared-release-release-shared-release-generic">ACQUIRE(…), ACQUIRE_SHARED(…), RELEASE(…), RELEASE_SHARED(…)</a> 来替代。</p><p>此外，还有其他一些注解，可以参考 Clang 官方的文档 <a href="https://clang.llvm.org/docs/ThreadSafetyAnalysis.html">Thread Safety Analysis</a> 了解更多细节。</p>]]></content>
    
    
    <summary type="html">本文介绍 LevelDB 中使用 Clang 的静态线程安全分析工具，通过在代码中添加宏注解，支持在编译期检测潜在的线程安全问题。</summary>
    
    
    
    <category term="源码剖析" scheme="https://selfboot.cn/categories/%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="LevelDB" scheme="https://selfboot.cn/tags/LevelDB/"/>
    
  </entry>
  
  
  
  
  
  <entry>
    <title>LevelDB 源码阅读：如何设计一个高性能哈希表</title>
    <link href="https://selfboot.cn/2024/12/25/leveldb_source_hashtable/"/>
    <id>https://selfboot.cn/2024/12/25/leveldb_source_hashtable/</id>
    <published>2024-12-25T21:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.713Z</updated>
    
    <content type="html"><![CDATA[<p>哈希表(HashTable) 是一个经典的数据结构，只要写点过代码，应该都有用过哈希表。每种语言都有自己的哈希表实现，基本都是开箱即用。以至于虽然用过哈希表的人很多，但自己动手写过哈希表的人估计没多少吧。</p><p>要设计一个高性能的哈希表，其实还是有不少细节需要考虑的。比如如何处理哈希冲突，如何处理哈希表扩容等。一些成熟的哈希表实现，比如 C++ 标准库中的哈希表，<a href="https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/tr1/hashtable.h">代码量</a>比较大，也比较难理解。</p><p>好在 LevelDB 在实现 LRU Cache 的时候，顺便实现了一个<a href="https://github.com/google/leveldb/blob/main/util/cache.cc#L70">简单高效的哈希表</a>，整体代码写的很精简，麻雀虽小五脏俱全，非常值得学习。本文以 LevelDB 的哈希表实现为例，分析下如何设计一个高性能的哈希表。</p><span id="more"></span><h2 id="LevelDB-实现哈希表的原因"><a href="#LevelDB-实现哈希表的原因" class="headerlink" title="LevelDB 实现哈希表的原因"></a>LevelDB 实现哈希表的原因</h2><p>C++ 标准库已经有了哈希表实现，为什么 LevelDB 还要实现一个自己的哈希表呢？官方是这样说的：</p><blockquote><p>We provide our own simple hash table since it removes a whole bunch<br>of porting hacks and is also faster than some of the built-in hash<br>table implementations in some of the compiler&#x2F;runtime combinations<br>we have tested.  E.g., readrandom speeds up by ~5% over the g++<br>4.4.3’s builtin hashtable.</p></blockquote><p>这里简单总结就是，其他实现有些冗杂，这里自己实现不依赖第三方库，代码精简的同时，也能保证实现的性能。</p><h2 id="LevelDB-哈希表实现原理"><a href="#LevelDB-哈希表实现原理" class="headerlink" title="LevelDB 哈希表实现原理"></a>LevelDB 哈希表实现原理</h2><p>这里 HashTable 实现的思想其实和 C++ 标准库中的哈希表实现差不多，用数组来存储哈希桶。<strong>插入、查找、删除操作的平均时间复杂度都是 O(1)，首先根据 key 的 hash 值定位到具体某个哈希桶，然后在冲突链表上执行相应的操作</strong>。同时，如果插入的时候发现哈希表的负载因子过高，则进行扩容。</p><p>这里补充一点，因为 LevelDB 的哈希表是用来实现 LRU Cache 的，所以这里哈希表的元素类型是 <code>LRUHandle</code>，除了有 key 和 value 两个字段外，还有一个 next_hash 指针，用链地址法来处理哈希冲突。另外，这里也存储了 hash 值，一般是调用方生成后保存下来。这样在后续的查找、插入和删除操作中，可以直接使用这个 hash 值来定位到具体的哈希桶。LRUHandle 的其他字段主要是在 LRU Cache 中使用，这里就不展开了。</p><h3 id="FindPointer-查找位置"><a href="#FindPointer-查找位置" class="headerlink" title="FindPointer 查找位置"></a>FindPointer 查找位置</h3><p>接着我们先看看查找指定 key 的操作，LevelDB 封装了一个基础的 <code>FindPointer()</code> 方法，返回了一个指向 key 的二级指针。<a href="https://github.com/google/leveldb/blob/main/util/cache.cc#L115">具体实现</a>如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Return a pointer to slot that points to a cache entry that</span></span><br><span class="line"><span class="comment">// matches key/hash.  If there is no such cache entry, return a</span></span><br><span class="line"><span class="comment">// pointer to the trailing slot in the corresponding linked list.</span></span><br><span class="line"><span class="function">LRUHandle** <span class="title">FindPointer</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span> </span>&#123;</span><br><span class="line">  LRUHandle** ptr = &amp;list_[hash &amp; (length_ - <span class="number">1</span>)];</span><br><span class="line">  <span class="keyword">while</span> (*ptr != <span class="literal">nullptr</span> &amp;&amp; ((*ptr)-&gt;hash != hash || key != (*ptr)-&gt;<span class="built_in">key</span>())) &#123;</span><br><span class="line">    ptr = &amp;(*ptr)-&gt;next_hash;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里根据 key 的 hash 值定位到具体的哈希桶，如果桶为空，则直接返回指向桶头指针 nullptr 的地址。如果桶不为空，<strong>则用经典的链地址法处理哈希冲突</strong>。遍历哈希桶上的冲突链表，如果找到对应的 key，则返回指向该节点的二级指针。如果遍历完链表都没有找到，则返回链表的尾指针地址。</p><p>这里比较巧妙的是<strong>返回了一个二级指针，这样就能在查找、插入和删除操作中都复用该方法</strong>。在查找时，直接解引用返回的指针就能获得目标节点。在插入时，通过这个指针可以既能检查是否存在相同key的节点，又能直接在正确的位置插入新节点。在删除时，可以直接通过修改这个指针指向的值来完成节点的移除，而不需要额外记录前驱节点。</p><h3 id="Remove-删除节点"><a href="#Remove-删除节点" class="headerlink" title="Remove 删除节点"></a>Remove 删除节点</h3><p>查找节点就是直接调前面的 <code>FindPointer</code> 方法，然后解引用即可，这里不再赘述。我们来看看删除 key 的 <a href="https://github.com/google/leveldb/blob/main/util/cache.cc#L95">Remove 方法</a>，代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LRUHandle* <span class="title">Remove</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span> </span>&#123;</span><br><span class="line">  LRUHandle** ptr = <span class="built_in">FindPointer</span>(key, hash);</span><br><span class="line">  LRUHandle* result = *ptr;</span><br><span class="line">  <span class="keyword">if</span> (result != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    *ptr = result-&gt;next_hash;</span><br><span class="line">    --elems_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很简单吧！为了在一个链表中删除指定节点，这里先用 FindPointer 找到指向链表节点指针的地址，然后<strong>将要删除节点的下一个节点地址(result-&gt;next_hash)赋值给原指针位置</strong>，就完成了删除操作。本方法返回了被删除的节点指针，方便调用者进行后续处理（如内存释放等）。这里的实现方式，<strong>不需要额外记录前驱节点，操作简单高效，也能够正确处理链表头节点的删除情况</strong>。</p><p>这里的删除方法可以优雅下面的所有情况：</p><table><thead><tr><th>情况</th><th>描述</th><th>初始状态</th><th>删除后状态</th></tr></thead><tbody><tr><td>1</td><td>删除链表第一个节点 A</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; [C] –&gt; nullptr</td><td>list_[i] –&gt; [B] –&gt; [C] –&gt; nullptr</td></tr><tr><td>2</td><td>删除链表中间节点 B</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; [C] –&gt; nullptr</td><td>list_[i] –&gt; [A] –&gt; [C] –&gt; nullptr</td></tr><tr><td>3</td><td>删除链表最后节点 C</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; [C] –&gt; nullptr</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; nullptr</td></tr><tr><td>4</td><td>删除链表唯一节点 A</td><td>list_[i] –&gt; [A] –&gt; nullptr</td><td>list_[i] –&gt; nullptr</td></tr><tr><td>5</td><td>要删除的key不存在</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; nullptr</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; nullptr</td></tr><tr><td>6</td><td>hash桶为空</td><td>list_[i] –&gt; nullptr</td><td>list_[i] –&gt; nullptr</td></tr></tbody></table><h3 id="Insert-插入节点"><a href="#Insert-插入节点" class="headerlink" title="Insert 插入节点"></a>Insert 插入节点</h3><p>插入节点的方法 <a href="https://github.com/google/leveldb/blob/main/util/cache.cc#L79">Insert</a> 和删除节点有点类似，也是先找到插入位置，然后进行插入操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LRUHandle* <span class="title">Insert</span><span class="params">(LRUHandle* h)</span> </span>&#123;</span><br><span class="line">  LRUHandle** ptr = <span class="built_in">FindPointer</span>(h-&gt;<span class="built_in">key</span>(), h-&gt;hash);</span><br><span class="line">  LRUHandle* old = *ptr;</span><br><span class="line">  h-&gt;next_hash = (old == <span class="literal">nullptr</span> ? <span class="literal">nullptr</span> : old-&gt;next_hash);</span><br><span class="line">  *ptr = h;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里第 4 行，用二级指针一次性处理了下面所有情况，文章后面会再详细介绍这里的二级指针。</p><table><thead><tr><th>情况</th><th>描述</th><th>初始状态</th><th>插入后状态</th><th>返回值</th></tr></thead><tbody><tr><td>1</td><td>插入到空桶</td><td>list_[i] –&gt; nullptr</td><td>list_[i] –&gt; [H] –&gt; nullptr</td><td>nullptr</td></tr><tr><td>2</td><td>插入时key已存在(第一个节点)</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; nullptr</td><td>list_[i] –&gt; [H] –&gt; [B] –&gt; nullptr</td><td>A</td></tr><tr><td>3</td><td>插入时key已存在(中间节点)</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; [C] –&gt; nullptr</td><td>list_[i] –&gt; [A] –&gt; [H] –&gt; [C] –&gt; nullptr</td><td>B</td></tr><tr><td>4</td><td>插入时key已存在(最后节点)</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; nullptr</td><td>list_[i] –&gt; [A] –&gt; [H] –&gt; nullptr</td><td>B</td></tr><tr><td>5</td><td>插入新key(非空桶)</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; nullptr</td><td>list_[i] –&gt; [A] –&gt; [B] –&gt; [H] –&gt; nullptr</td><td>nullptr</td></tr></tbody></table><p>这里插入后，还会根据 old 判断是否是新增节点，如果是新增节点，则更新哈希表的元素数量，并且要判断是否需要动态扩容，接下来看看这里扩容逻辑。</p><h2 id="高负载因子动态扩容"><a href="#高负载因子动态扩容" class="headerlink" title="高负载因子动态扩容"></a>高负载因子动态扩容</h2><p>对于某个固定桶数量的哈希表，<strong>随着插入元素的变多，哈希冲突的概率会变大</strong>。极端情况下，可能每个 key 都有很长的冲突链表，导致 hashtable 的查找和删除性能退化。为了<strong>衡量这里哈希冲突的严重程度</strong>，我们可以定义<strong>负载因子 &#x3D; 哈希表的元素数量 &#x2F; 哈希桶数量</strong>，一旦这个值超过某个阈值，则需要进行扩容。</p><p>前面 Insert 方法在插入元素的时候，会统计当前 hashtable 的元素数量。一旦负载因子超过阈值 1，则调用 <code>Resize()</code> 进行扩容。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (old == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    ++elems_;</span><br><span class="line">    <span class="keyword">if</span> (elems_ &gt; length_) &#123;</span><br><span class="line">    <span class="comment">// Since each cache entry is fairly large, we aim for a small</span></span><br><span class="line">    <span class="comment">// average linked list length (&lt;= 1).</span></span><br><span class="line">    <span class="built_in">Resize</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里<strong>扩容第一个要解决的问题就是决定新的哈希桶数量</strong>。LevelDB 的实现如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Resize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">uint32_t</span> new_length = <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">while</span> (new_length &lt; elems_) &#123;</span><br><span class="line">      new_length *= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实在标准库的 vector 扩容时候，也是选择按照 2 的整数倍进行扩容。这里<strong>扩容系数如果选择的太大，可能浪费比较多空间，选择倍数太小，可能导致频繁扩容</strong>。工程实践中，一般会选择 2 作为扩容倍数。</p><p>决定好新的桶大小后，就先创建这个更大容量的哈希桶，然后<strong>遍历所有旧的哈希桶，对于每个桶，还要遍历冲突链表上的每个 key，然后将每个 key 插入到新的链表上</strong>。核心的实现如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Resize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    LRUHandle** new_list = <span class="keyword">new</span> LRUHandle*[new_length];</span><br><span class="line">    <span class="built_in">memset</span>(new_list, <span class="number">0</span>, <span class="built_in">sizeof</span>(new_list[<span class="number">0</span>]) * new_length);</span><br><span class="line">    <span class="type">uint32_t</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; length_; i++) &#123;</span><br><span class="line">      LRUHandle* h = list_[i];</span><br><span class="line">      <span class="keyword">while</span> (h != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        LRUHandle* next = h-&gt;next_hash;</span><br><span class="line">        <span class="comment">// 头插法插入到新哈希表</span></span><br><span class="line">        h = next;</span><br><span class="line">        count++;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">assert</span>(elems_ == count);</span><br><span class="line">    <span class="keyword">delete</span>[] list_;</span><br><span class="line">    list_ = new_list;</span><br><span class="line">    length_ = new_length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里在 Resize 的时候，每次成功一个 key 到新的哈希表中，都会更新哈希表的元素数量。之后会用 assert 断言来检查扩容后，哈希表的元素数量是否正确。所有 key 都插入到新哈希表后，就可以回收旧哈希表的内存，然后替换 list_ 为新哈希表，并更新哈希表容量。</p><p>前面省略了关键的插入部分逻辑，这里<strong>在 while 循环中会遍历旧哈希表冲突链表中的每个 key，然后用头插法插入到新哈希表中</strong>，下面看看头插法的详细实现。</p><h2 id="头插法优化链表插入"><a href="#头插法优化链表插入" class="headerlink" title="头插法优化链表插入"></a>头插法优化链表插入</h2><p>这里前面 Resize 省略的头插法的核心代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="type">void</span> <span class="title">Resize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; length_; i++) &#123;</span><br><span class="line">      LRUHandle* h = list_[i];</span><br><span class="line">      <span class="keyword">while</span> (h != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="comment">// ... </span></span><br><span class="line">        <span class="type">uint32_t</span> hash = h-&gt;hash;</span><br><span class="line">        LRUHandle** ptr = &amp;new_list[hash &amp; (new_length - <span class="number">1</span>)];</span><br><span class="line">        h-&gt;next_hash = *ptr;</span><br><span class="line">        *ptr = h;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>头插法的核心思想是：<strong>将新节点插入到链表的头部</strong>。假设原始链表中如下：</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">list_</span><span class="title">[</span><span class="comment">i</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="title">[</span><span class="comment">A</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="title">[</span><span class="comment">B</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="title">[</span><span class="comment">C</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="comment">nullptr</span></span><br></pre></td></tr></table></figure><p><strong>重哈希过程会依次处理 A、B、C 三个节点，将其插入到新哈希表中</strong>。如果在新的哈希表中，A、B 个节点依旧在同一个桶中，则重哈希后的链表状态如下：</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">new_list</span><span class="title">[</span><span class="comment">hash_a</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="title">[</span><span class="comment">B</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="title">[</span><span class="comment">A</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="comment">nullptr</span></span><br><span class="line"><span class="comment">new_list</span><span class="title">[</span><span class="comment">hash_c</span><span class="title">]</span> <span class="literal">--</span>&gt; <span class="title">[</span><span class="comment">C</span><span class="title">]</span> <span class="literal">--</span>&gt;<span class="comment">nullptr</span></span><br></pre></td></tr></table></figure><p>这里 A 和 B 在新的链表中依旧在同一个桶中，但是 A 和 B 的顺序反过来了。相比传统的遍历到链表尾部进行插入，<strong>头插法的实现比较简单，只用在头部插入，不需要遍历到链表尾部，所以操作时间复杂度是O(1)</strong>。并且使用头插法也不需要维护尾指针，<strong>空间效率更高</strong>。此外，<strong>头插法还有缓存局部性，最近插入的节点在链表头部，对于某些访问模式下查找效率更高</strong>。   </p><h2 id="C-二级指针详解"><a href="#C-二级指针详解" class="headerlink" title="C++ 二级指针详解"></a>C++ 二级指针详解</h2><p>前面链表的操作代码十分简介，没有各种复杂的条件判断，正是因为用好了二级指针，那么要怎么理解 C++ 中的二级指针呢？<strong>C++ 中的对象有值和对应内存地址，指针存储的是对象的内存地址，而二级指针存储的是指针的地址</strong>。</p><p>举个例子来看更清晰些，比如某个 bucket 上有 <code>bucket-&gt;A-&gt;B-&gt;nullptr</code> 这样一个冲突链表，对应可以用下面 C++ 代码表示：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LRUHandle *node_a;    <span class="comment">// 地址：0x100，数据：&#123;value: &quot;A&quot;, next_hash: 0x200&#125;</span></span><br><span class="line">LRUHandle *node_b;    <span class="comment">// 地址：0x200，数据：&#123;value: &quot;B&quot;, next_hash: nullptr&#125;</span></span><br><span class="line">node_a-&gt;next_hash = node_b;</span><br><span class="line">LRUHandle* bucket = node_a;   <span class="comment">// 地址：0x300，数据：0x100</span></span><br></pre></td></tr></table></figure><p>当然这里内存地址的具体值只是为了方便理解，实际运行的内存地址位置会不一样。现在有一个新的节点 node_h，地址是 0x500，如果要在上面链表中用头插法插入该节点，核心代码只有 3 行，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LRUHandle** ptr = &amp;new_list[hash &amp; (new_length - <span class="number">1</span>)];</span><br><span class="line">h-&gt;next_hash = *ptr;    </span><br><span class="line">*ptr = h;</span><br></pre></td></tr></table></figure><p>我们来看这里每一行带来的变化。第一行执行完，这里整体内存布局如下：</p><table><thead><tr><th>变量名</th><th>内存地址</th><th>存储的值</th></tr></thead><tbody><tr><td>ptr</td><td>0x400</td><td>0x300</td></tr><tr><td>bucket</td><td>0x300</td><td>0x100</td></tr><tr><td>node_a</td><td>0x100</td><td>{value: “A”, next_hash: 0x200}</td></tr><tr><td>node_b</td><td>0x200</td><td>{value: “B”, next_hash: nullptr}</td></tr></tbody></table><p>接着执行 <code>h-&gt;next_hash = *ptr</code> 把 node_h 的 next_hash 指向 *ptr，这里 *ptr 拿到的就是 A 的地址，整体内存布局如下：</p><table><thead><tr><th>变量名</th><th>内存地址</th><th>存储的值</th></tr></thead><tbody><tr><td>ptr</td><td>0x400</td><td>0x300</td></tr><tr><td>bucket</td><td>0x300</td><td>0x100 (*ptr)</td></tr><tr><td>node_h</td><td>0x500</td><td>{value: “H”, next_hash: <strong>0x100</strong>}</td></tr><tr><td>node_a</td><td><strong>0x100</strong></td><td>{value: “A”, next_hash: <strong>0x200</strong>}</td></tr><tr><td>node_b</td><td><strong>0x200</strong></td><td>{value: “B”, next_hash: nullptr}</td></tr></tbody></table><p>这时候我们已经建好了 <strong>H-&gt;A-&gt;B-&gt;nullptr</strong> 链。只是 bucket 还是指向了 A，所以要接着执行 <code>*ptr = h</code> 让 bucket 指向 node_h 的地址，这一步完成后整体内存布局如下：</p><table><thead><tr><th>变量名</th><th>内存地址</th><th>存储的值</th></tr></thead><tbody><tr><td>ptr</td><td>0x400</td><td>0x300</td></tr><tr><td>bucket</td><td>0x300</td><td><strong>0x500</strong></td></tr><tr><td>node_h</td><td><strong>0x500</strong></td><td>{value: “H”, next_hash: <strong>0x100</strong>}</td></tr><tr><td>node_a</td><td><strong>0x100</strong></td><td>{value: “A”, next_hash: <strong>0x200</strong>}</td></tr><tr><td>node_b</td><td><strong>0x200</strong></td><td>{value: “B”, next_hash: nullptr}</td></tr></tbody></table><p>至此，我们就完成了 <code>p-&gt;bucket-&gt;H-&gt;A-&gt;B-&gt;nullptr</code> 的构建。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们详细分析了 LevelDB 的哈希表实现，看完应该能设计一个高性能的哈希表了吧，哈哈。最后总结下 LevelDB 哈希表实现的关键点：</p><ol><li><strong>巧妙运用二级指针</strong>：通过返回指向节点指针的指针，使得 FindPointer 方法能够在查找、插入和删除操作中复用，大大简化了链表操作的代码实现。</li><li><strong>高效的冲突处理</strong>：采用链地址法处理哈希冲突，并通过头插法优化链表插入操作，避免了遍历到链表尾部的开销。</li><li><strong>动态扩容机制</strong>：通过监控负载因子，在合适的时机进行 2 倍扩容，在空间利用和性能之间取得平衡。</li><li><strong>简洁优雅的实现</strong>：整个实现代码量很小，但包含了哈希表的所有核心功能，是一个非常好的学习范例。</li></ol><p>虽然这里哈希表主要用于 LevelDB 的 LRU Cache，但其中的很多设计思想对于实现其他高性能数据结构都很有参考价值。</p>]]></content>
    
    
    <summary type="html">以 LevelDB 的哈希表实现为例，分析了如何设计一个高性能的哈希表。通过二级指针，实现了链表的插入、删除和查找操作，并且通过头插法优化了链表插入操作，并分析了链表扩容的实现。最后，通过一个例子详细介绍了 C++ 中的二级指针。</summary>
    
    
    
    <category term="源码剖析" scheme="https://selfboot.cn/categories/%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="LevelDB" scheme="https://selfboot.cn/tags/LevelDB/"/>
    
  </entry>
  
  
  
  
  
  <entry>
    <title>LevelDB 源码阅读：如何分析跳表的时间复杂度？</title>
    <link href="https://selfboot.cn/2024/09/24/leveldb_source_skiplist_time_analysis/"/>
    <id>https://selfboot.cn/2024/09/24/leveldb_source_skiplist_time_analysis/</id>
    <published>2024-09-24T21:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.713Z</updated>
    
    <content type="html"><![CDATA[<p>在上篇 <a href="https://selfboot.cn/2024/09/09/leveldb_source_skiplist/">LevelDB 源码阅读：跳表的原理、实现以及可视化</a>中，详细分析了 LevelDB 中跳表的实现。然后在 <a href="https://selfboot.cn/2024/09/18/leveldb_source_skiplist_test/">LevelDB 源码阅读：如何正确测试跳表的并行读写？</a> 中，分析了 LevelDB 跳表的测试代码，最后还剩下一个问题，怎么分析跳表的时间复杂度呢？</p><p>在分析完跳表的时间复杂度之后，就能明白 LevelDB 中<strong>概率值和最大高度的选择</strong>，以及 Redis 为什么选择不同的最大高度。最后本文也会提供一个简单的压测代码，来看看跳表的性能如何。</p><p>本文不会有很高深的数学知识，只涉及简单的概率论，可以放心往下看。跳表的性能分析有不少思路很值得借鉴，希望本文能抛砖引玉，给大家带来一些启发。</p><h2 id="跳表性能分析拆解"><a href="#跳表性能分析拆解" class="headerlink" title="跳表性能分析拆解"></a>跳表性能分析拆解</h2><p>在知道 LevelDB 的原理和实现后，我们可以推测出来，在极端情况下，每个节点的高度都是 1，那么跳表的查找、插入、删除操作的时间复杂度都会退化到 O(n)。在这种情况下，性能比平衡树差了不少。当然，因为有随机性在里面，所以<strong>没有输入序列能始终导致性能最差</strong>。</p><p>那么跳表的平均性能如何呢？前面给出过结论，和平衡树的平均性能差不多。引入一个简单的随机高度，就能保证跳表的平均性能和平衡树差不多。<strong>这背后有没有什么分析方法，能够分析跳表的性能呢</strong>？</p><span id="more"></span><p>还得看论文，论文中给出了一个不错的分析方法，不过这里的思路其实有点难想到，理解起来也有点费劲。我会把问题尽量拆分，然后一步步来推导整个过程，每一步涉及到的数学推导也尽量给出来。哈哈，<strong>这不就是思维链嘛，拆解问题并逐步推理，是人和 AI 解决复杂问题的必备技能啊</strong>。这里的推导可以分为几个小问题：</p><ol><li>跳表的查找、插入和删除操作，哪部分操作最影响耗时？</li><li>对于查找操作，假设从任意层 k 开始往下找，这里的平均复杂度是多少(遍历多少次)？ </li><li>有没有什么办法，可以在链表中<strong>找到某个层数</strong>，从这层开始查找效率最高，并且遍历次数能代表平均性能？</li><li>能不能找到一个公式，来计算总的时间复杂度，并算出这里的平均复杂度上限？</li></ol><p>好了，下面我们逐个问题分析。</p><h2 id="跳表操作瓶颈"><a href="#跳表操作瓶颈" class="headerlink" title="跳表操作瓶颈"></a>跳表操作瓶颈</h2><p>第一个小问题比较简单。在前文讲跳表的原理和实现中，我们知道，对于插入和删除操作，也需要先通过查找操作找到对应的位置。之后就是几个指针操作，代价都是常量时间，可以忽略。所以，<strong>跳表操作的时间复杂度就是看查找操作的复杂度</strong>。</p><p>查找操作的过程就是往右，往下搜索跳表，直到找到目标元素。如果我们能知道这里搜索的平均复杂度，那么就可以知道跳表操作的平均复杂度。直接分析查找操作的平均复杂度，有点无从下手。按照 LevelDB 里面的实现，每次是从<strong>当前跳表中节点的最高层数</strong>开始找。但是节点高度是随机的，最高层数也是随机的，似乎没法分析从随机高度开始的查找操作的平均复杂度。</p><h2 id="跳-k-层的期望步数"><a href="#跳-k-层的期望步数" class="headerlink" title="跳 k 层的期望步数"></a>跳 k 层的期望步数</h2><p>先放弃直接分析，来尝试回答前面第二个问题。<strong>假设从任意层 k 开始往下找，平均要多少次才能找到目标位置</strong>呢？这里的分析思路比较跳跃，我们<strong>反过来分析从目标位置，往上往左查找，平均要多少步才能往上查 k 层。并且假设链表中节点高度是在反向查找过程中，根据概率 p 来随机决定的</strong>。</p><p>这种假设和分析过程得到的平均查找次数和<strong>真实查找情况等价</strong>吗？我们知道往右往下执行查找的时候，节点的高度都是已经决定的了。但是考虑到节点的高度本来就是随机决定的，<strong>假设反向查找时候来决定高度，并且逆向整个搜索过程，在统计上没有什么不同</strong>。</p><p>接下来我们假设<strong>当前处在节点 x 的任意一层 i (下图中的情形 a)，从这个位置往上查 k 层置需要 $ C(k) $ 步</strong>。我们不知道节点 x 上面还有没有层，也不知道节点 x 的左边还有没有节点(下图中<strong>用阴影问号</strong>表示这种未知)。再假设 x 不是 header 节点，左边还有节点（其实这里分析的话可以假设左边有无穷多节点）。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240914_leveldb_source_skiplist_more.png" alt="LevelDB 时间复杂度分析从 K 层查找复杂度(图片来自论文)"></p><p>那么整个链表的节点情况有两种可能，整体如上图：</p><ul><li>情形 b: 节点 x 一共就是 i 层，在左边有节点，查找的时候需要从左边节点的第 i 层水平跳到 x 的第 i 层。逆向分析的话，因为按照 $ p $ 的概率决定是否有更高层，所以这里处于情形 b 的概率是 $ 1 - p $。然后<strong>左边节点和 x 在同一层，往上查 k 层仍然需要 $ C(k) $ 步</strong>。因此这种情况下期望的查找步数是: $ (1 - p) * (C(k) + 1) $。</li><li>情形 c: 节点 x 层高大于 i，那么查找的时候需要从 x 的第 i+1 层往下跳到第 i 层。逆向分析的话，因为按照 $ p $ 的概率决定是否有更高层，所以这里处于情形 c 的概率是 $ p $。然后<strong>从 i+1 层往上查 k 层，等价于从第 i 层往上查找 k-1 层，需要 $ C(k-1) $ 步</strong>。因此期望的查找步数是: $ p * (C(k-1) + 1) $。</li></ul><p>也就是说，对于从任意层 i 开始查找，往上跳 $ k $ 层需要的期望步数为：</p><p>$$ \begin{align}<br>C(k) &amp;&#x3D; (1 - p) * (C(k) + 1) + p * (C(k-1) + 1)<br>\end{align} $$</p><p>化简这个方程得到下面结果：</p><p>$$<br>\begin{align}<br>C(k) &amp;&#x3D; 1&#x2F;p + C(k-1)<br>\\<br>C(k) &amp;&#x3D; k&#x2F;p<br>\end{align}<br>$$</p><p>这里从任意层 i 开始查找往上跳 k 层需要的期望步数 $ k&#x2F;p $ ，也等价于从第 k 层开始正常步骤查找，到最底层目标位置需要的期望步数。这个公式很重要，只要<strong>理解了这里的逆向分析步骤，最后公式也比较好推导出来</strong>。但是用这个公式还是没法直接分析出跳表的平均性能，中间缺少了点什么。</p><h2 id="从哪层开始搜索？"><a href="#从哪层开始搜索？" class="headerlink" title="从哪层开始搜索？"></a>从哪层开始搜索？</h2><p>从上面分析可以看到从第 K 层查找到底层的时间复杂度是 $ k&#x2F;p $，那么实际跳表查找的时候，从哪层开始搜索比较好呢？在<a href="https://selfboot.cn/2024/09/09/leveldb_source_skiplist/">LevelDB 源码阅读：跳表的原理、实现以及可视化</a>可以知道跳表中节点的层高是随机的，<strong>对于其中某层，可能有多个节点，越往上层，节点数越少</strong>。</p><p>LevelDB 的实现中，是<strong>从跳表的最高层开始查找</strong>的。但其实如果从最高层开始搜索，可能会做很多无用功。比如下面的跳表中，其中 79 对应的层非常高，从这层开始搜索，需要往下走很多步，都是无效搜索。如果从 5 对应的层高开始搜索，则节省了不少搜索步骤。下图来自<a href="https://gallery.selfboot.cn/zh/algorithms/skiplist">跳表的可视化页面</a>：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240920_leveldb_source_skiplist_more_search_start.png" alt="LevelDB 跳表查找的开始层分析"></p><p>理想情况下，我们希望从一个”<strong>合适</strong>“的层级开始搜索。论文中是这样定义合适的层：<strong>在该层期望看到 $1&#x2F;p$ 个节点</strong>。因为我们的 p 一般取值 1&#x2F;2，1&#x2F;4 这样的值，所以这里一般从有 2 或者 4 个节点的层开始搜索。从这个层开始搜索，不至于做无用功，也不至于从太低层开始的话，失去跳表的优势。接下来只需要知道<strong>这样的层，平均有多高</strong>，然后结合前面的 $ k&#x2F;p $ 就可以知道整体的搜索复杂度了。</p><h3 id="层高推算"><a href="#层高推算" class="headerlink" title="层高推算"></a>层高推算</h3><p>现在来看看具体的推算步骤。假设一共有 $ n $ 个节点，然后在第 $ L $ 层有 $ 1&#x2F;p $ 个节点。因为每次以 $ p $ 的概率决定是否向上层跳，所以有：</p><p>$$ n * p^{L-1} &#x3D; 1&#x2F;p $$</p><p>注意 L 层跳 $L-1$ 次，所以这里的 $ p^{L-1} $ 是 L-1 次幂。将等式两边同时乘以 p：</p><p>$$<br>\begin{align}<br>(n \cdot p^{L-1}) \cdot p &amp;&#x3D; \frac{1}{p} \cdot p \\<br>n \cdot p^{L} &amp;&#x3D; 1<br>\end{align}<br>$$</p><p>然后两边取对数 $ log_{1&#x2F;p} $，如下，这里用到了对数的乘法法则和幂法则：</p><p>$$<br>\begin{align}<br>\log_{1&#x2F;p} (n \cdot p^{L}) &amp;&#x3D; \log_{1&#x2F;p} 1<br>\\<br>\log_{1&#x2F;p} n + L \cdot \log_{1&#x2F;p} p &amp;&#x3D; 0<br>\end{align}<br>$$</p><p>接着进行简化：</p><p>$$<br>\begin{align}<br>log_{1&#x2F;p} p &amp;&#x3D; -1<br>\\<br>log_{1&#x2F;p} n + L * (-1) &amp;&#x3D; 0<br>\end{align}<br>$$</p><p>所以我们得到：</p><p>$$<br>L &#x3D; log_{1&#x2F;p} n<br>$$</p><p>也就是说，在 $ L &#x3D; log_{1&#x2F;p} n$ 层，期望有 $ 1&#x2F;p $ 个节点。这里再补充下上面的推导过程用到的对数的法则：</p><p>$$<br>\begin{align}<br>\log(xy) &amp;&#x3D; \log(x) + \log(y)  &amp;\text{对数的乘法法则}<br>\\<br>\log(x^n) &amp;&#x3D; n \cdot \log(x) &amp;\text{对数的幂法则}<br>\end{align}<br>$$</p><h2 id="总时间复杂度"><a href="#总时间复杂度" class="headerlink" title="总时间复杂度"></a>总时间复杂度</h2><p>好了，到此关键部分已经分析完了，下面综合上面的结论来看看总的时间复杂度。对于有 $n$ 个节点的跳表，可以将查找过程分为两部分，一个是从第 $L$ 层到最底层，另一个是从顶部到第 $L$ 层。</p><p>从第 $L$ 层到最底层，按照前面的等价逆向分享，相当于从底层往上爬 $L$ 层，这里爬升的成本是：</p><p>$$<br>\begin{align}<br>O(n) &amp;&#x3D; \frac{L}{p}<br>\\<br>O(n) &amp;&#x3D; \frac{log_{1&#x2F;p} n}{p}<br>\end{align}<br>$$</p><p>接着是从顶部到第 $L$ 层，这部分也是分为向左和向上。向左的步数最多也就是 $L$ 层的节点数 $\frac{1}{p}$。向上的话，从 LevelDB 的实现中，最高层次限制了 12 层，所以向上的步数也是一个常量。其实就算不限制整个跳表的高度，它的最大高度期望也可以计算出来(这里忽略计算过程，不是很重要)：</p><p>$$ H ≤ L + \frac{1}{1-p}$$</p><p>所以不限制高度的情况下，这里的整体时间复杂度上限是:</p><p>$$ O(n) &#x3D; \frac{log_{1&#x2F;p} n}{p} + \frac{1}{1-p} + \frac{1}{p} $$</p><p>上面的时间复杂度其实也就是 $ O(log n) $。最后再多说一点，虽然从第 L 层开始搜索比较好，但是实际实现中也没必要这样。像 LevelDB 一样，限制了整体跳表高度后，从当前跳表的最大高度开始查找，性能也不会差多少的。因为从第 L 层开始往上的搜索代价是常数级别的，所以没有大影响。此外，其实实现中最大层数也是根据 p 和 n 推算的一个接近 L 层的值。</p><h2 id="P-值选择"><a href="#P-值选择" class="headerlink" title="P 值选择"></a>P 值选择</h2><p>论文中还分析了 p 值选择对性能和空间占用的影响，这里也顺便提下。显而易见，p 值越小，空间效率越高（每个节点的指针更少），但搜索时间通常会增加。整体如下表：</p><table><thead><tr><th>p</th><th>Normalized search times (i.e., normalized L(n)&#x2F;p)</th><th>Avg. # of pointers per node (i.e., 1&#x2F;(1-p))</th></tr></thead><tbody><tr><td>1&#x2F;2</td><td>1</td><td>2</td></tr><tr><td>1&#x2F;e</td><td>0.94…</td><td>1.58…</td></tr><tr><td>1&#x2F;4</td><td>1</td><td>1.33…</td></tr><tr><td>1&#x2F;8</td><td>1.33…</td><td>1.14…</td></tr><tr><td>1&#x2F;16</td><td>2</td><td>1.07…</td></tr></tbody></table><p>论文推荐这里的 p 值选择 1&#x2F;4，既有不错的时间常数，每个节点平均空间也比较少。LevelDB 中实现选择了 p &#x3D; 1&#x2F;4，Redis 的 <a href="https://github.com/redis/redis/blob/438cfed70a203c8b708e6df200d1ad82c87f2901/src/t_zset.c#L126">zset 实现中</a>也是选择了 <a href="https://github.com/redis/redis/blob/unstable/src/server.h#L516">ZSKIPLIST_P</a>&#x3D;1&#x2F;4。</p><p>此外关于最高层数选择，<a href="https://github.com/google/leveldb/blob/main/db/skiplist.h#L100">LevelDB 中</a>实现选择了 12 层，<a href="https://github.com/redis/redis/blob/438cfed70a203c8b708e6df200d1ad82c87f2901/src/t_zset.c#L515C1-L515C71">Redis 中</a>选择了 32 层。这里是基于什么考虑呢？</p><p>回到前面的分析中，我们知道从一个合适的层开始搜索效率最高，这里合适的层是 $ log_{1&#x2F;p} n $。现在 p 已经确定是 1&#x2F;4，只要能预估跳表的最大节点数 N，那么就能知道合适的层是多少。然后设置最大层数为这个值，就能保证跳表的平均性能。下面是 p&#x3D;1&#x2F;4 时，不同节点数对应的合适层数：</p><table><thead><tr><th>概率值 p</th><th>节点数 n</th><th>合适的层数(最大层)</th></tr></thead><tbody><tr><td>1&#x2F;4</td><td>$2^{16}$</td><td>8</td></tr><tr><td>1&#x2F;4</td><td>$2^{20}$</td><td>10</td></tr><tr><td>1&#x2F;4</td><td>$2^{24}$</td><td>12</td></tr><tr><td>1&#x2F;4</td><td>$2^{32}$</td><td>16</td></tr><tr><td>1&#x2F;4</td><td>$2^{64}$</td><td>32</td></tr></tbody></table><p>Redis 中选择了 32 层，因为要支持最多 2^64 个元素。LevelDB 中在 Memtable 和 SSTable 中用跳表存储 key，里面 key 的数量不会很多，因此选择了 12 层，可以最大支持 2^24 个元素。</p><h2 id="性能测试-benchmark"><a href="#性能测试-benchmark" class="headerlink" title="性能测试 benchmark"></a>性能测试 benchmark</h2><p>LevelDB 中没有对跳表的性能进行测试，我们自己来简单写一个。这里用 Google 的 benchmark 库，来测试跳表的插入和查找性能。为了方便对比，这里也加了一个对 unordered_map 的测试，看看这两个的性能差异。跳表插入的测试核心代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">BM_SkipListInsertSingle</span><span class="params">(benchmark::State&amp; state)</span> </span>&#123;</span><br><span class="line">  TestContext context;</span><br><span class="line">  <span class="built_in">SetUp</span>(state, &amp;context);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> _ : state) &#123;</span><br><span class="line">    context.skiplist-&gt;<span class="built_in">Insert</span>(context.key_to_insert);</span><br><span class="line">    benchmark::<span class="built_in">DoNotOptimize</span>(context.skiplist);</span><br><span class="line">    state.<span class="built_in">PauseTiming</span>();</span><br><span class="line">    <span class="built_in">SetUp</span>(state, &amp;context);</span><br><span class="line">    state.<span class="built_in">ResumeTiming</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  state.<span class="built_in">SetLabel</span>(<span class="string">&quot;SkipList Single Insert&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里针对不同跳表和 unordered_map 表的长度，执行随机数字插入和查找，然后计算平均耗时。完整的代码在 <a href="https://gist.github.com/selfboot/9e236b4811aaf94b38762bcc88995540">skiplist_benchmark</a>。注意这里 benchmark 会自动决定 Iterations 的次数，跳表插入每次初始化有点久，所以这里手动指定了 Iterations 为 1000。</p><blockquote><p>.&#x2F;skiplist_benchmark  –benchmark_min_time&#x3D;1000x</p></blockquote><p>运行结果如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240924_leveldb_source_skiplist_more_benchmark.png" alt="LevelDB 跳表插入、查找性能测试"></p><p>虽然这里是编译的 Debug 版本，没有优化。但是根据这里的测试结果可以看到，虽然跳表长度增加，但是插入耗时并没有显著增加。查找性能和 unordered_map 相比，差别也不是很大。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文是 LevelDB 跳表的最后一篇了，详细分析了跳表的时间复杂度。通过拆解查找问题，逆向整个查找过程，以及找到合适的 L 层，最后推导出跳表的时间复杂度。在知道时间复杂度的基础上，进而推导如何选择概率 p，以及 redis 和 LevelDB 中跳表的最大高度选择原因。最后通过简单的 benchmark 测试了跳表的性能，并与 unordered_map 进行了对比。</p><p>本系列其他两篇文章：</p><ul><li><a href="https://selfboot.cn/2024/09/18/leveldb_source_skiplist_test/">LevelDB 源码阅读：如何正确测试跳表的并行读写？</a></li><li><a href="https://selfboot.cn/2024/09/09/leveldb_source_skiplist/">LevelDB 源码阅读：跳表的原理、实现以及可视化</a></li></ul>]]></content>
    
    
    <summary type="html">本文详细分析了跳表的时间复杂度。通过拆解查找问题，逆向整个查找过程，以及找到合适的 L 层，最后推导出跳表的时间复杂度。在知道时间复杂度的基础上，进而推导如何选择概率 p，以及 redis 和 LevelDB 中跳表的最大高度选择原因。最后通过简单的 benchmark 测试了跳表的性能，并与 unordered_map 进行了对比。</summary>
    
    
    
    <category term="源码剖析" scheme="https://selfboot.cn/categories/%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="LevelDB" scheme="https://selfboot.cn/tags/LevelDB/"/>
    
  </entry>
  
  
  
  
  
  <entry>
    <title>LevelDB 源码阅读：如何正确测试跳表的并行读写？</title>
    <link href="https://selfboot.cn/2024/09/18/leveldb_source_skiplist_test/"/>
    <id>https://selfboot.cn/2024/09/18/leveldb_source_skiplist_test/</id>
    <published>2024-09-18T21:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.712Z</updated>
    
    <content type="html"><![CDATA[<p>在上篇 <a href="https://selfboot.cn/2024/09/09/leveldb_source_skiplist/">LevelDB 源码阅读：跳表的原理、实现以及可视化</a>中，从当前二叉搜索树和平衡树的一些缺点出发，引出了跳表这种数据结构。然后结合论文，解释了跳表的实现原理。接着详细分析了 LevelDB 的代码实现，包括迭代器实现，以及<strong>并行读的极致性能优化</strong>。最后还提供了一个可视化页面，可以直观看到跳表的构建过程。</p><p>但是还有两个问题：</p><ol><li>怎么测试 LevelDB 跳表的代码，保证功能的正确性？特别是怎么<strong>保证读写并行情况下跳表实现的正确性</strong>。</li><li>怎么<strong>定量分析</strong>跳表的时间复杂度？</li></ol><p>接下来通过分析 LevelDB 的测试代码，先来回答第一个问题。跳表的性能定量分析，放到另外单独一篇文章。</p><span id="more"></span><h2 id="跳表测试分析"><a href="#跳表测试分析" class="headerlink" title="跳表测试分析"></a>跳表测试分析</h2><p><a href="https://selfboot.cn/2024/09/09/leveldb_source_skiplist/">上篇文章</a>分析了 LevelDB 跳表的实现，那么这里的实现是否正确呢？如果要写测试用例，应该怎么写？需要从哪些方面来测试跳表的正确性？我们看看 LevelDB 的测试代码 <a href="https://github.com/google/leveldb/blob/main/db/skiplist_test.cc">skiplist_test.cc</a>。</p><p>首先是<strong>空跳表的测试</strong>，验证空跳表不包含任何元素，检查空跳表的迭代器操作 SeekToFirst, Seek, SeekToLast 等。接着是插入、查找、迭代器的测试用例，通过不断插入大量随机生成的键值对，验证跳表是否正确包含这些键，以及测试迭代器的前向和后向遍历。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">TEST</span>(SkipTest, InsertAndLookup) &#123;</span><br><span class="line">  <span class="comment">// 测试插入和查找功能</span></span><br><span class="line">  <span class="comment">// 插入随机生成的键值对</span></span><br><span class="line">  <span class="comment">// 验证跳表正确包含这些键</span></span><br><span class="line">  <span class="comment">// 测试迭代器的前向和后向遍历</span></span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>这些都是比较常规的测试用例，这里不展开了。我们重点来看看 LevelDB 的<strong>并行测试</strong>。</p><h3 id="测试-Key-设计"><a href="#测试-Key-设计" class="headerlink" title="测试 Key 设计"></a>测试 Key 设计</h3><p>LevelDB 的跳表支持单线程写，多线程并行读，在上篇详细分析过这里的并行读实现细节，那么要如何测试呢？先定义测试目标，多个线程并行读的时候，<strong>每个读线程初始化迭代器后，应该要能读到当前跳表的所有元素</strong>。因为有写线程在同时运行，所以读线程可能<strong>也会读到后续新插入的元素</strong>。读线程在任何时刻，<strong>读到的元素都应该满足跳表的性质</strong>，即前一个元素小于等于后一个元素。</p><p>LevelDB 的测试方法设计的还是比较巧妙的。首先是一个<strong>精心设计的元素值 Key</strong>(这里 K 大写来区分)，注释部分写的很清晰：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// We generate multi-part keys:</span></span><br><span class="line"><span class="comment">//     &lt;key,gen,hash&gt;</span></span><br><span class="line"><span class="comment">// where:</span></span><br><span class="line"><span class="comment">//     key is in range [0..K-1]</span></span><br><span class="line"><span class="comment">//     gen is a generation number for key</span></span><br><span class="line"><span class="comment">//     hash is hash(key,gen)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The insertion code picks a random key, sets gen to be 1 + the last</span></span><br><span class="line"><span class="comment">// generation number inserted for that key, and sets hash to Hash(key,gen).</span></span><br><span class="line"><span class="comment">//</span></span><br></pre></td></tr></table></figure><p>跳表元素值由三部分组成，key 是随机生成，gen 是插入的递增序号，hash 是 key 和 gen 的 hash 值。三部分一起放在一个 uint64_t 的整数中，高 24 位是 key，中间 32 位是 gen，低 8 位是 hash。下面是根据 Key 提取三个部分，以及从 key 和 gen 生成 Key 的代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">uint64_t</span> Key;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConcurrentTest</span> &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">uint32_t</span> K = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">uint64_t</span> <span class="title">key</span><span class="params">(Key key)</span> </span>&#123; <span class="keyword">return</span> (key &gt;&gt; <span class="number">40</span>); &#125;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">uint64_t</span> <span class="title">gen</span><span class="params">(Key key)</span> </span>&#123; <span class="keyword">return</span> (key &gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xffffffffu</span>; &#125;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">uint64_t</span> <span class="title">hash</span><span class="params">(Key key)</span> </span>&#123; <span class="keyword">return</span> key &amp; <span class="number">0xff</span>; &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="function"><span class="type">static</span> Key <span class="title">MakeKey</span><span class="params">(<span class="type">uint64_t</span> k, <span class="type">uint64_t</span> g)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">static_assert</span>(<span class="built_in">sizeof</span>(Key) == <span class="built_in">sizeof</span>(<span class="type">uint64_t</span>), <span class="string">&quot;&quot;</span>);</span><br><span class="line">    <span class="built_in">assert</span>(k &lt;= K);  <span class="comment">// We sometimes pass K to seek to the end of the skiplist</span></span><br><span class="line">    <span class="built_in">assert</span>(g &lt;= <span class="number">0xffffffffu</span>);</span><br><span class="line">    <span class="keyword">return</span> ((k &lt;&lt; <span class="number">40</span>) | (g &lt;&lt; <span class="number">8</span>) | (<span class="built_in">HashNumbers</span>(k, g) &amp; <span class="number">0xff</span>));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>那<strong>为什么要设计 key 呢</strong>？key 的取值在 0 到 K-1 之间，K 这里是 4。key 虽然占了高 24 位，但是取值范围是 0-3。其实这里键值设计不用高 24 位的 key也是完全可以的，后面的测试逻辑没有大的影响。这里问了下 gpto1 和 claude3.5，给的解释也说不通。结合后续的并行读、写测试代码，个人理解可能是想<strong>模拟在链表中执行跨度比较大的 seek 操作</strong>。欢迎各位在评论区指正，给出其他可以说的通的解释～</p><p>至于 gen 和 hash 的好处就比较明显了，插入的时候保证 gen 递增，那么读线程就可以用 gen 来<strong>验证跳表中元素插入的顺序</strong>。每个键低 8 位是 hash，可以用来验证<strong>从跳表中读出来的元素和插入的元素是否一致</strong>，如下 IsValidKey 方法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">uint64_t</span> <span class="title">HashNumbers</span><span class="params">(<span class="type">uint64_t</span> k, <span class="type">uint64_t</span> g)</span> </span>&#123;</span><br><span class="line">  <span class="type">uint64_t</span> data[<span class="number">2</span>] = &#123;k, g&#125;;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Hash</span>(<span class="built_in">reinterpret_cast</span>&lt;<span class="type">char</span>*&gt;(data), <span class="built_in">sizeof</span>(data), <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">IsValidKey</span><span class="params">(Key k)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">hash</span>(k) == (<span class="built_in">HashNumbers</span>(<span class="built_in">key</span>(k), <span class="built_in">gen</span>(k)) &amp; <span class="number">0xff</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里取出键值的低 8 位，和从 key 和 gen 生成的 hash 值对比，如果相等，则说明元素是有效的。上面实现都放在 <a href="https://github.com/google/leveldb/blob/main/db/skiplist_test.cc#L152">ConcurrentTest 类</a>，这个类作为辅助类，定义了系列 Key 相关的方法，以及读写跳表部分。</p><h3 id="写线程操作"><a href="#写线程操作" class="headerlink" title="写线程操作"></a>写线程操作</h3><p>接下来看写线程的操作方法 WriteStep，它是 ConcurrentTest 类的 public 成员方法，核心代码如下:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// REQUIRES: External synchronization</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">WriteStep</span><span class="params">(Random* rnd)</span> </span>&#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint32_t</span> k = rnd-&gt;<span class="built_in">Next</span>() % K;</span><br><span class="line">  <span class="type">const</span> <span class="type">intptr_t</span> g = current_.<span class="built_in">Get</span>(k) + <span class="number">1</span>;</span><br><span class="line">  <span class="type">const</span> Key key = <span class="built_in">MakeKey</span>(k, g);</span><br><span class="line">  list_.<span class="built_in">Insert</span>(key);</span><br><span class="line">  current_.<span class="built_in">Set</span>(k, g);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里随机生成一个 key，然后拿到该 key 对应的上个 gen 值，递增生成新的 gen 值，调用 Insert 方法往跳表插入新的键。新的键是用前面的 MakeKey 方法，<strong>根据 key 和 gen 生成</strong>。插入调表后还要更新 key 对应的 gen 值，这样就保证了每个 key 下插入的元素 gen 是递增的。这里 key 的取值在 0 到 K-1 之间，K 这里取 4。</p><p>这里的 current_ 是一个 State 结构体，<strong>保存了每个 key 对应的 gen 值</strong>，代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">State</span> &#123;</span><br><span class="line">  std::atomic&lt;<span class="type">int</span>&gt; generation[K];</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Set</span><span class="params">(<span class="type">int</span> k, <span class="type">int</span> v)</span> </span>&#123;</span><br><span class="line">    generation[k].<span class="built_in">store</span>(v, std::memory_order_release);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">Get</span><span class="params">(<span class="type">int</span> k)</span> </span>&#123; <span class="keyword">return</span> generation[k].<span class="built_in">load</span>(std::memory_order_acquire); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">State</span>() &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; K; k++) &#123;</span><br><span class="line">      <span class="built_in">Set</span>(k, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>State 结构体中有一个 atomic 数组 generation，保存了每个 key 对应的 gen 值。这里用 atomic 原子类型和 memory_order_release, memory_order_acquire 语义来保证，<strong>写线程一旦更新了 key 的 gen 值，读线程立马就能读到新的值</strong>。关于 atomic 内存屏障语义的理解，可以参考上篇跳表实现中 Node 类的设计。</p><h3 id="读线程操作"><a href="#读线程操作" class="headerlink" title="读线程操作"></a>读线程操作</h3><p>上面写线程比较简单，一个线程不断往跳表插入新的元素即可。读线程相对复杂了很多，<strong>除了从跳表中读取元素，还需要验证数据是符合预期的</strong>。这里是注释中给出的测试读线程的整体思路：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// At the beginning of a read, we snapshot the last inserted</span></span><br><span class="line"><span class="comment">// generation number for each key.  We then iterate, including random</span></span><br><span class="line"><span class="comment">// calls to Next() and Seek().  For every key we encounter, we</span></span><br><span class="line"><span class="comment">// check that it is either expected given the initial snapshot or has</span></span><br><span class="line"><span class="comment">// been concurrently added since the iterator started.</span></span><br></pre></td></tr></table></figure><p>主要确保跳表在读写并行环境下的正确性，可以从下面 3 个角度来验证：</p><ol><li>一致性验证：确保读线程在迭代过程中<strong>不会遗漏在迭代器创建时已经存在的键</strong>。</li><li>顺序遍历：验证<strong>迭代器遍历的顺序始终是递增</strong>的，避免回退。</li><li>并行安全：通过随机的迭代器移动策略，模拟并行读操作场景，检测潜在的竞争条件或数据不一致问题。</li></ol><p>这里 ReadStep 方法有一个 while(true) 循环，在开始循环之前，先记录下跳表的初始状态到 initial_state 中，然后用 <a href="https://github.com/google/leveldb/blob/main/db/skiplist_test.cc#L176">RandomTarget</a> 方法随机生成一个目标键 pos，用 Seek 方法查找。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ReadStep</span><span class="params">(Random* rnd)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Remember the initial committed state of the skiplist.</span></span><br><span class="line">    State initial_state;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; K; k++) &#123;</span><br><span class="line">      initial_state.<span class="built_in">Set</span>(k, current_.<span class="built_in">Get</span>(k));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Key pos = <span class="built_in">RandomTarget</span>(rnd);</span><br><span class="line">    SkipList&lt;Key, Comparator&gt;::<span class="function">Iterator <span class="title">iter</span><span class="params">(&amp;list_)</span></span>;</span><br><span class="line">    iter.<span class="built_in">Seek</span>(pos);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后就是整个验证过程，这里省略了跳表中找不到 pos 的情况，只看核心测试路径。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    Key current;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">    current = iter.<span class="built_in">key</span>();</span><br><span class="line">    <span class="built_in">ASSERT_TRUE</span>(<span class="built_in">IsValidKey</span>(current)) &lt;&lt; current;</span><br><span class="line">    <span class="built_in">ASSERT_LE</span>(pos, current) &lt;&lt; <span class="string">&quot;should not go backwards&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Verify that everything in [pos,current) was not present in</span></span><br><span class="line">    <span class="comment">// initial_state.</span></span><br><span class="line">    <span class="keyword">while</span> (pos &lt; current) &#123;</span><br><span class="line">      <span class="built_in">ASSERT_LT</span>(<span class="built_in">key</span>(pos), K) &lt;&lt; pos;</span><br><span class="line">      <span class="built_in">ASSERT_TRUE</span>((<span class="built_in">gen</span>(pos) == <span class="number">0</span>) ||</span><br><span class="line">                  (<span class="built_in">gen</span>(pos) &gt; <span class="built_in">static_cast</span>&lt;Key&gt;(initial_state.<span class="built_in">Get</span>(<span class="built_in">key</span>(pos)))))</span><br><span class="line">          &lt;&lt; <span class="string">&quot;key: &quot;</span> &lt;&lt; <span class="built_in">key</span>(pos) &lt;&lt; <span class="string">&quot;; gen: &quot;</span> &lt;&lt; <span class="built_in">gen</span>(pos)</span><br><span class="line">          &lt;&lt; <span class="string">&quot;; initgen: &quot;</span> &lt;&lt; initial_state.<span class="built_in">Get</span>(<span class="built_in">key</span>(pos));</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Advance to next key in the valid key space</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">key</span>(pos) &lt; <span class="built_in">key</span>(current)) &#123;</span><br><span class="line">        pos = <span class="built_in">MakeKey</span>(<span class="built_in">key</span>(pos) + <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        pos = <span class="built_in">MakeKey</span>(<span class="built_in">key</span>(pos), <span class="built_in">gen</span>(pos) + <span class="number">1</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里找到位置 current 后，会验证 current 位置的键值 hash 是否正确，接着验证 pos &lt;&#x3D; current。之后用一个 while 循环遍历跳表，验证 <code>[pos, current)</code> 区间内的所有键都没有在初始状态 initial_state 中。这里可以用<strong>反证法思考，如果某个键 tmp 在 [pos, current) 区间内，并且也在 initial_state 中，那么根据跳表的性质，Seek 的时候就会找到 tmp，而不是 current 了</strong>。所以只要链表实现正确，那么 [pos, current) 区间内的所有键都没有在 initial_state 中。</p><p>当然这里没有记录下跳表中的键值，只用验证 [pos, current) 区间内所有键的 gen 值大于初始状态下的 gen 值，就能说明开始迭代的时候这个范围内的所有键都不在链表中。</p><p>在上面每轮验证后都会重新找到一个新的测试目标键 pos，并更新迭代器，如下代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (rnd-&gt;<span class="built_in">Next</span>() % <span class="number">2</span>) &#123;</span><br><span class="line">  iter.<span class="built_in">Next</span>();</span><br><span class="line">  pos = <span class="built_in">MakeKey</span>(<span class="built_in">key</span>(pos), <span class="built_in">gen</span>(pos) + <span class="number">1</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  Key new_target = <span class="built_in">RandomTarget</span>(rnd);</span><br><span class="line">  <span class="keyword">if</span> (new_target &gt; pos) &#123;</span><br><span class="line">    pos = new_target;</span><br><span class="line">    iter.<span class="built_in">Seek</span>(new_target);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里随机决定是 iter.Next() 移动到下一个键，还是创建一个新的目标键并重新定位到该目标键。整个读测试模拟了真实环境下的不确定性，确保跳表在各种访问模式下的稳定性和正确性。</p><h3 id="单线程读写"><a href="#单线程读写" class="headerlink" title="单线程读写"></a>单线程读写</h3><p>上面介绍完了测试读写的方法，下面看看具体怎么结合线程来测试。单线程下读、写比较简单，写和读交换执行就好。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Simple test that does single-threaded testing of the ConcurrentTest</span></span><br><span class="line"><span class="comment">// scaffolding.</span></span><br><span class="line"><span class="built_in">TEST</span>(SkipTest, ConcurrentWithoutThreads) &#123;</span><br><span class="line">  ConcurrentTest test;</span><br><span class="line">  <span class="function">Random <span class="title">rnd</span><span class="params">(test::RandomSeed())</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">    test.<span class="built_in">ReadStep</span>(&amp;rnd);</span><br><span class="line">    test.<span class="built_in">WriteStep</span>(&amp;rnd);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="并行读写测试"><a href="#并行读写测试" class="headerlink" title="并行读写测试"></a>并行读写测试</h3><p>实际场景中，有一个写线程，但是可以有多个读线程，还要测试读和写并行场景下跳表的正确性。核心测试代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">RunConcurrent</span><span class="params">(<span class="type">int</span> run)</span> </span>&#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> seed = test::<span class="built_in">RandomSeed</span>() + (run * <span class="number">100</span>);</span><br><span class="line">  <span class="function">Random <span class="title">rnd</span><span class="params">(seed)</span></span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> N = <span class="number">1000</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> kSize = <span class="number">1000</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> ((i % <span class="number">100</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">      std::<span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Run %d of %d\n&quot;</span>, i, N);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">TestState <span class="title">state</span><span class="params">(seed + <span class="number">1</span>)</span></span>;</span><br><span class="line">    Env::<span class="built_in">Default</span>()-&gt;<span class="built_in">Schedule</span>(ConcurrentReader, &amp;state);</span><br><span class="line">    state.<span class="built_in">Wait</span>(TestState::RUNNING);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; kSize; i++) &#123;</span><br><span class="line">      state.t_.<span class="built_in">WriteStep</span>(&amp;rnd);</span><br><span class="line">    &#125;</span><br><span class="line">    state.quit_flag_.<span class="built_in">store</span>(<span class="literal">true</span>, std::memory_order_release);</span><br><span class="line">    state.<span class="built_in">Wait</span>(TestState::DONE);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里每个用例中迭代 N 次，每次迭代中使用 Env::Default()-&gt;Schedule 方法，创建了一个新的线程执行 ConcurrentReader 函数，并传入 state 作为参数。ConcurrentReader 会在独立线程中执行读操作，模拟并行读环境。接着调用 state.Wait(TestState::RUNNING) 等读线程进入运行状态后，主线程开始写操作。</p><p>这里写操作通过循环调用 state.t_.WriteStep(&amp;rnd)，在跳表中执行 kSize 次写操作。每次写操作会插入新的键值对到跳表中，模拟写线程的行为。等执行完写操作后，设置 state.quit_flag_ 为 true，通知读线程停止读取操作并退出。等待读线程完成所有操作并退出，确保当前循环的读写操作全部结束后再进行下一次测试。</p><p>这里的测试用到了 TestState 来同步线程状态，还封装了一个 ConcurrentReader 作为读线程方法。此外还调用了 Env 封装的 Schedule 方法，在独立线程中执行读操作。涉及到条件变量、互斥锁以及线程相关内容，这里不展开了。</p><p>值得一说的是，这里也只是<strong>测试了一写一读并行的场景，并没有测试一写多读</strong>。可以在每轮迭代中启动多个读线程，所有读线程同时与写操作并发执行。或者维护一个固定数量的读线程池，多个读线程持续运行，与写线程并发操作。不过当前的测试，通过多次重复一写一读的方式，依然能够有效地验证跳表在读写并发下的正确性和稳定性。</p><p>下面是执行测试用例的输出截图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240918_leveldb_source_skiplist_more_runtest.png" alt="并行测试输出"></p><h2 id="并行测试正确性"><a href="#并行测试正确性" class="headerlink" title="并行测试正确性"></a>并行测试正确性</h2><p>上面并行测试比较详细，但是这里值得再多说一点。对于这种并行下的代码，特别是涉及内存屏障相关的代码，有时候<strong>测试通过可能只是因为没触发问题而已</strong>(出现问题的概率很低，可能和编译器，cpu 型号也有关)。比如这里我把 Insert 操作稍微改下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; height; i++) &#123;</span><br><span class="line">  <span class="comment">// NoBarrier_SetNext() suffices since we will add a barrier when</span></span><br><span class="line">  <span class="comment">// we publish a pointer to &quot;x&quot; in prev[i].</span></span><br><span class="line">  x-&gt;<span class="built_in">NoBarrier_SetNext</span>(i, prev[i]-&gt;<span class="built_in">NoBarrier_Next</span>(i));</span><br><span class="line">  prev[i]-&gt;<span class="built_in">NoBarrier_SetNext</span>(i, x); <span class="comment">// Change here, Use NoBarrier_SetNext</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里两个指针都用 NoBarrier_SetNext 方法来设置，然后重新编译 LevelDB 库和测试程序，运行多次，都是能通过测试用例的。</p><p>当然这种情况下，可以在不同的硬件配置和负载下进行长时间的测试，可能也可以发现问题。不过缺点就是耗时较长，可能无法重现发现的问题。</p><h3 id="ThreadSanitizer-检测数据竞争"><a href="#ThreadSanitizer-检测数据竞争" class="headerlink" title="ThreadSanitizer 检测数据竞争"></a>ThreadSanitizer 检测数据竞争</h3><p>此外也可以使用 clang 的动态分析工具 <a href="https://clang.llvm.org/docs/ThreadSanitizer.html">ThreadSanitizer</a> 来检测数据竞争。使用也比较简单，编译的时候带上 <code>-fsanitize=thread</code> 选项即可。完整的编译指令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CC=/usr/bin/clang CXX=/usr/bin/clang++  cmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_CXX_FLAGS=&quot;-fsanitize=thread&quot; -DCMAKE_C_FLAGS=&quot;-fsanitize=thread&quot; -DCMAKE_EXE_LINKER_FLAGS=&quot;-fsanitize=thread&quot; -DCMAKE_INSTALL_PREFIX=$(pwd) .. &amp;&amp; cmake --build . --target install</span><br></pre></td></tr></table></figure><p>把上面改动后的代码重新编译链接，运行测试用例，结果如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240918_leveldb_source_skiplist_more_threadsanitizer.png" alt="ThreadSanitizer 检测数据竞争"></p><p>这里定位到了问题代码，还是很精准的。如果取消这里的错误改动重新编译运行，是不会有问题的。ThreadSanitizer 的实现原理比较复杂，程序被编译时，TSan 在<strong>每个内存访问操作前后插入检查代码</strong>。运行过程中，当程序执行到一个内存访问操作时，插入的代码会被触发，这段代码检查并更新相应的影子内存。它比较当前访问与该内存位置的历史访问记录。如果检测到潜在的数据竞争，TSan 会记录详细信息，包括堆栈跟踪。</p><p>它的优点是能够检测到难以通过其他方法发现的微妙数据竞争，同时还提供详细的诊断信息，有助于快速定位和修复问题。不过会显著增加程序的运行时间和内存使用。可能无法检测到所有类型的并发错误，特别是那些依赖于特定时序的错误。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>跳表的测试部分也分析完了，我们重点分析了下并行读写场景下的正确性验证。这里插入键值 Key 的设计，读线程的验证方法都很巧妙，值得我们借鉴。同时我们也要认识到，多线程下数据竞争的检测，有时候靠测试用例是很难发现的。借助 ThreadSanitizer 这种工具，可以辅助发现一些问题。</p><p>最后欢迎大家留言交流～</p>]]></content>
    
    
    <summary type="html">深入剖析 LevelDB 跳表实现的测试方法,重点探讨并行读写场景下的正确性验证。详细介绍了测试用Key的巧妙设计、写线程和读线程的操作实现,以及单线程和多线程测试的具体方法。文章还讨论了并行测试的局限性,引入ThreadSanitizer工具进行更深入的数据竞争检测。</summary>
    
    
    
    <category term="源码剖析" scheme="https://selfboot.cn/categories/%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="LevelDB" scheme="https://selfboot.cn/tags/LevelDB/"/>
    
  </entry>
  
  
  
  
  
  <entry>
    <title>实际例子上手体验 OpenAI o1-preview，比预期差一点？</title>
    <link href="https://selfboot.cn/2024/09/13/gpto1_hands_on/"/>
    <id>https://selfboot.cn/2024/09/13/gpto1_hands_on/</id>
    <published>2024-09-13T21:00:00.000Z</published>
    <updated>2025-06-10T13:51:57.712Z</updated>
    
    <content type="html"><![CDATA[<p>OpenAI 半夜悄咪咪推出了新的模型，<a href="https://openai.com/index/introducing-openai-o1-preview/">introducing-openai-o1-preview</a>。放出了系列视频，展示新模型的强大，网上也是普天盖地的文章来讲新模型测评有多厉害。不过见惯了 AI 界的放卫星，怀着怀疑的态度，第一时间上手体验一把。</p><h2 id="汉语新解"><a href="#汉语新解" class="headerlink" title="汉语新解"></a>汉语新解</h2><p>刚好最近<a href="https://www.lijigang.com/">李继刚</a>有个提示词很火，可以生成很好玩的汉语新解。用 Claude3.5 试了效果特别好，下面是一些 Claude 生成的 SVG 图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_claude35_demo.png" alt="Claude3.5 汉语新解的示例"></p><span id="more"></span><p>这个提示词特别有意思，用经典编程语言 Lisp 来描述要执行的任务，大模型居然能理解，还能生成稳定、美观的 SVG 图。这个提示词很考验模型的理解和生成能力，试了 GLM 和 GPT-4o，都不能生成符合要求的 SVG 图。目前只有在 Claude3.5 上稳定输出，效果也很好，那么 OpenAI 的最新 o1-preview 模型如何呢？</p><p>我们直接输出提示词，接着输入词语，结果如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_preview.png" alt="o1-preview 汉语新解的示例"></p><p>这里没有输出 svg，给出了一个 markdown 格式的输出。然后新的模型有个比较有意思的地方，这里有个“思考”，<strong>会显示思考多长时间，然后点击后可以看到思考的过程</strong>。</p><p>看起来模型也能理解提示词，只是输出有点问题。<a href="https://selfboot.cn/2024/06/22/claude35_artifacts/">Claude3.5 是因为有 Artifacts 能力</a>，所以可以直接输 SVG 格式图片。这里我们可以直接提示 o1-preview 生成 SVG 源码，于是提示词稍详细下，约束下输出格式，如下：</p><blockquote><p>生成 svg 源码：宇宙</p></blockquote><p>这次终于给出了一个 SVG 源码，生成了“宇宙”的汉语新解图。接着我想着模型已经理解了我的意图，于是直接输入“数学”，结果模型还是给了一开始的 markdown 输出了。<strong>每次必须在词语前面明确提示”生成 svg 源码”</strong> ，才能输出想要的 SVG 格式。下图是三个词的输出效果，可以对比前面 claude3.5 的结果。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_demo2.png" alt="o1-preview 汉语新解的示例"></p><p>个人感觉 Claude3.5 生成的图更简洁美观些，o1-preview 生成的图有点粗糙。并且文字内容上，Claude3.5 的也更有深意，gpto1 的有点直白。</p><h2 id="代码理解能力"><a href="#代码理解能力" class="headerlink" title="代码理解能力"></a>代码理解能力</h2><p>OpenAI 的新模型着重强调说写代码和理解代码能力很强，这个我可是太需要了。最近刚好在看 <a href="https://selfboot.cn/tags/leveldb/">LevelDB 源码实现</a>，跳表这里的<a href="https://github.com/google/leveldb/blob/main/db/skiplist_test.cc">测试用例</a>写的有点复杂，代码虽然不多，但是理解起来有点费劲。</p><p>之前试过用 GPT4 和 Claude3.5 来解读，虽然也给了不少帮助，但是有些疑问还是没能得到让我信服的解答。刚好可以拿来给 o1-preview 模型来解读下。开始解决疑问之前，先让他读了这里并发测试的代码，看他怎么理解。提示词：</p><blockquote><p>这里是 LevelDB 跳表的并发测试代码，帮我分析这段代码，然后告诉我这里的测试实现优点。</p><p>&#x2F;&#x2F; We want to make sure that with a single writer and multiple<br>&#x2F;&#x2F; concurrent readers (with no synchronization other than when<br>…</p></blockquote><p>提示的时候是给了完整代码，这里先省略后面的代码部分。模型给的结果还算可以，比之前 Claude3.5 的稍微好一点。分为几个部分分析了这里的代码，包括关键数据结构和概念，核心方法，并发测试的执行流程，最后总结了测试代码的优点。这里摘录小部分：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3</span>. 并发测试的执行流程</span><br><span class="line">TestState 类：管理测试的状态，包括启动和停止读线程的同步。</span><br><span class="line">ConcurrentReader：读线程的执行函数，不断调用 ReadStep 直到接收到停止信号。</span><br><span class="line">RunConcurrent：主测试函数。</span><br><span class="line"></span><br><span class="line">创建一个 TestState 实例，启动读线程。</span><br><span class="line">主线程执行写操作，不断调用 WriteStep。</span><br><span class="line">在写操作完成后，设置停止信号，等待读线程结束。</span><br><span class="line">测试用例：<span class="built_in">TEST</span>(SkipTest, Concurrent1) 到 <span class="built_in">TEST</span>(SkipTest, Concurrent5)，分别运行多次并发测试。</span><br></pre></td></tr></table></figure><p>然后就是我的疑问：</p><blockquote><p>这里  K 的值现在是 4，为什么设计这么小的 1 个值呢？ 这个值会影响到测试的哪部分</p></blockquote><p>接下来 gpto1 就开始胡说八道了。</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">K</span> 的值被设置为 <span class="number">4</span>，这是一个很小的值，目的是为了在测试中增加对同一组键的访问冲突，从而更有效地检测并发环境下可能出现的问题。</span><br><span class="line"></span><br><span class="line">为什么选择小的 <span class="built_in">K</span> 值？</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> 增加键的重用率：当 <span class="built_in">K</span> 较小（如 <span class="number">4</span>）时，键的范围仅在 <span class="punctuation">[</span><span class="number">0</span><span class="operator">,</span> <span class="number">3</span><span class="punctuation">]</span> 之间。这意味着在大量的读写操作中，不同线程很可能频繁地访问相同的键。这种高频率的键重用会增加线程之间的竞争，从而更容易暴露并发访问时的潜在问题。</span><br></pre></td></tr></table></figure><p>这里接着提示：</p><blockquote><p>不对不对吧！这里 K 只是影响最终键值的前 24 位而已，插入链表的键值还有其他gen 和 hash位，这些都不会重复的呀</p></blockquote><p>这次模型思考时间比较久，思考过程比较有意思，如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_leveldb_case.png" alt="o1-preview 思考过程"></p><p>但是给的结果也并不能说服我，又接着继续追问：</p><blockquote><p>为什么一定要引入 K 值呢？ 直接用 gen 和 hash 不就能测试了吗？<br>另外，就算引入 K 值，取值 0 到 4，为啥要给 24 位呢？</p></blockquote><p>回答似乎又回到前面的套路上了，始终没有给出有价值的观点。当然这里的疑问，Claude3.5 也不能给出很好的答案，我自己暂时也还没想出一个很好的解释。可能只是 LevelDB 作者随手设计的，并没有什么道理在里面？欢迎评论区留下自己的看法哈。</p><p>这里还没来得及测试代码生成能力，已经没有额度了。根据 OpenAI 的文档，目前 o1-preview 每周是限制 30 条消息，o1-mini 每周 50 条。后面有额度后，会继续尝试这里的新模型，更新本文，争取给出全面的测评。</p><h2 id="再谈模型效果"><a href="#再谈模型效果" class="headerlink" title="再谈模型效果"></a>再谈模型效果</h2><p>最近这一年以来，不断有各种新模型涌现出来，时不时声称在评测集上评分又创新高。但是从实际体验来看，不少模型的能力还是比较一般，有些甚至是不能用。大模型公司似乎热衷于跑分，热衷于夸大模型的能力，就算是 Google 和 OpenAI 也不能免俗。Google 之前放出的 Gemini 宣传视频被爆是剪辑过的，OpenAI 的 GPT4o 多模态很多官方例子我现在都不能复现。</p><p><strong>评价一个模型的能力，最后还是得靠自己上手多体验才行</strong>。最近我已经很少用 GPT 了，写代码和日常任务都是用 Claude3.5，不管是代码生成，还是文本理解等，感觉比其他模型要好不少。写代码的话，用 cursor 搭配 Claude3.5，体验好了不少。作为一个 0 基础前端，用 Claude3.5 都能很快做出不少算法可视化，放在 <a href="http://gallery.selfboot.cn/">AI Gallery</a> 上，大家可以去体验下。</p>]]></content>
    
    
    <summary type="html">OpenAI 发布了新的模型 o1-preview，号称更强的代码生成和理解能力，各种评测效果也都很好。第一时间体验了新模型，包括使用比较火的提示词汉语新解来生成 svg，以及解释 LevelDB 的代码。整体感觉下来，新的 o1-preview 模型效果有提升，但是并没有拉开代差。</summary>
    
    
    
    <category term="人工智能" scheme="https://selfboot.cn/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="ChatGPT" scheme="https://selfboot.cn/tags/ChatGPT/"/>
    
    <category term="LLM" scheme="https://selfboot.cn/tags/LLM/"/>
    
  </entry>
  
  
</feed>
