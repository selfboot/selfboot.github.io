<!DOCTYPE html><html lang="[&quot;zh-CN&quot;,&quot;en&quot;,&quot;default&quot;]"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="baidu-site-verification" content="codeva-NxrUEx2EFN"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Hands-on with OpenAI's o1-preview - Not Better Enough?</title><link rel="stylesheet" type="text/css" href="/css/normalize.min.css"><link rel="stylesheet" type="text/css" href="/css/pure-min.min.css"><link rel="stylesheet" type="text/css" href="/css/grids-responsive-min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css"><script type="text/javascript" src="/js/jquery.min.js"></script><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml,en/atom.xml"><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;973c5bad683a49b8af76df256779f523&quot;}"></script>
<script defer="" src="https://cloud.umami.is/script.js" data-website-id="3578d9f2-9ea0-49d4-8781-e8d1217ab924" data-domains="selfboot.cn"></script><script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="referrer" content="no-referrer-when-downgrade"><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QNFB9JLSPV"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QNFB9JLSPV');
</script><script async="" type="text/javascript" src="/js/clipboard.min.js"></script><script async="" type="text/javascript" src="/js/toastr.min.js"></script><link rel="stylesheet" href="/css/toastr.min.css"><script>function switchLanguage(lang) {
  var currentPath = window.location.pathname;
  var newPath;
  if (lang === 'en') {
    newPath = '/en' + currentPath.replace(/^\/(zh-CN\/)?/, '/');
  } else {
    newPath = currentPath.replace(/^\/en/, '');
  }
  window.location.href = newPath;
}
</script><link rel="icon" href="https://slefboot-1251736664.file.myqcloud.com/selfboot//favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="https://slefboot-1251736664.file.myqcloud.com/selfboot//apple-touch-icon.png"><link rel="manifest" href="https://slefboot-1251736664.file.myqcloud.com/selfboot//site.webmanifest"><meta name="generator" content="Hexo 7.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><a id="logo" href="/.">Just For Fun</a><div class="lang-select-wrapper"><i class="fas fa-globe"></i><select id="lang-select" onchange="switchLanguage(this.value)"><option value="zh-CN">中文</option><option value="en" selected="">English</option></select></div><p class="description">Know what it is, and know why it is so. The breadth of knowledge is a byproduct of its depth!</p></div><div id="nav-menu"><a href="/en/."><i class="fa fa-home"></i><span> Home</span></a><a href="/en/archives/"><i class="fa fa-archive"></i><span> Archive</span></a><a href="/en/aboutme.html"><i class="fa fa-user"></i><span> About</span></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Hands-on with OpenAI's o1-preview - Not Better Enough?</h1><div class="post-meta">2024/09/13<span> | </span><span class="category"><a href="/categories/Artificial-Intelligence/">Artificial Intelligence</a></span><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a class="disqus-comment-count" data-disqus-identifier="en/2024/09/13/gpto1_hands_on/" href="/en/2024/09/13/gpto1_hands_on/#disqus_thread"></a><div class="post-content"><p>OpenAI quietly released a new model in the middle of the night, <a target="_blank" rel="noopener" href="https://openai.com/index/introducing-openai-o1-preview/">introducing-openai-o1-preview</a>. They released a series of videos showcasing the power of the new model, and the internet is flooded with articles discussing how impressive the new model’s evaluations are. However, having seen plenty of hype in the AI world, I approached it with a skeptical attitude and immediately tried it out firsthand.</p>
<h2 id="Chinese-Interpretations"><a href="#Chinese-Interpretations" class="headerlink" title="Chinese Interpretations"></a>Chinese Interpretations</h2><p>Recently, <a target="_blank" rel="noopener" href="https://www.lijigang.com/">Li Jigang</a> had a very popular prompt that can generate interesting new interpretations of Chinese characters. I tried it with Claude3.5 and the results were particularly good. Below are some SVG images generated by Claude:</p>
<p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_claude35_demo.png/webp" alt="Claude3.5 examples of new Chinese interpretations" srcset="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_claude35_demo.png/webp 3124w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_claude35_demo.png/webp400 400w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_claude35_demo.png/webp800 800w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_claude35_demo.png/webp1600 1600w" sizes="(min-width: 1150px) 723px, (min-width: 48em) calc((100vw - 120px) * 3 / 4 - 50px), (min-width: 35.5em) calc((100vw - 75px), calc(100vw - 40px)" width="3124" height="1558"></p>
<span id="more"></span>

<p>This prompt is particularly interesting as it uses the classic programming language Lisp to describe the task to be executed, and large language models can actually understand it and generate stable, aesthetically pleasing SVG images. This prompt really tests the model’s understanding and generation capabilities. I tried it with GLM and GPT-4o, but neither could generate SVG images that met the requirements. Currently, only Claude3.5 can consistently output good results. So how does OpenAI’s latest o1-preview model perform?</p>
<p>We directly output the prompt, then input the words, and the results are as follows:</p>
<p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_preview.png/webp" alt="o1-preview examples of new Chinese interpretations" srcset="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_preview.png/webp 1564w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_preview.png/webp400 400w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_preview.png/webp800 800w" sizes="(min-width: 1150px) 723px, (min-width: 48em) calc((100vw - 120px) * 3 / 4 - 50px), (min-width: 35.5em) calc((100vw - 75px), calc(100vw - 40px)" width="1564" height="1698"></p>
<p>Here, it didn’t output SVG, but provided output in Markdown format. Then, an interesting feature of the new model is that there’s a “thinking” process, <strong>which will show how long it thinks, and you can click to see the thinking process</strong>.</p>
<p>It seems the model can understand the prompt, but the output is a bit problematic. <a href="https://selfboot.cn/en/2024/06/22/claude35_artifacts/">Claude3.5 can directly output SVG format images because of its Artifacts capability</a>. Here, we can directly prompt o1-preview to generate SVG source code, so we make the prompt a bit more detailed and constrain the output format, like this:</p>
<blockquote>
<p>Generate svg source code: Universe</p>
</blockquote>
<p>This time it finally gave an SVG source code, generating a new Chinese interpretation image for “Universe”. Then I thought the model had understood my intention, so I directly input “mathematics”, but the model still gave the initial Markdown output. <strong>Each time, you must explicitly prompt “Generate svg source code” before the word</strong> to get the desired SVG format output. The image below shows the output for three words, which can be compared with the previous Claude3.5 results.</p>
<p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_demo2.png/webp" alt="o1-preview examples of new Chinese interpretations" srcset="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_demo2.png/webp 2400w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_demo2.png/webp400 400w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_demo2.png/webp800 800w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_demo2.png/webp1600 1600w" sizes="(min-width: 1150px) 723px, (min-width: 48em) calc((100vw - 120px) * 3 / 4 - 50px), (min-width: 35.5em) calc((100vw - 75px), calc(100vw - 40px)" width="2400" height="1200"></p>
<p>Personally, I feel that the images generated by Claude3.5 are more concise and aesthetically pleasing, while those generated by o1-preview are a bit rough. In terms of text content, Claude3.5’s interpretations are also more profound, while gpto1’s are a bit straightforward.</p>
<h2 id="Code-Understanding-Capability"><a href="#Code-Understanding-Capability" class="headerlink" title="Code Understanding Capability"></a>Code Understanding Capability</h2><p>OpenAI’s new model emphasizes its strong ability to write and understand code, which is exactly what I need. I’ve recently been looking at the <a href="https://selfboot.cn/en/tags/leveldb/">LevelDB source code implementation</a>, and the <a target="_blank" rel="noopener" href="https://github.com/google/leveldb/blob/main/db/skiplist_test.cc">test cases</a> for the skip list are a bit complex. Although the code isn’t extensive, it’s a bit challenging to understand.</p>
<p>I’ve tried using GPT4 and Claude3.5 to interpret it before, and while they provided considerable help, some questions still didn’t get convincing answers. This is a good opportunity to have the o1-preview model interpret it. Before addressing my questions, I first had it read the concurrent testing code here to see how it understands it. The prompt was:</p>
<blockquote>
<p>This is the concurrent testing code for LevelDB’s skip list. Please analyze this code and tell me the advantages of this test implementation.</p>
<p>// We want to make sure that with a single writer and multiple<br>// concurrent readers (with no synchronization other than when<br>…</p>
</blockquote>
<p>When prompting, I provided the complete code, but I’ve omitted the latter part of the code here. The model’s result was fairly good, slightly better than Claude3.5’s previous attempt. It analyzed the code in several parts, including key data structures and concepts, core methods, the execution flow of concurrent testing, and finally summarized the advantages of the test code. Here’s an excerpt:</p>
<figure class="highlight pgsql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3.</span> Execution flow <span class="keyword">of</span> concurrent testing</span><br><span class="line">TestState <span class="keyword">class</span>: Manages the test state, including synchronization <span class="keyword">for</span> starting <span class="keyword">and</span> stopping <span class="keyword">read</span> threads.</span><br><span class="line">ConcurrentReader: The execution <span class="keyword">function</span> <span class="keyword">for</span> <span class="keyword">read</span> threads, continuously calling ReadStep <span class="keyword">until</span> receiving a stop signal.</span><br><span class="line">RunConcurrent: The main test <span class="keyword">function</span>.</span><br><span class="line">Creates a TestState instance, starts <span class="keyword">read</span> threads.</span><br><span class="line">The main thread performs <span class="keyword">write</span> operations, continuously calling WriteStep.</span><br><span class="line"><span class="keyword">After</span> <span class="keyword">write</span> operations are complete, sets the stop signal <span class="keyword">and</span> waits <span class="keyword">for</span> <span class="keyword">read</span> threads <span class="keyword">to</span> <span class="keyword">end</span>.</span><br><span class="line">Test cases: TEST(SkipTest, Concurrent1) <span class="keyword">to</span> TEST(SkipTest, Concurrent5), running multiple concurrent tests respectively.</span><br></pre></td></tr></tbody></table></figure>

<p>Then came my question:</p>
<blockquote>
<p>The value of K here is now 4, why design such a small value? Which part of the test will this value affect?</p>
</blockquote>
<p>At this point, gpto1 started to give inaccurate information.</p>
<figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">The <span class="built_in">value</span> <span class="keyword">of</span> K is <span class="built_in">set</span> <span class="built_in">to</span> <span class="number">4</span>, which is <span class="keyword">a</span> very small <span class="built_in">value</span>, aimed <span class="keyword">at</span> increasing access conflicts <span class="built_in">to</span> <span class="keyword">the</span> same <span class="built_in">set</span> <span class="keyword">of</span> <span class="built_in">keys</span> <span class="keyword">in</span> <span class="keyword">the</span> test, thereby more effectively detecting potential issues <span class="keyword">in</span> <span class="keyword">a</span> concurrent environment.</span><br><span class="line"></span><br><span class="line">Why choose <span class="keyword">a</span> small K <span class="built_in">value</span>?</span><br><span class="line">- Increase key reuse rate: When K is small (like <span class="number">4</span>), <span class="keyword">the</span> range <span class="keyword">of</span> <span class="built_in">keys</span> is only between [<span class="number">0</span>, <span class="number">3</span>]. This means that <span class="keyword">in</span> <span class="keyword">a</span> large <span class="built_in">number</span> <span class="keyword">of</span> <span class="built_in">read</span> <span class="keyword">and</span> <span class="built_in">write</span> operations, different threads are likely <span class="built_in">to</span> frequently access <span class="keyword">the</span> same <span class="built_in">keys</span>. This high frequency <span class="keyword">of</span> key reuse will increase competition between threads, making <span class="keyword">it</span> easier <span class="built_in">to</span> expose potential problems during concurrent access.</span><br></pre></td></tr></tbody></table></figure>

<p>Here, I continued to prompt:</p>
<blockquote>
<p>That’s not right, is it? K here only affects the first 24 bits of the final key value, and the key values inserted into the linked list also have other gen and hash bits, which won’t be repeated, right?</p>
</blockquote>
<p>This time the model thought for a longer time, and the thinking process was quite interesting, as shown below:</p>
<p><img src="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_leveldb_case.png/webp" alt="o1-preview thinking process" srcset="https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_leveldb_case.png/webp 1390w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_leveldb_case.png/webp400 400w, https://slefboot-1251736664.file.myqcloud.com/20240913_gpto1_hands_on_leveldb_case.png/webp800 800w" sizes="(min-width: 1150px) 723px, (min-width: 48em) calc((100vw - 120px) * 3 / 4 - 50px), (min-width: 35.5em) calc((100vw - 75px), calc(100vw - 40px)" width="1390" height="1704"></p>
<p>But the result given still couldn’t convince me, so I continued to ask:</p>
<blockquote>
<p>Why introduce the K value at all? Couldn’t we just use gen and hash for testing?<br>Also, even if we introduce the K value, taking values from 0 to 4, why give it 24 bits?</p>
</blockquote>
<p>The answer seemed to return to the previous pattern, still not providing valuable insights. Of course, Claude3.5 couldn’t give a very good answer to these questions either, and I haven’t come up with a good explanation myself yet. Maybe it’s just something the LevelDB author designed casually, without any particular reason behind it? Feel free to leave your thoughts in the comments section.</p>
<p>I didn’t get a chance to test the code generation ability as I ran out of quota. According to OpenAI’s documentation, currently o1-preview is limited to 30 messages per week, and o1-mini is 50 messages per week. When I have more quota later, I will continue to try this new model, update this article, and strive to provide a comprehensive evaluation.</p>
<h2 id="Revisiting-Model-Performance"><a href="#Revisiting-Model-Performance" class="headerlink" title="Revisiting Model Performance"></a>Revisiting Model Performance</h2><p>Over the past year, various new models have continually emerged, occasionally claiming to have set new highs in evaluation set scores. However, from practical experience, many models’ capabilities are still relatively average, with some even being unusable. Large model companies seem keen on chasing benchmarks and exaggerating their models’ capabilities, and even Google and OpenAI are not immune to this trend. Google’s previously released Gemini promotional video was exposed as being edited, and many of OpenAI’s official examples for GPT4o’s multimodal capabilities cannot be reproduced now.</p>
<p><strong>To evaluate a model’s capabilities, you ultimately need to try it out yourself multiple times</strong>. Recently, I’ve rarely used GPT, instead using Claude3.5 for coding and daily tasks. Whether it’s code generation or text understanding, I feel it’s considerably better than other models. For coding, using cursor paired with Claude3.5 has significantly improved the experience. As a frontend novice with zero foundation, I’ve been able to quickly create many algorithm visualizations using Claude3.5, which are now available on <a target="_blank" rel="noopener" href="http://gallery.selfboot.cn/">AI Gallery</a> for everyone to experience.</p>
</div><div class="article-footer-copyright"><p> Written in Chinese, LLM translated into English</p><p>Non-commercial reproduction is allowed with proper attribution to the author and source. </p><p>For commercial reproduction, please contact the <a href="mailto:xuezaigds@gmail.com">author</a></p></div><div class="post-donate"><div class="donate_bar center" id="donate_board"><a class="btn_donate" id="btn_donate" href="javascript:;" title="Sponsor"></a><div class="donate_txt"> ↑<br>Good content, Sponsor it<br></div></div><div class="donate_bar center hidden" id="donate_guide"><img src="https://slefboot-1251736664.file.myqcloud.com/weixin.jpg" title="WeChat Sponsor"><img src="https://slefboot-1251736664.file.myqcloud.com/zhifubao.jpg" title="Alipay Sponsor"></div><script type="text/javascript">document.getElementById('btn_donate').onclick = function(){
    $('#donate_board').addClass('hidden');
    $('#donate_guide').removeClass('hidden');
}</script></div><div class="addthis_sharing_toolbox"></div><div class="tags"><a href="/tags/ChatGPT/"><i class="fa fa-tag"></i>ChatGPT</a><a href="/tags/LLM/"><i class="fa fa-tag"></i>LLM</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://selfboot.cn/en/2024/09/13/gpto1_hands_on/';
    this.page.identifier = 'en/2024/09/13/gpto1_hands_on/';
    this.page.title = 'Hands-on with OpenAI's o1-preview - Not Better Enough?';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//xuelangZF.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//xuelangZF.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://xuelangZF.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });</script></div><script type="text/javascript">document.addEventListener('DOMContentLoaded', function () {
  var disqusThread = document.getElementById('disqus_thread');
  if (!disqusThread) return;
  
  function removeAdIframes() {
    var iframes = disqusThread.getElementsByTagName('iframe');
    for (var i = iframes.length - 1; i >= 0; i--) {
      var iframe = iframes[i];
      if (iframe.src && iframe.src.indexOf("tempest.services.disqus.com/ads-iframe") !== -1) {
        iframe.parentNode.removeChild(iframe);
      }
    }
  }
  
  removeAdIframes();
  
  var observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
      removeAdIframes();
    });
  });
  observer.observe(disqusThread, { childList: true, subtree: true });
});
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="https://www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://selfboot.cn"></form></div><div class="widget recommendations-widget"><div class="widget-title"> Recommended</div><div class="recommendations-container"><div class="recommendation-item"><a class="promo-link" href="https://puzzles-game.com/" target="_blank"><div class="promo-content"><i class="fa fa-gamepad"></i><span class="promo-text">Train Your Brain And Stay Smart</span></div></a></div><div class="recommendation-item"><a class="promo-link" href="https://gallery.selfboot.cn" target="_blank"><div class="promo-content"><i class="fa fa-robot"></i><span class="promo-text">Use AI And Help Me Make Things</span></div></a></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"></i><span>Categories</span></div><ul><li><a href="/en/categories/Programming/">Programming</a> (19)</li><li><a href="/en/categories/Source-Code-Analysis/">Source Code Analysis</a> (21)</li><li><a href="/en/categories/Artificial-Intelligence/">Artificial Intelligence</a> (14)</li><li><a href="/en/categories/Discovery/">Discovery</a> (1)</li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"></i><span>Tags</span></div><div class="tagcloud"><a href="/en/tags/Python/" style="font-size: 15.00px;">Python</a> <a href="/en/tags/Google/" style="font-size: 15.00px;">Google</a> <a href="/en/tags/C/" style="font-size: 15.00px;">C++</a> <a href="/en/tags/ChatGPT/" style="font-size: 15.00px;">ChatGPT</a> <a href="/en/tags/Prompt/" style="font-size: 15.00px;">Prompt</a> <a href="/en/tags/Redis/" style="font-size: 15.00px;">Redis</a> <a href="/en/tags/Debug/" style="font-size: 15.00px;">Debug</a> <a href="/en/tags/eBPF/" style="font-size: 15.00px;">eBPF</a> <a href="/en/tags/Go/" style="font-size: 15.00px;">Go</a> <a href="/en/tags/Frontend/" style="font-size: 15.00px;">Frontend</a> <a href="/en/tags/Gemini/" style="font-size: 15.00px;">Gemini</a> <a href="/en/tags/SEO/" style="font-size: 15.00px;">SEO</a> <a href="/en/tags/LLM/" style="font-size: 15.00px;">LLM</a> <a href="/en/tags/Web/" style="font-size: 15.00px;">Web</a> <a href="/en/tags/LevelDB/" style="font-size: 15.00px;">LevelDB</a></div></div><!-- Debug: page.path = en/2024/09/13/gpto1_hands_on/ --><div class="widget"><div class="widget-title"><i class="fa fa-file-o"></i><span>Recent</span></div><ul><li><a href="/en/2025/06/27/leveldb_source_table_build/" title="LevelDB Explained - A Step by Step Guide to SSTable Build">LevelDB Explained - A Step by Step Guide to SSTable Build</a></li><li><a href="/en/2025/06/13/leveldb_source_LRU_cache/" title="LevelDB Explained - The Implementation Details of a High-Performance LRU Cache">LevelDB Explained - The Implementation Details of a High-Performance LRU Cache</a></li><li><a href="/en/2025/06/11/leveldb_source_memtable/" title="LevelDB Explained - The Implementation Details of MemTable">LevelDB Explained - The Implementation Details of MemTable</a></li><li><a href="/en/2025/06/10/leveldb_mvcc_intro/" title="LevelDB Explained - Understanding Multi-Version Concurrency Control (MVCC)">LevelDB Explained - Understanding Multi-Version Concurrency Control (MVCC)</a></li><li><a href="/en/2025/05/23/mcp_user_report/" title="In-depth Experience with 3 MCP Servers via Cursor: Impressive but Not Yet Practical?">In-depth Experience with 3 MCP Servers via Cursor: Impressive but Not Yet Practical?</a></li><li><a href="/en/2025/01/24/leveldb_source_writedb/" title="LevelDB Explained - Implementation and Optimization Details of Key-Value Writing">LevelDB Explained - Implementation and Optimization Details of Key-Value Writing</a></li><li><a href="/en/2025/01/13/leveldb_source_write_batch/" title="LevelDB Explained - Elegant Merging of Write and Delete Operations">LevelDB Explained - Elegant Merging of Write and Delete Operations</a></li><li><a href="/en/2025/01/10/c++_crash_cases/" title="5 Real-world Cases of C++ Process Crashes from Production">5 Real-world Cases of C++ Process Crashes from Production</a></li><li><a href="/en/2025/01/02/leveldb_source_thread_anno/" title="LevelDB Explained - Static Thread Safety Analysis with Clang">LevelDB Explained - Static Thread Safety Analysis with Clang</a></li><li><a href="/en/2024/12/25/leveldb_source_hashtable/" title="LevelDB Explained - How to Design a High-Performance HashTable">LevelDB Explained - How to Design a High-Performance HashTable</a></li></ul></div><!-- Debug: Current Language = en, Filtered Posts Count = 10 --><div class="widget" id="toc"><div class="widget-title"><i class="fa fa-list-ul"></i><span> Contents</span></div><ul class="dsq-widget-list"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Chinese-Interpretations"><span class="toc-number">1.</span> <span class="toc-text">Chinese Interpretations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Code-Understanding-Capability"><span class="toc-number">2.</span> <span class="toc-text">Code Understanding Capability</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Revisiting-Model-Performance"><span class="toc-number">3.</span> <span class="toc-text">Revisiting Model Performance</span></a></li></ol></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Just For Fun.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/selfboot/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/selfboot"> SelfBoot.</a><p><span id="busuanzi_container_site_pv"></span>Total Site Visits:  <span id="busuanzi_value_site_pv"></span> Times，<span id="busuanzi_container_site_uv"></span>Unique Visitors:  <span id="busuanzi_value_site_uv"></span> People</p><p>Friend Link:<a rel="dofollow" target="_blank" href="https://puzzles-game.com/">Puzzle Games</a></p></div></div></div><link rel="stylesheet" type="text/css" href="/css/donate.css"><link rel="stylesheet" type="text/css" href="/css/copyright.css"><link rel="stylesheet" type="text/css" href="/css/recommendations.css"><a class="show" id="rocket" href="#top" aria-label="Back to top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script><script type="text/javascript" src="/js/jquery.fancybox.min.js" defer=""></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" defer=""></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async=""></script><script type="text/javascript" src="/js/toc.js?v=1.0.0"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>