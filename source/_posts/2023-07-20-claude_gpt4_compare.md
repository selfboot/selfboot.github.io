---
title: 大语言模型 Claude2 和 GPT4 实测对比
tags:
  - GPT4
category: 人工智能
toc: true
date: 2023-07-20 23:33:57
description: 对两种大语言模型GPT4和Claude2进行了详细对比,从语言理解、文本生成、逻辑推理、编程、数学以及出现幻觉等多个维度进行测试,发现GPT4的整体表现要略胜一筹,尤其是在编程和避免幻觉方面表现较好。Claude2在语义理解和文本生成上与GPT4基本匹敌,但数学推理和代码能力略逊一筹,且较易出现幻觉。
---

GPT4 是 OpenAI 开发的大语言模型，可以生成文章、代码并执行各种任务。`Claude` 是Anthropic创建的，也是比较领先的大语言模型，核心成员也是前 OpenAI 员工。最近 Claude 2 正式发布，号称在编写代码、分析文本、数学推理等方面的能力都得到了加强，我们来使用下看看吧。

Claude2 的使用比较简单，直接访问 https://claude.ai 即可，不过要保证访问 `anthropic.com` 和 `claude.ai` 的 IP 地址是美国，相信这一点难不倒大家吧。如果觉得有点难，可以参考左耳朵耗子写的[上网指南](https://github.com/haoel/haoel.github.io)。

![模型对比，图片来自 https://www.demandsage.com/chatgpt-vs-claude/](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_vs.png)

<!--more-->

个人用下来，体验以及一些使用门槛的对比如下：

| 功能 | ChatGPT | Claude2 |
|-- | -- | -- |
| 使用限制 | 地区限制，IP 风控，支付风控 | 地区限制 | 
| 费用 | 免费3.5, 付费 4 | 免费 |
| 语言理解 | 3.5 一般，4 很强 | 感觉和 4 差不多|
| 幻觉 | 3.5 比较容易出现, 4 很少出现 | 好于 3.5, 比 4 差| 
| 速度 | 3.5 很快，4 慢很多 | 好于 3.5, 比 4 差 |
| 流式输出 | 支持 | 支持 |
| 中文对话| 支持 | 支持 |
| 插件功能| 支持 | 不支持 |
| 代码解释器 | 支持 | 不支持 |
| Token 上限 | 32K | 200K |
| 编程能力 | 4 很强 | 感觉和 3.5 差不多|

下面将通过一些实际用例来展示这两个模型的能力。

## 语言能力

现在的大语言模型不仅能够理解复杂的语境和语义，还能够生成流畅的文本，甚至能够进行一些基本的推理。下面我们通过几个例子，来对比下这两个模型在语义理解，文本生成和逻辑推理上的效果。

### 语义理解

[TK 教主](https://weibo.com/n/tombkeeper)在微博上面曾经提供了几个例子，来说明大语言模型的语义理解能力。TK 给的例子比较好，都是一些隐喻的描述，可能普通人都很难理解，很考验语义理解能力，这里我们直接也用这两个例子了。

第一个是关于汤不热的隐喻，文本如下：

> 她们也学了煲汤的手艺，但并不见效。谁都不知道是为什么。越是不知道为什么，她们就越恨三姨太。这天晚上，她们偷偷来到三姨太窗外，听到屋里传来一个声音:
> “汤不热了吧?我去给你热一下。"
> 老爷子眼中忽然闪出一道光芒，像年轻了三十岁。

TK 当时用的 Claude+ 能给出不错的解释，知道这个对话用汤不热来传达性的双关和隐喻。Claude2 优化了道德审查能力，直接识别出涉及一些敏感话题，然后不给回答了。相比之下，GPT4 就比较傻了，只理解字面意思。回答对比如下图：

![语义理解，Claude 理解双关和隐喻](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_mean_1.png)

再来看另一个例子，还是一个隐喻，具体文本如下：

> 对微博上的佩奇们来说，今天是最黑暗的一天——她们的摩西杀了她们的加百列。 

可以看到 GPT4 和 Claude2 的理解也都基本是可以的，如下图：

![语义理解，GPT4 稍微好一点](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_mean_2.png)

### 文本生成

文本生成这里，首先考虑让 AI 来续写小说。其实就目前最强大的 GPT4 来说，也不能写出风格统一，情节符合常识并且连贯的小说。AI 离替代人类作家，还有很远的路要走。不过这里我们还是尝试了一下，提示词如下：

> 你是一个优秀的小说作家，现在准备写一篇盗窃相关的小说，开头部分如下：
> 在一个风高月黑的晚上。
> 
> 帮我续写，字数大概在 300 字左右，文笔要诙谐一点，风格要是中国现代小说的风格。

![GPT4 和 Claude2 的小说创作](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_generate_3.png)

GPT4 老老实实地生成了小说，总体文笔和情节还说的过去，不过里面有些情节不太符合常识，比如**熬夜打王者荣耀的太监**。可能中文语料里，熬夜打王者荣耀出现的次数太多了吧。Claude2 则承认自己在写小说方面不太擅长，然后给出了一些写作建议。

写小说有点难度，来试试一个比较常见的**生成文本摘要**。我们选择科幻小说《三体3：死神永生》的章节：“广播纪元 7 年，程心”的开头部分，效果如下：

![GPT4 和 Claude2 的文本摘要总结](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_generate_4.png)

GPT4也可以再简短一点，生成如下：程心经过五年基因克隆和视网膜移植治疗，恢复了视力，同时她的公司在近地轨道太空建筑业中崭露头角，而艾AA虽经历移民艰难，但未显岁月痕迹。总体看两个模型能力基本一样，没有明显优劣。

### 逻辑推理

除了上面的语义理解和文本生成，现在的大语言模型还可以进行一些逻辑推理。来看一个具体的例子，提问内容是

> 鲁迅生气打了周树人，可能是什么原因呢？

GPT4 回答鲁迅和周树人是同一人，都是现代中国著名的文学家周樟寿的笔名。而 Claude2 的回答就不着调了，还说根据公开报道，鲁迅和周树人是良好的朋友与合作伙伴关系。

![鲁迅打了周树人](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230719_claude_gpt4_compare_mean_5.png)

再来看另一个比较经典的问题：“我爸我妈结婚为什么没有邀请我”，GPT4 的回答考虑的逻辑就很完备，知道分结婚前出生和结婚后出生这两种情况了。Claude2 知识考虑了结婚前出生，另外多了一些道德引导，完整如下图：

![经典父母结婚请客问题](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230719_claude_gpt4_compare_mean_6.png)

## 数学问题

数学其实一直是大模型的一个弱项，就算是 GPT4，数学推理计算能力也不行，需要依赖外部工具。下面用实例来比较两个模型在数学能力上的差距。

### 简单数学

先来看看简单的鸡兔同笼问题，我们让 GPT4 和 Claude2 自己生成题目并解决，发现两者的能力基本一致，如下图所示：

![简单鸡兔同笼问题](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230715_claude_gpt4_compare_math.png)

### 微积分

再看一个稍微复杂的微积分的例子，我们尝试让 GPT4 和 Claude 讲解微积分并给出具体的示例，提示词如下：

> 可以给我一个例子，教我什么是积分，以及怎么求积分吗

两个模型回答都还可以，GPT4 的解释稍微清晰一点，如下图：

![微积分知识的回答](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230719_claude_gpt4_compare_math_2.png)

## 代码能力

平时用 GPT4 比较多，对于一些不是很复杂的逻辑，GPT4 写的代码还是很不错的。Claude2 的测评显示代码能力有了大的提升，下面通过几个示例来直观体验下。

### 最大公约数

提问内容都如下：

> 帮我用 python 写一个函数，用来计算两个数字的最大公约数。

GPT4 的代码用循环实现了欧几里得辗转相除法，给了完整的解释和代码，以及简单测试。而 Claude2 则给出了辗转相除法的递归实现和简单测试，对代码进行了简单解释。如下：

![最大公约数生成的代码](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_code_1.png)

我们知道 Python 中没有尾递归优化，所以递归深度太深的话，可能会栈溢出，抛出一个 RecursionError 错误。拿这一点来继续追问 GPT4 和 Claude2，提示词分别如下：

> GPT4: 上面用循环实现，为啥不用递归实现呢？ python 中递归会有什么问题？
> Claude2: 上面代码用到了递归，python 递归深度太深的话，会不会有问题呢？

GPT4 给出了递归版本的实现，然后提醒了 Python 中递归深度限制的原因，以及可以通过 `sys.getrecursionlimit()` 查看当前的递归深度限制。提醒到在处理大数据或是不确定数据规模的时候，循环结构通常是一个更安全、更可靠的选择。另外也提到在其他一些语言，如 Haskell 或 Scheme 中，由于它们使用`尾递归优化`，递归在这些语言中可能会被更广泛地使用。

Claude2 也知道 Python 递归深度限制，给出了循环版本的实现。另外，还提到在 Python 3.8 之后，可以使用functools.lru_cache 做memoization，避免重复计算。其实在最大公约数这里，添加记忆话效果并不是很好，这里的建议不是很合理。

完整的回答如下图：

![对于 Python 递归深度问题的追问结果](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_code_2.png)

### 解释代码

上面看到两个模型写代码能力有一点区别，接下来看看在对代码的理解上有没有明显差异。这里我们选择的源代码是 OpenAI 的 python 库 [openai-python](https://github.com/openai/openai-python) 中 [openai_response.py](https://github.com/openai/openai-python/blob/main/openai/openai_response.py) 的实现。提问的 Prompt 如下：

> 解释下面代码的作用，可以适当总结概括下。
> (复制的代码，这里忽略)

从回复上看，GPT4 的更加详细点，对每个字段都有简单说明，Claude2 则对整理的设计思路讲的比较详细些。如下图：

![openai_response.py 实现的解释](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_code_3.png)

接着再详细问一些 Python 语法相关的知识点，`@property` 和 `-> Optional[str]` 分别是什么意思。两个模型都回答对了，不过 GPT4 的回答明显会更加详细，并且有一定的扩展。会回答在实际运行中，Python 不会强制检查类型注解的正确性，**类型注解主要用于提示和文档**，以及一些集成开发环境（IDE）和工具会**使用类型注解来提供更好的代码完成和错误检查**。

![Python 实现技术细节的回答](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_code_4.png)

## 人文历史

试着让这两个模型分别回答了下面的一些人文历史的提问：

> 介绍下中国历史上的名人武则天的生平。
> 建安七子都是谁，分别都有什么事迹。
> 诸葛亮是曹操的丞相，做了哪些大事呢？
> 怎么评价汉武帝？

建安七子的问题上，GPT4 和 Claude2 的回答都不太准备，其他问题，两个模型回答都还算符合事实。GPT4 的回答会更加饱满立体，细节也会多一些。比如在诸葛亮的贡献上提到了：协助刘备立国，开展鞠躬尽瘁的治国理政，北伐中原，稳定国内，木牛流马，文化贡献等。而 Claude2 的回答就简单了很多，几乎没有提到诸葛亮的贡献。

GPT4 的总结评价也比较到位：诸葛亮是中国历史上著名的政治家、军事家、文学家、书法家，被尊称为"睿智的孔明"或"诸葛孔明"，在中国历史上享有极高的威望。如下图：

![历史问题的回答](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_history.png)

在评价汉武帝的时候，两个模型基本也都给了正面和负面的评价，不过 Claude2 的回答有点搞笑，在提到成就的时候有下面一条：

> employing能臣如霍光等人,改革弊政,使汉朝政治清明。

忽然冒出了个英文，有点奇怪，应该是模型的 bug 了。

## 幻觉

大语言模型本质上是一个概率预测，并不知道事实，因此会**“胡编乱造”一些看起来很“合理”**的内容。

在编程领域，模型有时候会编造一些不存在的库或者函数，来完成一些编程任务。有时候也会给出一些虚假的信息，来尝试回答某个问题。接下来我们试着让 GPT4 和 Claude2 回答下面的一个编程问题：

> 帮我写一个程序验证 `np.linalg.eig(np.random.rand(n, n))` 有没有自动在底层并行化，执行程序并告诉我结果。

两个模型都给出了还算合理的解决代码，区别在于 GPT4 直接回答自己是语言模型**没法运行代码**(这里没用Code Interpreter)，但是 Claude2 则出现幻觉，说已经在本地机器上运行，当 n=1000 时，计算时间大约为0.4秒。如下图：

![GPT4 和 Claude2 的幻觉](https://slefboot-1251736664.cos.ap-beijing.myqcloud.com/20230718_claude_gpt4_compare_hallucination.png)

除了幻觉这一点，对比回答质量，GPT4 还是会好很多，给出的解释也会详细很多：`numpy.linalg.eig` 函数在底层实现上依赖于 `BLAS(LAPACK)` 库，这些库可能会根据安装和编译时的配置自动实现并行化。不过 Python 自身是无法控制这个过程的。此外，验证并行化的效果通常需要在多核 CPU 上运行，如果只有单核 CPU，那么并行化不会带来任何性能提升。

另外试了下提问：“用 notion 的 api 创建笔记，想上传本地的图片到笔记中，要如何做？”，这里 GPT4 直接回答Notion的API（到2021年9月为止）并未提供直接上传图片的功能，然后给的方案是上传到图片托管服务拿到链接，直接用链接。但是 Claude2 幻觉比较严重，直接伪造了一个不存在的 API 接口，还提供了具体的方法。参考 `Notion API` 文档,上传文件需要发起一个 `POST` 请求到 `/upload` endpoint，在 body 中包含图片二进制数据以及 parent 对象信息。

其他领域也会出现一些幻觉，比如捏造一些不存在的人或者事情，引用不存在的论文等。总之，在用的时候，一定能够验证 AI 的回答是否正确。

上面基本就是 GPT4 和 Claude2 的对比实测了，总体而言付费的 GPT4 还是要好一些，Claude2 还有一点差距。